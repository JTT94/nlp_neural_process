{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_NeuralProcesses_notebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JTT94/nlp_neural_process/blob/master/BERT_NeuralProcesses_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SZKAwmizhzHo",
        "outputId": "b481b52f-d4a9-4865-f985-bda5084c1319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import re\n",
        "\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import string\n",
        "from datetime import datetime \n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow_probability import distributions as tfd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0516 00:01:21.830325 139860753180544 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pgB8X8dti3qc",
        "outputId": "37285144-4785-475f-9c41-3d9df364b42d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "!pip install bert-tensorflow\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCJDPOgQOsqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialiase tensorboard \n",
        "# from https://stackoverflow.com/questions/47818822/can-i-use-tensorboard-with-google-colab\n",
        "\n",
        "\n",
        "# Get TensorBoard running in the background. \n",
        "LOG_DIR = './test_output'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sZ3Bl48oaxU",
        "colab_type": "code",
        "outputId": "ca239282-2756-451a-9605-0816f0d9fd5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# # #Download and unzip ngrok. \n",
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-16 00:01:30--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.4.75.11, 52.45.111.123, 3.214.163.243, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.4.75.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16529980 (16M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  15.76M  15.6MB/s    in 1.0s    \n",
            "\n",
            "2019-05-16 00:01:31 (15.6 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [16529980/16529980]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLp9PmAzoWhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Launch ngrok background process...\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL1A1ibjOwnL",
        "colab_type": "code",
        "outputId": "e74f69be-bc33-4230-8915-0cbdeff132d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://2a19ca21.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bweIS72l5WS5",
        "colab_type": "code",
        "outputId": "ec0469d1-47a4-4952-d6f9-c3e5d60f5454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "import os, sys\n",
        "sys.path.append('../') # add personal code dir to path for import\n",
        "\n",
        "\n",
        "!test -d neural_process || git clone https://github.com/JTT94/nlp_neural_process.git neural_process\n",
        "sys.path.append('./neural_process/')\n",
        "\n",
        "import random\n",
        "from neural_process import split_context_target, NeuralProcessParams\n",
        "from neural_process.network import *\n",
        "from neural_process.loss import *\n",
        "from neural_process.predict import *\n",
        "from neural_process.process import *\n",
        "\n",
        "from neural_process.tf_model_builder_AUC import *\n",
        "from neural_process.bert_utils import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'neural_process'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 39 (delta 16), reused 27 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (39/39), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "69MNF4fEi5Ly",
        "outputId": "577eb83f-d37e-4329-b3c0-104b822bf529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "source": [
        "# Initialize session\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "K.tensorflow_backend._get_available_gpus()\n",
        "# tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/job:localhost/replica:0/task:0/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDvh4JVNQFck",
        "colab_type": "code",
        "outputId": "75f43ee9-85a4-44bd-9f6d-1c965bbe39f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfAdXX0kQFfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cc1rwgOZi9F1",
        "outputId": "985f28a6-0758-465d-9ccf-eb1ab9e58b70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "source": [
        "# filename = './cleaned_data.csv'\n",
        "# filename = './data1.csv'\n",
        "# df = pd.read_csv(filename, index_col=0)\n",
        "# cols = ['comment','antagonize', 'condescending', 'dismissive', 'generalisation', 'hostile', 'sarcastic', 'healthy']\n",
        "# cols = ['comment','cleaned_comment','antagonize', 'condescending', 'dismissive', 'generalisation', 'hostile', 'sarcastic', 'healthy']\n",
        "# df = df[cols]\n",
        "\n",
        "#score_column = ['antagonize', 'condescending', 'dismissive', 'generalisation', 'hostile', 'sarcastic', 'healthy']\n",
        "# text_col_name = 'cleaned_comment'\n",
        "# text_col_name = 'comment'\n",
        "\n",
        "#--------\n",
        "\n",
        "## For kaggle dataset\n",
        "\n",
        "filename = './gdrive/My Drive/Kaggle_toxic_comments/kaggle_train.csv'\n",
        "df = pd.read_csv(filename)\n",
        "cols = ['comment_text','toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "df = df[cols]\n",
        "\n",
        "score_column = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'] \n",
        "\n",
        "text_col_name = 'comment_text'\n",
        "\n",
        "#Cast to float - because scores and labels need to be concattenated in the model function, and so need to be same type\n",
        "for i in score_column:\n",
        "  df[i] = pd.to_numeric(df[i],downcast='float')\n",
        "  \n",
        "len(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "159571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p_JIbqhY55L_",
        "outputId": "a2247ffd-bf91-40b4-d654-e2fab881e576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "# Restrict comment length\n",
        "\n",
        "df = df[df.comment_text.str.len() <= 250]\n",
        "\n",
        "# print(len(df))\n",
        "\n",
        "# full_df = df.copy(deep=True)\n",
        "\n",
        "#sample portion of dataset to speed up preprocessing\n",
        "\n",
        "# df = df.sample(frac = 0.5)\n",
        "\n",
        "# over represent toxic comments\n",
        "\n",
        "df['num_toxic_atts'] = df[cols[1:]].apply(lambda x: np.sum(x), axis = 1)\n",
        "\n",
        "df_toxic = df[df.num_toxic_atts  > 0]\n",
        "# print(len(df_toxic))\n",
        "df_healthy_sample = df[df.num_toxic_atts == 0][:len(df_toxic)]\n",
        "print(len(df_healthy_sample))\n",
        "df_healthy_remaining = df[df.num_toxic_atts == 0][len(df_toxic):]\n",
        "print(len(df_healthy_remaining))\n",
        "\n",
        "df_overrep = pd.concat([df_toxic, df_healthy_sample]).sample(frac=1.0)\n",
        "print(len(df_overrep))\n",
        "train_propn = 0.8\n",
        "\n",
        "ratio = len(df_toxic)/(len(df_healthy_sample)+len(df_healthy_remaining))\n",
        "print(ratio)\n",
        "\n",
        "df_train = df_overrep[:int(len(df_overrep)*train_propn)]\n",
        "print(len(df_train))\n",
        "\n",
        "#construct a test set with similar proportion/imbalance in toxic - nontoxic data to the real data set\n",
        "df_test = pd.concat([df_overrep[int(len(df_overrep)*train_propn):], df_healthy_remaining[:int((1-0.8)*(len(df_healthy_remaining)-len(df_train)))]])\n",
        "\n",
        "print(0.5*len(df_overrep[int(len(df_overrep)*train_propn):]) / len(df_test))\n",
        "# df_train.head(50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11640\n",
            "67417\n",
            "23280\n",
            "0.14723553891496008\n",
            "18624\n",
            "0.16150964340224783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8p3Cm_z3nm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mUIe15uTi9Ok",
        "outputId": "224f40f3-31a2-4a6e-947f-ac15b3056364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_model_hub = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "tokenizer = create_tokenizer_from_hub_module(BERT_model_hub)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0516 00:03:12.077280 139860753180544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:03:14.211209 139860753180544 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IVESPLmgl98I",
        "colab": {}
      },
      "source": [
        "# #Pre process data for bert embedding\n",
        "\n",
        "max_seq_length = 128\n",
        "\n",
        "import pickle\n",
        "\n",
        "train_input_examples = create_examples(df_train, score_column, text_col_name)\n",
        "test_input_examples = create_examples(df_test, score_column, text_col_name)\n",
        "\n",
        "train_features = convert_examples_to_features(train_input_examples, max_seq_length, tokenizer)\n",
        "test_features = convert_examples_to_features(test_input_examples, max_seq_length, tokenizer)\n",
        "\n",
        "pickle.dump(train_features, open('./gdrive/My Drive/Kaggle_toxic_comments/train_features.p', 'wb'))\n",
        "pickle.dump(test_features, open('./gdrive/My Drive/Kaggle_toxic_comments/test_features.p', 'wb'))\n",
        "\n",
        "# # ## Load features previously saved\n",
        "\n",
        "# train_features = pickle.load(open('./gdrive/My Drive/Kaggle_toxic_comments/train_features.p', 'rb'))\n",
        "# test_features = pickle.load(open('./gdrive/My Drive/Kaggle_toxic_comments/train_features.p', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUGi_5G5VzBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fvzbqq1alHf8",
        "colab": {}
      },
      "source": [
        "outputDim = len(score_column)\n",
        "num_draws = 20\n",
        "\n",
        "def encoder_h(context_xys: tf.Tensor, params: NeuralProcessParams) -> tf.Tensor:\n",
        "    \"\"\"Map context inputs (x_i, y_i) to r_i\n",
        "\n",
        "    Creates a fully connected network with a single sigmoid hidden layer and linear output layer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    context_xys\n",
        "        Input tensor, shape: (n_samples, dim_x + dim_y)\n",
        "    params\n",
        "        Neural process parameters\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        Output tensor of encoder network\n",
        "    \"\"\"\n",
        "    hidden_layer = context_xys\n",
        "#     print('hidden layer')\n",
        "#     print(hidden_layer)\n",
        "#     print(enumerate(params.n_hidden_units_h))\n",
        "    # First layers are relu\n",
        "    for i, n_hidden_units in enumerate(params.n_hidden_units_h):\n",
        "#         print(i)\n",
        "#         print(n_hidden_units)\n",
        "        hidden_layer = tf.layers.dense(hidden_layer, n_hidden_units,\n",
        "                                       activation=tf.nn.relu,\n",
        "                                       name='encoder_layer_{}'.format(i),\n",
        "                                       reuse=tf.AUTO_REUSE,\n",
        "                                       kernel_initializer='normal')\n",
        "#         print(hidden_layer)\n",
        "\n",
        "    # Last layer is simple linear\n",
        "    i = len(params.n_hidden_units_h)\n",
        "    r = tf.layers.dense(hidden_layer, params.dim_r,\n",
        "                        name='encoder_layer_{}'.format(i),\n",
        "                        reuse=tf.AUTO_REUSE,\n",
        "                        kernel_initializer='normal')\n",
        "    return r\n",
        "  \n",
        "  \n",
        "def aggregate_r(context_rs: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Aggregate the output of the encoder to a single representation\n",
        "\n",
        "    Creates an aggregation (mean) operator to combine the encodings of multiple context inputs\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    context_rs\n",
        "        Input encodings tensor, shape: (n_samples, dim_r)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        Output tensor of aggregation result\n",
        "    \"\"\"\n",
        "    mean = tf.reduce_mean(context_rs, axis=0)\n",
        "\n",
        "    r = tf.reshape(mean, [1, -1])\n",
        "    return r\n",
        "\n",
        "\n",
        "def get_z_params(context_r: tf.Tensor, params: NeuralProcessParams) -> GaussianParams:\n",
        "    \"\"\"Map encoding to mean and covariance of the random variable Z\n",
        "\n",
        "    Creates a linear dense layer to map encoding to mu_z, and another linear mapping + a softplus activation for Sigma_z\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    context_r\n",
        "        Input encoding tensor, shape: (1, dim_r)\n",
        "    params\n",
        "        Neural process parameters\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        Output tensors of the mappings for mu_z and Sigma_z\n",
        "    \"\"\"\n",
        "    mu = tf.layers.dense(context_r, params.dim_z, name=\"z_params_mu\", reuse=tf.AUTO_REUSE, kernel_initializer='normal')\n",
        "\n",
        "    sigma = tf.layers.dense(context_r, params.dim_z, name=\"z_params_sigma\", reuse=tf.AUTO_REUSE,\n",
        "                            kernel_initializer='normal')\n",
        "    sigma = tf.nn.softplus(sigma)\n",
        "\n",
        "    return GaussianParams(mu, sigma)\n",
        "\n",
        "\n",
        "def decoder_g(input_xs_embedding, z_samples: tf.Tensor, params: NeuralProcessParams,\n",
        "              noise_std: float = 0.05) -> GaussianParams:\n",
        "    \"\"\"Determine output y* by decoding input and latent variable\n",
        "\n",
        "    Creates a fully connected network with a single sigmoid hidden layer and linear output layer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    z_samples\n",
        "        Random samples from the latent variable distribution, shape: (n_z_draws, dim_z)\n",
        "    input_xs\n",
        "        Input values to predict for, shape: (n_x_samples, dim_x)\n",
        "    params\n",
        "        Neural process parameters\n",
        "    noise_std\n",
        "        Constant standard deviation used on output\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        Output tensors for the parameters of Gaussian distributions for target outputy, where its mean mu has shape\n",
        "        (n_x_samples, n_z_draws)\n",
        " \n",
        "    \"\"\"\n",
        "    # inputs dimensions\n",
        "    # z_sample has dim [n_draws, dim_z]\n",
        "    # x_star has dim [N_star, dim_x]\n",
        "\n",
        "    n_draws = z_samples.get_shape().as_list()[0]\n",
        "#     print('n_draws')\n",
        "#     print(n_draws)\n",
        "    n_xs = tf.shape(input_xs_embedding)[0]\n",
        "\n",
        "    # Repeat z samples for each x*\n",
        "    z_samples_repeat = tf.expand_dims(z_samples, axis=1)\n",
        "    z_samples_repeat = tf.tile(z_samples_repeat, [1, n_xs, 1])\n",
        "\n",
        "    # Repeat x* for each z sample\n",
        "#     input_xs_embedding = embedder(input_xs)\n",
        "    x_star_repeat = tf.expand_dims(input_xs_embedding, axis=0)\n",
        "    x_star_repeat = tf.tile(x_star_repeat, [n_draws, 1, 1])\n",
        "\n",
        "    # Concatenate x* and z\n",
        "    # shape: (n_z_draws, n_xs, dim_x + dim_z)\n",
        "    inputs = tf.concat([x_star_repeat, z_samples_repeat], axis=2)\n",
        "\n",
        "    hidden_layer = inputs\n",
        "    # First layers are relu\n",
        "    for i, n_hidden_units in enumerate(params.n_hidden_units_g):\n",
        "        hidden_layer = tf.layers.dense(hidden_layer, n_hidden_units,\n",
        "                                       activation=tf.nn.relu,\n",
        "                                       name='decoder_layer_{}'.format(i),\n",
        "                                       reuse=tf.AUTO_REUSE,\n",
        "                                       kernel_initializer='normal')\n",
        "\n",
        "    # Last layer is simple linear\n",
        "    i = len(params.n_hidden_units_g)\n",
        "    hidden_layer = tf.layers.dense(hidden_layer, outputDim,\n",
        "                                   name='decoder_layer_{}'.format(i),\n",
        "                                   reuse=tf.AUTO_REUSE,\n",
        "                                   kernel_initializer='normal')\n",
        "\n",
        "    hidden_layer = tf.math.sigmoid(hidden_layer)\n",
        "    \n",
        "    # mu will be of the shape [N_star, n_draws]\n",
        "    mu_star = hidden_layer\n",
        "\n",
        "    sigma_star = tf.constant(noise_std, dtype=tf.float32)\n",
        "\n",
        "    return GaussianParams(mu_star, sigma_star)\n",
        "\n",
        "\n",
        "def xy_to_z_params(context_xs: tf.Tensor, context_ys: tf.Tensor,\n",
        "                   params: NeuralProcessParams) -> GaussianParams:\n",
        "    \"\"\"Wrapper to create full network from context samples to parameters of pdf of Z\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    context_xs\n",
        "        Tensor with context features, shape: (n_samples, dim_x)\n",
        "    context_ys\n",
        "        Tensor with context targets, shape: (n_samples, dim_y)\n",
        "    params\n",
        "        Neural process parameters\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        Output tensors of the mappings for mu_z and Sigma_z\n",
        "    \"\"\"\n",
        "#     context_xs = embedder(context_xs)\n",
        "    xys = tf.concat([context_xs, context_ys], axis=1)\n",
        "    rs = encoder_h(xys, params)\n",
        "    r = aggregate_r(rs)\n",
        "    z_params = get_z_params(r, params)\n",
        "    return z_params\n",
        "\n",
        "def loglikelihood(y_star: tf.Tensor, y_pred_params: GaussianParams):\n",
        "    \"\"\"Log-likelihood of an output given a predicted \"\"\"\n",
        "    p_normal = tfd.MultivariateNormalDiag(loc=y_pred_params.mu)\n",
        "    loglike = p_normal.log_prob(y_star)\n",
        "    loglike = tf.reduce_sum(loglike, axis=0)\n",
        "    loglike = tf.reduce_mean(loglike)\n",
        "    return loglike\n",
        "  \n",
        "  \n",
        "def create_model(input_ids, input_mask, segment_ids, num_labels, scores):\n",
        "\n",
        "#     \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "    # 1 split input ids, input mask, seg ids and scores into context and target\n",
        "#     tf.logging.info('input ids shape')\n",
        "      \n",
        "    \n",
        "    bert_module = hub.Module(BERT_model_hub,trainable=True)\n",
        "\n",
        "    bert_inputs = dict(input_ids=input_ids,input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "\n",
        "    bert_outputs = bert_module(inputs=bert_inputs,signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "    \n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence. Use \"sequence_outputs\" for token-level output.\n",
        "    output_bert_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "    tf.logging.info(output_bert_layer)\n",
        "    \n",
        "    hidden_size = output_bert_layer.shape[-1].value\n",
        "\n",
        "    # -------\n",
        "     \n",
        "    params = NeuralProcessParams(dim_r=20, dim_z=20, n_hidden_units_h=[128, 128, 128], n_hidden_units_g=[128, 128, 128])\n",
        "\n",
        "    btch_sz = tf.shape(output_bert_layer)[0]\n",
        "    \n",
        "    n_context = tf.random_shuffle(tf.range(1,btch_sz))[0]\n",
        "  \n",
        "    \n",
        "    indices = tf.range(0,batch_size)\n",
        "    context_set_indices = tf.gather(tf.random_shuffle(indices),tf.range(n_context))\n",
        "    target_set_indices = tf.gather(tf.random_shuffle(indices),tf.range(n_context, btch_sz))\n",
        "    context_xs = tf.gather(output_bert_layer,context_set_indices)\n",
        "    context_ys = tf.gather(scores, context_set_indices)\n",
        "    target_xs = tf.gather(output_bert_layer,target_set_indices)\n",
        "    target_ys = tf.gather(scores,target_set_indices)\n",
        "\n",
        "    x_all = tf.concat([context_xs, target_xs], axis=0)\n",
        "#     print('context_ys')\n",
        "#     print(context_ys)\n",
        "#     print('target_ys')\n",
        "#     print(target_ys)\n",
        "   \n",
        "    y_all = tf.concat([context_ys, target_ys], axis = 0)\n",
        "    \n",
        "#     print('z_context:')\n",
        "    z_context = xy_to_z_params(context_xs, context_ys, params)\n",
        "#     print('zall:')\n",
        "    z_all = xy_to_z_params(x_all, y_all, params)\n",
        "    \n",
        "    epsilon = tf.random_normal([num_draws, params.dim_z])\n",
        "    z_samples = tf.multiply(epsilon, z_all.sigma)\n",
        "    z_samples = tf.add(z_samples, z_all.mu)\n",
        "#     print('z_samples:')\n",
        "#     print(z_samples)\n",
        "    \n",
        "    y_pred_params = decoder_g(target_xs, z_samples, params)\n",
        "\n",
        "    loglike = loglikelihood(target_ys, y_pred_params)\n",
        "    KL_loss = KLqp_gaussian(z_all.mu, z_all.sigma, z_context.mu, z_context.sigma)\n",
        "    loss = tf.negative(loglike) + KL_loss\n",
        "    \n",
        "    ystar = tf.math.reduce_mean(y_pred_params.mu, 0)\n",
        "#     print('y_mu')\n",
        "#     print(y_pred_params.mu)\n",
        "#     print('ystar')\n",
        "#     print(ystar[:,1])\n",
        "#     print('target_ys')\n",
        "#     print(tf.math.round(target_ys)[:,1])\n",
        "    \n",
        "    return (loss, y_pred_params, target_ys)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8iSEczc6NS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3K9kf-1DlHJA",
        "outputId": "675b82b5-68d9-429c-f465-13a84d4971de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3909
        }
      },
      "source": [
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "batch_size = 32\n",
        "# lr = 2e-2\n",
        "lr = 2e-5\n",
        "epochs = 6.0\n",
        "# Warmup is a period of time where the learning rate  is small and gradually increases\n",
        "warmpup_proportion = 0.1\n",
        "\n",
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / batch_size *epochs)\n",
        "num_warmup_steps = int(num_train_steps * warmpup_proportion)\n",
        "\n",
        "#####\n",
        "\n",
        "output_dir = \"./test_output\"\n",
        "save_checkpoints_steps = 500\n",
        "save_summary_steps = 100\n",
        "\n",
        "# Specify outpit directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(model_dir=output_dir,\n",
        "    save_summary_steps=save_summary_steps, save_checkpoints_steps=save_checkpoints_steps)\n",
        "\n",
        "#####\n",
        "\n",
        "num_labels = len(score_column)\n",
        "\n",
        "model_fn = model_fn_builder(create_model, num_labels = num_labels, learning_rate=lr,\n",
        "  num_train_steps=num_train_steps, num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(model_fn=model_fn,config=run_config,\n",
        "  params={\"batch_size\": batch_size})\n",
        "\n",
        "#####\n",
        "\n",
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = input_fn_builder(\n",
        "    features=train_features, seq_length=max_seq_length, \n",
        "    num_labels = num_labels, is_training=True, drop_remainder=False)\n",
        "\n",
        "#####\n",
        "\n",
        "print('Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': './test_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f333bc89b00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:04:10.381706 139860753180544 estimator.py:201] Using config: {'_model_dir': './test_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f333bc89b00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:04:21.236845 139860753180544 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:04:24.324681 139860753180544 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor(\"module_apply_tokens/bert/pooler/dense/Tanh:0\", shape=(?, 768), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:04:24.437022 139860753180544 <ipython-input-14-03d076912b2b>:212] Tensor(\"module_apply_tokens/bert/pooler/dense/Tanh:0\", shape=(?, 768), dtype=float32)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-03d076912b2b>:32: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0516 00:04:24.467227 139860753180544 deprecation.py:323] From <ipython-input-14-03d076912b2b>:32: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0516 00:04:24.809773 139860753180544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0516 00:04:24.898495 139860753180544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0516 00:04:34.622909 139860753180544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:04:35.269004 139860753180544 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:04:35.272695 139860753180544 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:04:39.630389 139860753180544 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:04:44.768957 139860753180544 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:04:45.006608 139860753180544 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into ./test_output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:05:00.612030 139860753180544 basic_session_run_hooks.py:594] Saving checkpoints for 0 into ./test_output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 125.24926, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:05:19.970800 139860753180544 basic_session_run_hooks.py:249] loss = 125.24926, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.01358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:06:58.630043 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.01358\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 120.82421, step = 100 (98.662 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:06:58.632730 139860753180544 basic_session_run_hooks.py:247] loss = 120.82421, step = 100 (98.662 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:08:24.522011 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16425\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 113.88687, step = 200 (85.892 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:08:24.524725 139860753180544 basic_session_run_hooks.py:247] loss = 113.88687, step = 200 (85.892 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:09:50.369359 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16486\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 113.53316, step = 300 (85.848 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:09:50.372483 139860753180544 basic_session_run_hooks.py:247] loss = 113.53316, step = 300 (85.848 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16686\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:11:16.069515 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16686\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 112.56376, step = 400 (85.703 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:11:16.075495 139860753180544 basic_session_run_hooks.py:247] loss = 112.56376, step = 400 (85.703 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 500 into ./test_output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:12:40.893782 139860753180544 basic_session_run_hooks.py:594] Saving checkpoints for 500 into ./test_output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.04924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:12:51.376903 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.04924\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 110.42627, step = 500 (95.308 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:12:51.384026 139860753180544 basic_session_run_hooks.py:247] loss = 110.42627, step = 500 (95.308 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:14:17.456445 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16172\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 113.55364, step = 600 (86.079 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:14:17.462230 139860753180544 basic_session_run_hooks.py:247] loss = 113.55364, step = 600 (86.079 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:15:43.347286 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16427\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 113.16369, step = 700 (85.893 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:15:43.355630 139860753180544 basic_session_run_hooks.py:247] loss = 113.16369, step = 700 (85.893 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:17:09.145811 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16552\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 113.287445, step = 800 (85.797 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:17:09.152234 139860753180544 basic_session_run_hooks.py:247] loss = 113.287445, step = 800 (85.797 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:18:34.823504 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16717\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 112.191925, step = 900 (85.675 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:18:34.827246 139860753180544 basic_session_run_hooks.py:247] loss = 112.191925, step = 900 (85.675 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1000 into ./test_output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:19:59.679044 139860753180544 basic_session_run_hooks.py:594] Saving checkpoints for 1000 into ./test_output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.04938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:20:10.117633 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.04938\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 113.47943, step = 1000 (95.293 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:20:10.119954 139860753180544 basic_session_run_hooks.py:247] loss = 113.47943, step = 1000 (95.293 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:21:36.204208 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16162\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 112.40215, step = 1100 (86.089 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:21:36.209373 139860753180544 basic_session_run_hooks.py:247] loss = 112.40215, step = 1100 (86.089 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:23:02.080669 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16446\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 111.99368, step = 1200 (85.877 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:23:02.086729 139860753180544 basic_session_run_hooks.py:247] loss = 111.99368, step = 1200 (85.877 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:24:27.834459 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16613\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 110.67973, step = 1300 (85.755 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:24:27.842114 139860753180544 basic_session_run_hooks.py:247] loss = 110.67973, step = 1300 (85.755 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:25:53.478961 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16762\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 116.937874, step = 1400 (85.642 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:25:53.488729 139860753180544 basic_session_run_hooks.py:247] loss = 116.937874, step = 1400 (85.642 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1500 into ./test_output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:27:18.379077 139860753180544 basic_session_run_hooks.py:594] Saving checkpoints for 1500 into ./test_output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.04958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:27:28.755436 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.04958\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 112.313, step = 1500 (95.274 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:27:28.757899 139860753180544 basic_session_run_hooks.py:247] loss = 112.313, step = 1500 (95.274 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:28:54.901185 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16082\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 110.8466, step = 1600 (86.150 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:28:54.908220 139860753180544 basic_session_run_hooks.py:247] loss = 110.8466, step = 1600 (86.150 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16443\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:30:20.779788 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16443\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 113.09156, step = 1700 (85.880 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:30:20.787978 139860753180544 basic_session_run_hooks.py:247] loss = 113.09156, step = 1700 (85.880 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:31:46.556877 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16581\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 111.41201, step = 1800 (85.775 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:31:46.563053 139860753180544 basic_session_run_hooks.py:247] loss = 111.41201, step = 1800 (85.775 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:33:12.432027 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16448\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 113.270905, step = 1900 (85.875 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:33:12.437983 139860753180544 basic_session_run_hooks.py:247] loss = 113.270905, step = 1900 (85.875 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 2000 into ./test_output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:34:37.395866 139860753180544 basic_session_run_hooks.py:594] Saving checkpoints for 2000 into ./test_output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.04721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:34:47.924243 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.04721\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 112.1551, step = 2000 (95.492 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:34:47.929557 139860753180544 basic_session_run_hooks.py:247] loss = 112.1551, step = 2000 (95.492 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.1617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:36:14.004965 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.1617\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 112.04161, step = 2100 (86.080 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:36:14.009839 139860753180544 basic_session_run_hooks.py:247] loss = 112.04161, step = 2100 (86.080 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:37:39.783792 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16579\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 113.10185, step = 2200 (85.782 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:37:39.791788 139860753180544 basic_session_run_hooks.py:247] loss = 113.10185, step = 2200 (85.782 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:39:05.643465 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16469\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 115.08159, step = 2300 (85.855 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:39:05.646320 139860753180544 basic_session_run_hooks.py:247] loss = 115.08159, step = 2300 (85.855 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:40:31.448582 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16543\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 112.150375, step = 2400 (85.812 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:40:31.458331 139860753180544 basic_session_run_hooks.py:247] loss = 112.150375, step = 2400 (85.812 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 2500 into ./test_output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:41:56.546056 139860753180544 basic_session_run_hooks.py:594] Saving checkpoints for 2500 into ./test_output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0516 00:42:04.517587 139860753180544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.04687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:42:06.971211 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.04687\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 113.534904, step = 2500 (95.522 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:42:06.980135 139860753180544 basic_session_run_hooks.py:247] loss = 113.534904, step = 2500 (95.522 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:43:33.071007 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16144\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 112.93633, step = 2600 (86.093 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:43:33.073606 139860753180544 basic_session_run_hooks.py:247] loss = 112.93633, step = 2600 (86.093 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:44:58.894537 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16518\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 112.70289, step = 2700 (85.827 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:44:58.900971 139860753180544 basic_session_run_hooks.py:247] loss = 112.70289, step = 2700 (85.827 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:46:24.551579 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16745\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 110.607605, step = 2800 (85.653 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:46:24.553966 139860753180544 basic_session_run_hooks.py:247] loss = 110.607605, step = 2800 (85.653 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:47:50.194120 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16764\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 112.87035, step = 2900 (85.643 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:47:50.196614 139860753180544 basic_session_run_hooks.py:247] loss = 112.87035, step = 2900 (85.643 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 3000 into ./test_output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:49:15.083055 139860753180544 basic_session_run_hooks.py:594] Saving checkpoints for 3000 into ./test_output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.04792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:49:25.621612 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.04792\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 111.735115, step = 3000 (95.437 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:49:25.633135 139860753180544 basic_session_run_hooks.py:247] loss = 111.735115, step = 3000 (95.437 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:50:51.662871 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16223\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 110.81381, step = 3100 (86.036 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:50:51.669227 139860753180544 basic_session_run_hooks.py:247] loss = 110.81381, step = 3100 (86.036 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16568\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:52:17.449705 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16568\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 112.22641, step = 3200 (85.788 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:52:17.456917 139860753180544 basic_session_run_hooks.py:247] loss = 112.22641, step = 3200 (85.788 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.1663\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:53:43.190685 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.1663\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 111.18647, step = 3300 (85.739 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:53:43.195559 139860753180544 basic_session_run_hooks.py:247] loss = 111.18647, step = 3300 (85.739 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 1.16543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:55:08.995791 139860753180544 basic_session_run_hooks.py:680] global_step/sec: 1.16543\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 116.59294, step = 3400 (85.803 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:55:08.998374 139860753180544 basic_session_run_hooks.py:247] loss = 116.59294, step = 3400 (85.803 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 3492 into ./test_output/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:56:27.093864 139860753180544 basic_session_run_hooks.py:594] Saving checkpoints for 3492 into ./test_output/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 112.06003.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:56:37.344464 139860753180544 estimator.py:359] Loss for final step: 112.06003.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training took time  0:52:26.942136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dFExnumOEgY",
        "colab_type": "code",
        "outputId": "75f3d3dd-a237-42b5-d3f5-d37a8e326f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        }
      },
      "source": [
        "eval_steps = int(len(df_test) / batch_size)\n",
        "eval_input_fn = input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=max_seq_length,\n",
        "    num_labels = num_labels,\n",
        "    is_training=False,\n",
        "    drop_remainder=True)\n",
        "result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:56:45.037169 139860753180544 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:56:48.758835 139860753180544 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor(\"module_apply_tokens/bert/pooler/dense/Tanh:0\", shape=(32, 768), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:56:48.877473 139860753180544 <ipython-input-14-03d076912b2b>:212] Tensor(\"module_apply_tokens/bert/pooler/dense/Tanh:0\", shape=(32, 768), dtype=float32)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:56:58.276544 139860753180544 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-16T00:56:58Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:56:58.302890 139860753180544 evaluation.py:257] Starting evaluation at 2019-05-16T00:56:58Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:57:00.377092 139860753180544 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0516 00:57:00.381582 139860753180544 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./test_output/model.ckpt-3492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:57:00.390501 139860753180544 saver.py:1270] Restoring parameters from ./test_output/model.ckpt-3492\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:57:02.901714 139860753180544 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:57:03.171465 139860753180544 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [45/450]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:57:17.995735 139860753180544 evaluation.py:169] Evaluation [45/450]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [90/450]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:57:31.682562 139860753180544 evaluation.py:169] Evaluation [90/450]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [135/450]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:57:45.764075 139860753180544 evaluation.py:169] Evaluation [135/450]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [180/450]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:57:59.490115 139860753180544 evaluation.py:169] Evaluation [180/450]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [225/450]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:58:12.867784 139860753180544 evaluation.py:169] Evaluation [225/450]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [270/450]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:58:26.060059 139860753180544 evaluation.py:169] Evaluation [270/450]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [315/450]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:58:39.270290 139860753180544 evaluation.py:169] Evaluation [315/450]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [360/450]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:58:52.660281 139860753180544 evaluation.py:169] Evaluation [360/450]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [405/450]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:59:06.237992 139860753180544 evaluation.py:169] Evaluation [405/450]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [450/450]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:59:19.806475 139860753180544 evaluation.py:169] Evaluation [450/450]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-05-16-00:59:20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:59:20.291541 139860753180544 evaluation.py:277] Finished evaluation at 2019-05-16-00:59:20\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 3492: auc0 = 0.98228854, auc1 = 0.97972816, auc2 = 0.9901888, auc3 = 0.64688843, auc4 = 0.98179, auc5 = 0.9209815, global_step = 3492, loss = 111.42505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:59:20.298499 139860753180544 estimator.py:1979] Saving dict for global step 3492: auc0 = 0.98228854, auc1 = 0.97972816, auc2 = 0.9901888, auc3 = 0.64688843, auc4 = 0.98179, auc5 = 0.9209815, global_step = 3492, loss = 111.42505\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3492: ./test_output/model.ckpt-3492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0516 00:59:22.897378 139860753180544 estimator.py:2039] Saving 'checkpoint_path' summary for global step 3492: ./test_output/model.ckpt-3492\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5B_xCGcxazj",
        "colab_type": "code",
        "outputId": "b505ee21-03ae-4df1-e913-f5c5db1e1a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "print(\"***** Eval results *****\")\n",
        "for key in sorted(result.keys()):\n",
        "  print('  {} = {}'.format(key, str(result[key])))\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Eval results *****\n",
            "  auc0 = 0.98228854\n",
            "  auc1 = 0.97972816\n",
            "  auc2 = 0.9901888\n",
            "  auc3 = 0.64688843\n",
            "  auc4 = 0.98179\n",
            "  auc5 = 0.9209815\n",
            "  global_step = 3492\n",
            "  loss = 111.42505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3LbhkBuhn83S",
        "colab": {}
      },
      "source": [
        "test_input_fn = input_fn_builder(\n",
        "    features=test_features, seq_length=max_seq_length, \n",
        "    num_labels = num_labels, is_training=False, drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEpP5kJQD9Ag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = estimator.predict(input_fn=test_input_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW94Qp_XXB4J",
        "colab_type": "code",
        "outputId": "e4db2c68-72c3-4a1f-cd70-07a136110f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4156
        }
      },
      "source": [
        "count = 0\n",
        "for i in preds:\n",
        "  print(i['prediction_mean'])\n",
        "  count+=1\n",
        "  if count>10:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0515 23:07:16.528932 140254083180416 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0515 23:07:20.021068 140254083180416 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor(\"module_apply_tokens/bert/pooler/dense/Tanh:0\", shape=(?, 768), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0515 23:07:20.153734 140254083180416 <ipython-input-14-03d076912b2b>:212] Tensor(\"module_apply_tokens/bert/pooler/dense/Tanh:0\", shape=(?, 768), dtype=float32)\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0515 23:07:30.500238 140254083180416 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0515 23:07:32.563863 140254083180416 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0515 23:07:32.571105 140254083180416 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./test_output/model.ckpt-1039\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0515 23:07:32.583526 140254083180416 saver.py:1270] Restoring parameters from ./test_output/model.ckpt-1039\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0515 23:07:35.473065 140254083180416 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0515 23:07:35.810457 140254083180416 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.03640676 0.01069544 0.00746595 0.01058346 0.01486148 0.01773299]\n",
            "comment_text      Why is Azerbaijan highlighted in the inset?\n",
            "toxic                                                       0\n",
            "severe_toxic                                                0\n",
            "obscene                                                     0\n",
            "threat                                                      0\n",
            "insult                                                      0\n",
            "identity_hate                                               0\n",
            "num_toxic_atts                                              0\n",
            "Name: 91072, dtype: object\n",
            "[0.03488696 0.01151568 0.00779048 0.01164709 0.01559253 0.0191257 ]\n",
            "comment_text      There is a virus called Krishna, and a virus c...\n",
            "toxic                                                             0\n",
            "severe_toxic                                                      0\n",
            "obscene                                                           0\n",
            "threat                                                            0\n",
            "insult                                                            0\n",
            "identity_hate                                                     0\n",
            "num_toxic_atts                                                    0\n",
            "Name: 33903, dtype: object\n",
            "[0.06348224 0.00918621 0.00813098 0.00823302 0.01637255 0.01492803]\n",
            "comment_text      You fake bastard.  This site is a fraud!\n",
            "toxic                                                    1\n",
            "severe_toxic                                             0\n",
            "obscene                                                  1\n",
            "threat                                                   0\n",
            "insult                                                   1\n",
            "identity_hate                                            0\n",
            "num_toxic_atts                                           3\n",
            "Name: 56057, dtype: object\n",
            "[0.9699742  0.0910514  0.8395487  0.0219038  0.70362294 0.06398666]\n",
            "comment_text      Block \\nOh shit I'm going to be blocked\n",
            "toxic                                                   1\n",
            "severe_toxic                                            0\n",
            "obscene                                                 1\n",
            "threat                                                  0\n",
            "insult                                                  0\n",
            "identity_hate                                           0\n",
            "num_toxic_atts                                          2\n",
            "Name: 90846, dtype: object\n",
            "[0.40168142 0.01133132 0.02755683 0.00679155 0.04565337 0.01627547]\n",
            "comment_text      fucking getting none, I hope you choke,\\nThere...\n",
            "toxic                                                             1\n",
            "severe_toxic                                                      1\n",
            "obscene                                                           1\n",
            "threat                                                            0\n",
            "insult                                                            1\n",
            "identity_hate                                                     0\n",
            "num_toxic_atts                                                    4\n",
            "Name: 91988, dtype: object\n",
            "[0.80015695 0.0175483  0.1022837  0.00778581 0.13343999 0.02570092]\n",
            "comment_text      . The world is better off without someone that...\n",
            "toxic                                                             1\n",
            "severe_toxic                                                      0\n",
            "obscene                                                           1\n",
            "threat                                                            0\n",
            "insult                                                            1\n",
            "identity_hate                                                     0\n",
            "num_toxic_atts                                                    3\n",
            "Name: 150158, dtype: object\n",
            "[0.93948346 0.03485718 0.38745978 0.01036328 0.3599617  0.03595755]\n",
            "comment_text      Muslim lover \\n\\nYou are scared of Islam.\n",
            "toxic                                                     1\n",
            "severe_toxic                                              0\n",
            "obscene                                                   0\n",
            "threat                                                    0\n",
            "insult                                                    0\n",
            "identity_hate                                             0\n",
            "num_toxic_atts                                            1\n",
            "Name: 31588, dtype: object\n",
            "[0.03468176 0.0112633  0.00764877 0.01130852 0.01528098 0.01873476]\n",
            "comment_text      Wikipedia Club of New York\\nCome see: Wikipedi...\n",
            "toxic                                                             0\n",
            "severe_toxic                                                      0\n",
            "obscene                                                           0\n",
            "threat                                                            0\n",
            "insult                                                            0\n",
            "identity_hate                                                     0\n",
            "num_toxic_atts                                                    0\n",
            "Name: 62863, dtype: object\n",
            "[0.9703223  0.1044488  0.8672389  0.02429819 0.7327242  0.06872555]\n",
            "comment_text      \"\\nIt was Raul's idea, but we all thought you ...\n",
            "toxic                                                             0\n",
            "severe_toxic                                                      0\n",
            "obscene                                                           0\n",
            "threat                                                            0\n",
            "insult                                                            0\n",
            "identity_hate                                                     0\n",
            "num_toxic_atts                                                    0\n",
            "Name: 1073, dtype: object\n",
            "[0.9631314  0.05712051 0.670987   0.0153032  0.55862176 0.04814564]\n",
            "comment_text      Sock puppet accusations now? Well, I have plen...\n",
            "toxic                                                             0\n",
            "severe_toxic                                                      0\n",
            "obscene                                                           0\n",
            "threat                                                            0\n",
            "insult                                                            0\n",
            "identity_hate                                                     0\n",
            "num_toxic_atts                                                    0\n",
            "Name: 72595, dtype: object\n",
            "[0.0352217  0.01092541 0.00751613 0.01097993 0.01505585 0.01833007]\n",
            "comment_text      3RR Noticeboard report here.\n",
            "toxic                                        0\n",
            "severe_toxic                                 0\n",
            "obscene                                      0\n",
            "threat                                       0\n",
            "insult                                       0\n",
            "identity_hate                                0\n",
            "num_toxic_atts                               0\n",
            "Name: 101150, dtype: object\n",
            "[0.03489668 0.01087136 0.00744746 0.01087005 0.01492102 0.01818551]\n",
            "comment_text      \"\\n\"\"Actually, Jarlaxle is right; that shit wa...\n",
            "toxic                                                             1\n",
            "severe_toxic                                                      0\n",
            "obscene                                                           1\n",
            "threat                                                            0\n",
            "insult                                                            1\n",
            "identity_hate                                                     0\n",
            "num_toxic_atts                                                    3\n",
            "Name: 44910, dtype: object\n",
            "[0.5046357  0.01219612 0.03621282 0.00674385 0.05650684 0.01734303]\n",
            "comment_text      Keith Olbermann \\n\\nthe material i put on ther...\n",
            "toxic                                                             0\n",
            "severe_toxic                                                      0\n",
            "obscene                                                           0\n",
            "threat                                                            0\n",
            "insult                                                            0\n",
            "identity_hate                                                     0\n",
            "num_toxic_atts                                                    0\n",
            "Name: 149521, dtype: object\n",
            "[0.03577296 0.0106637  0.0073699  0.01062476 0.01479804 0.01774942]\n",
            "comment_text      Television in Germany \\nYou're right, I forgot...\n",
            "toxic                                                             0\n",
            "severe_toxic                                                      0\n",
            "obscene                                                           0\n",
            "threat                                                            0\n",
            "insult                                                            0\n",
            "identity_hate                                                     0\n",
            "num_toxic_atts                                                    0\n",
            "Name: 77122, dtype: object\n",
            "[0.9372708  0.3199183  0.9268883  0.07867344 0.843397   0.15097825]\n",
            "comment_text      I would also support 195's view. You clearly t...\n",
            "toxic                                                             1\n",
            "severe_toxic                                                      0\n",
            "obscene                                                           0\n",
            "threat                                                            0\n",
            "insult                                                            1\n",
            "identity_hate                                                     0\n",
            "num_toxic_atts                                                    2\n",
            "Name: 58404, dtype: object\n",
            "[0.05677088 0.00919059 0.00779205 0.00841119 0.01566453 0.01504379]\n",
            "comment_text      \"The \"\"jobber\"\" had a name. Rory Fox to be exa...\n",
            "toxic                                                             1\n",
            "severe_toxic                                                      0\n",
            "obscene                                                           0\n",
            "threat                                                            0\n",
            "insult                                                            0\n",
            "identity_hate                                                     0\n",
            "num_toxic_atts                                                    1\n",
            "Name: 154995, dtype: object\n",
            "[0.92654955 0.34626603 0.9211335  0.09403756 0.83894026 0.16752061]\n",
            "comment_text      \"|decline=Please follow Yamla's instructions a...\n",
            "toxic                                                             0\n",
            "severe_toxic                                                      0\n",
            "obscene                                                           0\n",
            "threat                                                            0\n",
            "insult                                                            0\n",
            "identity_hate                                                     0\n",
            "num_toxic_atts                                                    0\n",
            "Name: 126579, dtype: object\n",
            "[0.03516793 0.01078963 0.00740017 0.01077922 0.01489199 0.0180095 ]\n",
            "comment_text      your time....\\n\\nYou suck because you are RIGH...\n",
            "toxic                                                             0\n",
            "severe_toxic                                                      0\n",
            "obscene                                                           1\n",
            "threat                                                            0\n",
            "insult                                                            1\n",
            "identity_hate                                                     0\n",
            "num_toxic_atts                                                    2\n",
            "Name: 44960, dtype: object\n",
            "[0.9670857  0.17269775 0.9227869  0.03396969 0.814501   0.0903395 ]\n",
            "comment_text      inconvIT IS I WHO WINS!enience\n",
            "toxic                                          0\n",
            "severe_toxic                                   0\n",
            "obscene                                        0\n",
            "threat                                         0\n",
            "insult                                         0\n",
            "identity_hate                                  0\n",
            "num_toxic_atts                                 0\n",
            "Name: 68920, dtype: object\n",
            "[0.03478748 0.01098232 0.00748203 0.01100462 0.01503345 0.01833464]\n",
            "comment_text      tight that guy will never find us\n",
            "toxic                                             0\n",
            "severe_toxic                                      0\n",
            "obscene                                           0\n",
            "threat                                            0\n",
            "insult                                            0\n",
            "identity_hate                                     0\n",
            "num_toxic_atts                                    0\n",
            "Name: 83544, dtype: object\n",
            "[0.96666574 0.06802229 0.7478748  0.0174964  0.62486064 0.05447393]\n",
            "comment_text      You \\n\\nSo, you delete my right to comment abo...\n",
            "toxic                                                             1\n",
            "severe_toxic                                                      0\n",
            "obscene                                                           0\n",
            "threat                                                            0\n",
            "insult                                                            0\n",
            "identity_hate                                                     0\n",
            "num_toxic_atts                                                    1\n",
            "Name: 27339, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XugnI3LwXcFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}