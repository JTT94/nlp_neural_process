{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/JTT94/nlp_neural_process/blob/master/Class_BERT_NeuralProcesses_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 94
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2395,
     "status": "ok",
     "timestamp": 1561566394397,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "SZKAwmizhzHo",
    "outputId": "edfb0e2d-46a8-4b2a-a68b-f94e9722aed4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import re\n",
    "\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import string\n",
    "from datetime import datetime \n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8783,
     "status": "ok",
     "timestamp": 1559675981247,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "pgB8X8dti3qc",
    "outputId": "07ec76ca-946b-413f-da17-d0b63f07a562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 24.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
      "Installing collected packages: bert-tensorflow\n",
      "Successfully installed bert-tensorflow-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-tensorflow\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31388,
     "status": "ok",
     "timestamp": 1561566427264,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "jDvh4JVNQFck",
    "outputId": "82e1aefb-9f85-43e3-b7e9-eff620c64907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6BzlNM53sIBp"
   },
   "outputs": [],
   "source": [
    "# output_directory = \"./gdrive/My Drive/Kaggle_toxic_comments/test_output\"\n",
    "output_directory = \"./test_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZCJDPOgQOsqJ"
   },
   "outputs": [],
   "source": [
    "# initialiase tensorboard \n",
    "# from https://stackoverflow.com/questions/47818822/can-i-use-tensorboard-with-google-colab\n",
    "\n",
    "\n",
    "# Get TensorBoard running in the background. \n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(output_directory)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5785,
     "status": "ok",
     "timestamp": 1559676017293,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "5sZ3Bl48oaxU",
    "outputId": "3f38c25a-90b4-4fb4-b9ed-42b93ca53b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-06-04 19:20:12--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
      "Resolving bin.equinox.io (bin.equinox.io)... 54.165.51.142, 54.173.32.212, 34.206.36.121, ...\n",
      "Connecting to bin.equinox.io (bin.equinox.io)|54.165.51.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16648024 (16M) [application/octet-stream]\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
      "\n",
      "ngrok-stable-linux- 100%[===================>]  15.88M  8.61MB/s    in 1.8s    \n",
      "\n",
      "2019-06-04 19:20:15 (8.61 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [16648024/16648024]\n",
      "\n",
      "Archive:  ngrok-stable-linux-amd64.zip\n",
      "  inflating: ngrok                   \n"
     ]
    }
   ],
   "source": [
    "# # #Download and unzip ngrok. \n",
    "!test -e ngrok-stable-linux-amd64.zip || wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!test -e ngrok || unzip ngrok-stable-linux-amd64.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mLp9PmAzoWhE"
   },
   "outputs": [],
   "source": [
    "# #Launch ngrok background process...\n",
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2482,
     "status": "ok",
     "timestamp": 1559676020489,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "eL1A1ibjOwnL",
    "outputId": "72d62bd9-1eab-4f48-9945-f57cf9ff987a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://3eaa4c13.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3542,
     "status": "ok",
     "timestamp": 1559676024413,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "bweIS72l5WS5",
    "outputId": "198e1df5-29d6-4ea5-f5bd-4c9906113963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'neural_process'...\n",
      "remote: Enumerating objects: 137, done.\u001b[K\n",
      "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
      "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
      "remote: Total 137 (delta 84), reused 132 (delta 79), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (137/137), 734.33 KiB | 1.05 MiB/s, done.\n",
      "Resolving deltas: 100% (84/84), done.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append('../') # add personal code dir to path for import\n",
    "\n",
    "\n",
    "!test -d neural_process || git clone https://github.com/JTT94/nlp_neural_process.git neural_process\n",
    "sys.path.append('./neural_process/')\n",
    "\n",
    "import random\n",
    "from neural_process import split_context_target, NeuralProcessParams\n",
    "from neural_process.network import *\n",
    "from neural_process.loss import *\n",
    "from neural_process.predict import *\n",
    "from neural_process.process import *\n",
    "\n",
    "from neural_process.tf_model_builder_AUC import *\n",
    "from neural_process.bert_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 94
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3211,
     "status": "ok",
     "timestamp": 1559676026230,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "69MNF4fEi5Ly",
    "outputId": "87065e62-1afd-459c-ca76-d2586c74c23b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "K.tensorflow_backend._get_available_gpus()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cc1rwgOZi9F1"
   },
   "outputs": [],
   "source": [
    "# # filename = './cleaned_data.csv'\n",
    "# filename = './gdrive/My Drive/Oxford/RAIL/Jigsaw/Technical Team/toxic_comments/Data/data1.csv'\n",
    "# df = pd.read_csv(filename, index_col=0)\n",
    "# cols = ['comment','antagonize', 'condescending', 'dismissive', 'generalisation', 'hostile', 'sarcastic']\n",
    "# # cols = ['comment','cleaned_comment','antagonize', 'condescending', 'dismissive', 'generalisation', 'hostile', 'sarcastic', 'healthy']\n",
    "# df = df[cols]\n",
    "\n",
    "# score_column = ['antagonize', 'condescending', 'dismissive', 'generalisation', 'hostile', 'sarcastic']\n",
    "# # text_col_name = 'cleaned_comment'\n",
    "# text_col_name = 'comment'\n",
    "\n",
    "# df_train = df.sample(frac = 0.8)\n",
    "# df_test = df[~df.isin(df_train)].dropna()\n",
    "\n",
    "# df_train[score_column] = df_train[score_column].round()\n",
    "# df_test[score_column] = df_test[score_column].round()\n",
    "# #--------\n",
    "\n",
    "# # ### For kaggle dataset\n",
    "\n",
    "## Training data\n",
    "\n",
    "# filename = './gdrive/My Drive/Data/train.csv'\n",
    "train_filename = './gdrive/My Drive/Kaggle_toxic_comments/kaggle_train.csv'\n",
    "\n",
    "df = pd.read_csv(train_filename)\n",
    "cols = ['comment_text','toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "df = df[cols]\n",
    "\n",
    "score_column = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "text_col_name = 'comment_text'\n",
    "\n",
    "#Cast to float - because scores and labels need to be concattenated in the model function, and so need to be same type\n",
    "for i in score_column:\n",
    "  df[i] = pd.to_numeric(df[i],downcast='float')\n",
    "\n",
    "df_train = df[df.comment_text.str.len() <= 250]\n",
    "  \n",
    "# ## over represent toxic comments\n",
    "\n",
    "# df['num_toxic_atts'] = df[cols[1:]].apply(lambda x: np.sum(x), axis = 1)\n",
    "\n",
    "# df_toxic = df[df.num_toxic_atts  > 0]\n",
    "# # print(len(df_toxic))\n",
    "\n",
    "# df_healthy_sample = df[df.num_toxic_atts == 0].sample(frac=1.0)[:len(df_toxic)]\n",
    "# # print(len(df_healthy_sample))\n",
    "\n",
    "# df_train = pd.concat([df_toxic, df_healthy_sample]).sample(frac=1.0)\n",
    "\n",
    "\n",
    "## Test data:\n",
    "\n",
    "test_data_filename = './gdrive/My Drive/Kaggle_toxic_comments/kaggle_test.csv'\n",
    "test_labels_filename = './gdrive/My Drive/Kaggle_toxic_comments/kaggle_test_labels.csv'\n",
    "test_df = pd.read_csv(test_data_filename)\n",
    "test_labels = pd.read_csv(test_labels_filename)\n",
    "test_df = pd.merge(test_df, test_labels, on='id')\n",
    "#get rid of -1 values\n",
    "test_df = test_df.replace(-1, np.nan).dropna(subset=cols)\n",
    "\n",
    "#restrict comment length\n",
    "test_df = test_df[test_df.comment_text.str.len() <= 250]\n",
    "\n",
    "test_df = test_df[cols]\n",
    "#Cast to float - because scores and labels need to be concattenated in the model function, and so need to be same type\n",
    "for i in score_column:\n",
    "    test_df[i] = pd.to_numeric(test_df[i],downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i2roS1iGnUvH"
   },
   "outputs": [],
   "source": [
    "# data = pd.concat([df_train,test_df])\n",
    "\n",
    "# data =  data.sample(frac = 1.0)\n",
    "\n",
    "# msk = np.random.rand(len(data)) < 0.8\n",
    "\n",
    "# train = data[msk]\n",
    "\n",
    "# temp = data[~msk]\n",
    "\n",
    "# msk2 = np.random.rand(len(temp)) <= 0.5\n",
    "\n",
    "# val = temp[msk2]\n",
    "\n",
    "# test = temp[~msk2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "coSxH1Vgnw_H"
   },
   "outputs": [],
   "source": [
    "# train.to_csv(\"train_kaggle.csv\")\n",
    "# test.to_csv(\"test_kaggle.csv\")\n",
    "# val.to_csv(\"val_kaggle.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p_JIbqhY55L_"
   },
   "outputs": [],
   "source": [
    "df_train['num_toxic_atts'] = df_train[cols[1:]].apply(lambda x: np.sum(x), axis = 1)\n",
    "\n",
    "df_toxic = df_train[df_train.num_toxic_atts  > 0]\n",
    "\n",
    "df_toxic = pd.concat([df_toxic, df_toxic, df_toxic]).reset_index(drop=True)\n",
    "\n",
    "df_non_toxic = df_train[~df_train.isin(df_toxic)].dropna()\n",
    "\n",
    "df_train = pd.concat([df_non_toxic, df_toxic]).sample(frac = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11931,
     "status": "ok",
     "timestamp": 1559676048535,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "mUIe15uTi9Ok",
    "outputId": "8dd02076-ae76-41fc-cd94-5d94079d7a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 19:20:45.703840 139889894938496 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:20:47.792265 139889894938496 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_model_hub = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "tokenizer = create_tokenizer_from_hub_module(BERT_model_hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jECyqGRfyht4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IVESPLmgl98I"
   },
   "outputs": [],
   "source": [
    "# #Pre process data for bert embedding\n",
    "max_seq_length = 128\n",
    "\n",
    "import pickle\n",
    "\n",
    "# train_input_examples = create_examples(df_train.sample(100), score_column, text_col_name)\n",
    "# # # test_input_examples = create_examples(df_test, score_column, text_col_name)\n",
    "\n",
    "# train_features = convert_examples_to_features(train_input_examples, max_seq_length, tokenizer)\n",
    "# # # test_features = convert_examples_to_features(test_input_examples, max_seq_length, tokenizer)\n",
    "\n",
    "# pickle.dump(train_features, open('./gdrive/My Drive/Kaggle_toxic_comments/train_features.p', 'wb'))\n",
    "# # pickle.dump(test_features, open('./gdrive/My Drive/Kaggle_toxic_comments/test_features.p', 'wb'))\n",
    "\n",
    "# # ## Load features previously saved\n",
    "# train_features = pickle.load(open('./gdrive/My Drive/Kaggle_toxic_comments/train_features.p', 'rb'))\n",
    "# test_features = pickle.load(open('./gdrive/My Drive/Kaggle_toxic_comments/train_features.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wOdj6CWiPYSX"
   },
   "outputs": [],
   "source": [
    "# utility methods\n",
    "from collections import namedtuple\n",
    "NeuralProcessParams = namedtuple('NeuralProcessParams', ['dim_z', 'n_hidden_units_h', 'n_hidden_units_g'])\n",
    "GaussianParams = namedtuple('GaussianParams', ['mu', 'sigma'])\n",
    "\n",
    "\n",
    "def batch_mlp(input, inner_layer_dims, output_dim, variable_scope):\n",
    "  \"\"\"Apply MLP to the final axis of a 3D tensor (reusing already defined MLPs).\n",
    "  \n",
    "  Args:\n",
    "    input: input tensor of shape [B,n,d_in].\n",
    "    output_sizes: An iterable containing the output sizes of the MLP as defined \n",
    "        in `basic.Linear`.\n",
    "    variable_scope: String giving the name of the variable scope. If this is set\n",
    "        to be the same as a previously defined MLP, then the weights are reused.\n",
    "    \n",
    "  Returns:\n",
    "    tensor of shape [B,n,d_out] where d_out=output_sizes[-1]\n",
    "  \"\"\"\n",
    "  # Get the shapes of the input and reshape to parallelise across observations\n",
    "\n",
    "  output = input\n",
    "\n",
    "  \n",
    "  # Pass through MLP\n",
    "  with tf.variable_scope(variable_scope, reuse=tf.AUTO_REUSE):\n",
    "    for i, size in enumerate(inner_layer_dims):\n",
    "      output = tf.nn.relu(\n",
    "          tf.layers.dense(output, size, name=\"layer_{}\".format(i)))\n",
    "\n",
    "    # Last layer without a ReLu\n",
    "    output = tf.layers.dense(output, output_dim, name=\"layer_{}\".format(i + 1))\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_gK0D7AhoLK"
   },
   "outputs": [],
   "source": [
    "# class Embedder(object):\n",
    "  \n",
    "#   def __init__(self, BERT_model_hub = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\", trainable=True):\n",
    "#     self.BERT_model_hub = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "#     self.tokenizer = create_tokenizer_from_hub_module(BERT_model_hub)\n",
    "#     self.trainable = trainable\n",
    "    \n",
    "#   def __call__(self, input_ids, input_mask, segment_ids):\n",
    "#     embedder = hub.Module(self.BERT_model_hub,trainable=self.trainable)\n",
    "#     bert_inputs = dict(input_ids=input_ids,\n",
    "#                        input_mask=input_mask, \n",
    "#                        segment_ids=segment_ids)\n",
    "\n",
    "#     bert_outputs = embedder(inputs=bert_inputs,\n",
    "#                                signature=\"tokens\", \n",
    "#                                as_dict=True)\n",
    "    \n",
    "#   # Use \"pooled_output\" for classification tasks on an entire sentence. Use \"sequence_outputs\" for token-level output\n",
    "#     return bert_outputs[\"pooled_output\"]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2HMqLmD8PTEP"
   },
   "outputs": [],
   "source": [
    "class Decoder(object):\n",
    "  \"\"\"The Decoder.\"\"\"\n",
    "\n",
    "  def __init__(self, layer_dims, num_classes):\n",
    "    self.layer_dims = layer_dims\n",
    "    self.num_classes = num_classes\n",
    "    \n",
    "  def __call__(self, input_xs_embedding, z_samples):\n",
    "  \n",
    "        # inputs dimensions\n",
    "    # z_sample has dim [n_draws, dim_z]\n",
    "    # x_star has dim [N_star, dim_x]\n",
    "    n_draws = z_samples.get_shape().as_list()[0]\n",
    "    n_xs = tf.shape(input_xs_embedding)[0]\n",
    "\n",
    "    # Repeat z samples for each x*\n",
    "    #z_samples_repeat = tf.expand_dims(z_samples, axis=1)\n",
    "\n",
    "    #z_samples_repeat = tf.expand_dims(z_samples, axis=1)\n",
    "    z_samples_repeat = tf.tile(z_samples, [1, n_xs, 1])\n",
    "\n",
    "    # Repeat x* for each z sample\n",
    "    x_star_repeat = tf.expand_dims(input_xs_embedding, axis=0)\n",
    "    x_star_repeat = tf.tile(x_star_repeat, [n_draws, 1, 1])\n",
    "\n",
    "    # Concatenate x* and z\n",
    "    inputs = tf.concat([x_star_repeat, z_samples_repeat], axis=2)\n",
    "\n",
    "    # decoder mlp\n",
    "    inner_layer_dims = self.layer_dims\n",
    "    output_dim = self.num_classes *2\n",
    "    hidden = batch_mlp(inputs, inner_layer_dims, output_dim, \"decoder\")\n",
    "\n",
    "    # Get the mean an the variance\n",
    "    mu, log_sigma = tf.split(hidden, 2, axis= -1)\n",
    "\n",
    "    # Bound the variance\n",
    "    sigma_star = 0.1 + 0.9 * tf.nn.softplus(log_sigma)\n",
    "    mu_star = tf.math.sigmoid(mu)\n",
    "\n",
    "\n",
    "    return GaussianParams(mu_star, sigma_star)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6DmGdqzaGjS"
   },
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "\n",
    "  def __init__(self, layer_dims, latent_dim):\n",
    "    self.layer_dims = layer_dims\n",
    "    self.latent_dim = latent_dim\n",
    "    \n",
    "  def __call__(self, xs, ys):\n",
    "    print(xs)\n",
    "    print(ys)\n",
    "    xys = tf.concat([xs, ys], axis=1)\n",
    "\n",
    "\n",
    "    # encoder mlp\n",
    "    inner_layer_dims = self.layer_dims[:-1]\n",
    "    output_dim = self.layer_dims[-1]\n",
    "    rs = batch_mlp(xys, inner_layer_dims, output_dim, \"encoder\")\n",
    "    \n",
    "    # aggregate rs\n",
    "    r = self._aggregate_r(rs)\n",
    "    \n",
    "    # get mu and sigma\n",
    "    z_params = self._get_z_params(r)\n",
    "    \n",
    "    # distribution\n",
    "    dist = tfd.MultivariateNormalDiag(loc=z_params.mu,\n",
    "                                          scale_diag=z_params.sigma)\n",
    "    return dist\n",
    "    \n",
    "  def _aggregate_r(self, context_rs: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Aggregate the output of the encoder to a single representation\n",
    "\n",
    "    Creates an aggregation (mean) operator to combine the encodings of multiple context inputs\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    context_rs\n",
    "        Input encodings tensor, shape: (n_samples, dim_r)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Output tensor of aggregation result\n",
    "    \"\"\"\n",
    "    mean = tf.reduce_mean(context_rs, axis=0)\n",
    "    r = tf.reshape(mean, [1, -1])\n",
    "    return r\n",
    "  \n",
    "  def _get_z_params(self, context_r: tf.Tensor) -> GaussianParams:\n",
    "    \"\"\"Map encoding to mean and covariance of the random variable Z\n",
    "\n",
    "    Creates a linear dense layer to map encoding to mu_z, and another linear mapping + a softplus activation for Sigma_z\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    context_r\n",
    "        Input encoding tensor, shape: (1, dim_r)\n",
    "    params\n",
    "        Neural process parameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        Output tensors of the mappings for mu_z and Sigma_z\n",
    "    \"\"\"\n",
    "    hidden = context_r\n",
    "    with tf.variable_scope(\"latent_encoder\", reuse=tf.AUTO_REUSE):\n",
    "      # First apply intermediate relu layer \n",
    "      hidden = tf.nn.relu(\n",
    "          tf.layers.dense(hidden, \n",
    "                          (self.layer_dims[-1] + self.latent_dim)/2, \n",
    "                          name=\"penultimate_layer\"))\n",
    "      \n",
    "      # Then apply further linear layers to output latent mu and log sigma\n",
    "      mu = tf.layers.dense(hidden, self.latent_dim, name=\"mean_layer\")\n",
    "      log_sigma = tf.layers.dense(hidden, self.latent_dim, name=\"std_layer\")\n",
    "      \n",
    "\n",
    "    # Compute sigma\n",
    "    sigma = 0.1 + 0.9 * tf.sigmoid(log_sigma)\n",
    "\n",
    "    return GaussianParams(mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LWZZAs1haFkc"
   },
   "outputs": [],
   "source": [
    "class NLP_NeuralProcess(object):\n",
    "  \n",
    "  def __init__(self,\n",
    "                  score_col, \n",
    "                  params = NeuralProcessParams(dim_z=20, \n",
    "                                                     n_hidden_units_h=[128, 128, 128], \n",
    "                                                     n_hidden_units_g=[128, 128, 128]),\n",
    "                  num_classes = 6, \n",
    "                  num_draws = 2, \n",
    "                  lr = 2e-5,\n",
    "                  batch_size = 32, \n",
    "                  num_warmup_steps=100,\n",
    "                  num_train_steps = 10**3,\n",
    "                  save_summary_steps = 100,\n",
    "                  save_checkpoints_steps = 500,\n",
    "                  output_dir = \"./test_output\",\n",
    "                  context_features = None\n",
    "                 ):\n",
    "    \n",
    "    self.params = params\n",
    "    self.encoder = Encoder(layer_dims = self.params.n_hidden_units_h, \n",
    "                           latent_dim=self.params.dim_z)\n",
    "    self.decoder = Decoder(layer_dims= self.params.n_hidden_units_g, \n",
    "                           num_classes=num_classes)\n",
    "    self.num_draws = num_draws\n",
    "    self.num_classes = num_classes\n",
    "#     self.estimator = None\n",
    "    #self.embedder = Embedder()\n",
    "    #####  \n",
    "    num_labels = len(score_col)\n",
    "    \n",
    "    \n",
    "    # Specify outpit directory and number of checkpoint steps to save\n",
    "    \n",
    "    run_config = tf.estimator.RunConfig(model_dir=output_dir,\n",
    "          save_summary_steps=save_summary_steps, save_checkpoints_steps=save_checkpoints_steps)\n",
    "    \n",
    "    model_fn = self.model_fn_builder(num_labels = num_labels, learning_rate=lr,\n",
    "      num_train_steps=num_train_steps, num_warmup_steps=num_warmup_steps)\n",
    "    \n",
    "    if context_features is not None:\n",
    "      estimator_params = {\"batch_size\": batch_size, \"context_features\": context_features}\n",
    "      self.estimator = tf.estimator.Estimator(model_fn=model_fn,config=run_config,\n",
    "                                              params=estimator_params)\n",
    "    \n",
    "    else: \n",
    "      self.estimator = tf.estimator.Estimator(model_fn=model_fn,config=run_config,\n",
    "            params={\"batch_size\": batch_size})\n",
    "    \n",
    "    \n",
    "  def create_model(self, \n",
    "                   target_input_ids, \n",
    "                   target_input_mask, \n",
    "                   target_segment_ids, \n",
    "                   target_scores=None,\n",
    "                   context_input_ids = None, \n",
    "                   context_input_mask = None, \n",
    "                   context_segment_ids= None, \n",
    "                   context_scores = None\n",
    "                   ):\n",
    "    \n",
    "    # apply embedder\n",
    "    embedder = hub.Module(BERT_model_hub,trainable=True)\n",
    "    \n",
    "    valid_context = (context_input_ids is not None) & (context_input_mask is not None) & (context_segment_ids is not None) & (context_scores is not None)\n",
    "    \n",
    "    # target processing - all scenarios\n",
    "    target_inputs = dict(input_ids=target_input_ids,\n",
    "                     input_mask=target_input_mask, \n",
    "                     segment_ids=target_segment_ids)\n",
    "    target_embeddings = embedder(inputs=target_inputs,\n",
    "                               signature=\"tokens\", \n",
    "                               as_dict=True)\n",
    "    target_xs = target_embeddings[\"pooled_output\"]\n",
    "    \n",
    "    \n",
    "    if valid_context:\n",
    "      \n",
    "      # context processing - training\n",
    "      context_inputs = dict(input_ids=context_input_ids,\n",
    "                         input_mask=context_input_mask, \n",
    "                         segment_ids=context_segment_ids)\n",
    "      context_embeddings = embedder(inputs=context_inputs,\n",
    "                                 signature=\"tokens\", \n",
    "                                 as_dict=True)\n",
    "      context_xs = context_embeddings[\"pooled_output\"]\n",
    "      context_ys = context_scores\n",
    "      # total x,y \n",
    "      x_all = tf.concat([context_xs, target_xs], axis=0)\n",
    "      \n",
    "      # get encoding params with context\n",
    "      context_z_dist = self.encoder(context_xs, context_ys)\n",
    "      # predictions with context\n",
    "      posterior_pred = self.decoder(target_xs, context_z_dist.sample(self.num_draws))\n",
    "        \n",
    "       # target scores - context training / evaluation\n",
    "      if target_scores is not None:\n",
    "        target_ys = target_scores\n",
    "        y_all = tf.concat([context_ys, target_ys], axis=0)\n",
    "        all_z_dist = self.encoder(x_all, y_all)\n",
    "        \n",
    "        # loss\n",
    "        loglike = self.loglikelihood(target_ys, posterior_pred)\n",
    "        KL_loss = self.KLqp_gaussian(all_z_dist.parameters['loc'], \n",
    "                                     all_z_dist.parameters['scale_diag'], \n",
    "                                     context_z_dist.parameters['loc'], \n",
    "                                     context_z_dist.parameters['scale_diag'])\n",
    "        loss = tf.negative(loglike) + KL_loss\n",
    "        # context and training / evaluation\n",
    "        return (loss, posterior_pred, target_ys)\n",
    "      \n",
    "      # context prediction\n",
    "      return  (None, posterior_pred, None)\n",
    "    \n",
    "    # no context\n",
    "    else:\n",
    "      x_all = target_xs \n",
    "      # get internal representation\n",
    "      mean_zero = tf.constant(np.repeat(0., params.dim_z))\n",
    "      epsilon_dist = tfd.MultivariateNormalDiag(loc= mean_zero)                            \n",
    "      epsilon = tf.expand_dims(epsilon_dist.sample(self.num_draws), axis=1)\n",
    "      epsilon = tf.cast(epsilon, tf.float32)\n",
    "      prior_predict = self.decoder(x_all, epsilon)\n",
    "      \n",
    "      # target scores - no context training / evaluation\n",
    "      if target_scores is not None:\n",
    "        target_ys = target_scores\n",
    "        loglike = self.loglikelihood(target_ys, prior_predict)\n",
    "        loss = tf.negative(loglike)\n",
    "        # no context/ training / evaluation\n",
    "        return  (loss, prior_predict, target_ys)\n",
    "   \n",
    "    \n",
    "      # no context prediction\n",
    "      return  (None, prior_predict, None)\n",
    "\n",
    "  \n",
    "  def loglikelihood(self, y_star: tf.Tensor, dist):\n",
    "    \"\"\"Log-likelihood of an output given a predicted \"\"\"\n",
    "    p_normal = tfd.MultivariateNormalDiag(loc = dist.mu, scale_diag=dist.sigma)\n",
    "    loglike = p_normal.log_prob(y_star)\n",
    "    loglike = tf.reduce_sum(loglike, axis=0)\n",
    "    loglike = tf.reduce_mean(loglike)\n",
    "    return loglike\n",
    "  \n",
    "  def KLqp_gaussian(self, mu_q: tf.Tensor, sigma_q: tf.Tensor, mu_p: tf.Tensor, sigma_p: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"Kullback-Leibler divergence between two Gaussian distributions\n",
    "\n",
    "    Determines KL(q || p) = < log( q / p ) >_q\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mu_q\n",
    "        Mean tensor of distribution q, shape: (1, dim)\n",
    "    sigma_q\n",
    "        Variance tensor of distribution q, shape: (1, dim)\n",
    "    mu_p\n",
    "        Mean tensor of distribution p, shape: (1, dim)\n",
    "    sigma_p\n",
    "        Variance tensor of distribution p, shape: (1, dim)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        KL tensor, shape: (1)\n",
    "    \"\"\"\n",
    "    sigma2_q = tf.square(sigma_q) + 1e-16\n",
    "    sigma2_p = tf.square(sigma_p) + 1e-16\n",
    "    temp = sigma2_q / sigma2_p + tf.square(mu_q - mu_p) / sigma2_p - 1.0 + tf.log(sigma2_p / sigma2_q + 1e-16)\n",
    "    return 0.5 * tf.reduce_sum(temp)\n",
    "  \n",
    "  def context_target_split(self, batch_size =32):\n",
    "    btch_sz = batch_size\n",
    "    n_context = tf.random_shuffle(tf.range(1,btch_sz))[0]\n",
    "    \n",
    "    indices = tf.range(0, btch_sz)\n",
    "    context_set_indices = tf.gather(tf.random_shuffle(indices),tf.range(n_context))\n",
    "    target_set_indices = tf.gather(tf.random_shuffle(indices),tf.range(n_context, btch_sz))\n",
    "    \n",
    "    return context_set_indices, target_set_indices\n",
    "    \n",
    "  def model_fn_builder(self, num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
    "      \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "      \n",
    "      \n",
    "      def model_fn(features, mode, params):  # pylint: disable=unused-argument\n",
    "          \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "          \n",
    "          # run model\n",
    "          # -------------------------------------------------------------------------------------------\n",
    "          target_input_ids = None\n",
    "          target_input_mask = None\n",
    "          target_segment_ids = None \n",
    "          target_scores = None\n",
    "          \n",
    "          context_input_ids = None \n",
    "          context_input_mask = None \n",
    "          context_segment_ids = None\n",
    "          context_scores = None\n",
    "          \n",
    "          # training \n",
    "          if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            input_ids = features[\"input_ids\"]\n",
    "            input_mask = features[\"input_mask\"]\n",
    "            segment_ids = features[\"segment_ids\"]    \n",
    "            scores = features[\"scores\"]\n",
    "            \n",
    "            # context split\n",
    "            context_set_indices, target_set_indices= self.context_target_split(batch_size =32)\n",
    "            \n",
    "            target_input_ids = tf.gather(input_ids,target_set_indices)\n",
    "            target_input_mask = tf.gather(input_mask,target_set_indices)\n",
    "            target_segment_ids = tf.gather(segment_ids,target_set_indices) \n",
    "            target_scores = tf.gather(scores,target_set_indices)\n",
    "\n",
    "            context_input_ids = tf.gather(input_ids,context_set_indices) \n",
    "            context_input_mask = tf.gather(input_mask,context_set_indices) \n",
    "            context_segment_ids = tf.gather(segment_ids,context_set_indices)\n",
    "            context_scores = tf.gather(scores,context_set_indices)\n",
    "            \n",
    "            \n",
    "          elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            print('Prediction')\n",
    "            target_input_ids = features[\"input_ids\"]\n",
    "            target_input_mask = features[\"input_mask\"]\n",
    "            target_segment_ids = features[\"segment_ids\"]    \n",
    "            target_scores = features[\"scores\"]\n",
    "            \n",
    "            try:\n",
    "              context_input_ids = features[\"supplied_context_input_ids\"][0]\n",
    "              context_input_mask = features[\"supplied_context_input_mask\"][0]\n",
    "              context_segment_ids = features[\"supplied_context_segment_ids\"][0] \n",
    "              context_scores = features[\"supplied_context_scores\"][0]\n",
    "               \n",
    "            except:\n",
    "              print(\"****No context supplied ****\")\n",
    "              context_input_ids = None\n",
    "              context_input_mask = None\n",
    "              context_segment_ids = None\n",
    "              context_scores = None\n",
    "            \n",
    "          else:\n",
    "            print('Evaluation')\n",
    "            target_input_ids = features[\"input_ids\"]\n",
    "            target_input_mask = features[\"input_mask\"]\n",
    "            target_segment_ids = features[\"segment_ids\"]    \n",
    "            target_scores = features[\"scores\"]\n",
    "\n",
    "            try:\n",
    "              context_input_ids = features[\"supplied_context_input_ids\"][0]\n",
    "              context_input_mask = features[\"supplied_context_input_mask\"][0]\n",
    "              context_segment_ids = features[\"supplied_context_segment_ids\"][0] \n",
    "              context_scores = features[\"supplied_context_scores\"][0]\n",
    "               \n",
    "            except:\n",
    "              print(\"****No context supplied ****\")\n",
    "              context_input_ids = None\n",
    "              context_input_mask = None\n",
    "              context_segment_ids = None\n",
    "              context_scores = None\n",
    "\n",
    "\n",
    "          (loss, prediction, true_y) = self.create_model(target_input_ids, \n",
    "                                                         target_input_mask, \n",
    "                                                         target_segment_ids, \n",
    "                                                         target_scores,\n",
    "                                                         context_input_ids, \n",
    "                                                         context_input_mask, \n",
    "                                                         context_segment_ids, \n",
    "                                                         context_scores)\n",
    "\n",
    "          train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "          ystar, _ = tf.nn.moments(prediction.mu,[0])\n",
    "          variance, _ = tf.nn.moments(tf.math.square(prediction.sigma),[0])\n",
    "          \n",
    "          # Calculate evaluation metrics\n",
    "          eval_metrics = {}\n",
    "          # AUC\n",
    "          def metric_fn(pred_scores, real_scores, trait_num):\n",
    "              auc_value = tf.metrics.auc(real_scores[:,trait_num], pred_scores[:,trait_num])\n",
    "              accuracy_value = tf.metrics.accuracy(labels = tf.round(real_scores[:,trait_num]), predictions=tf.round(pred_scores[:,trait_num]))\n",
    "              recall_value = tf.metrics.recall(labels = tf.round(real_scores[:,trait_num]), predictions=tf.round(pred_scores[:,trait_num]))\n",
    "              precision_value = tf.metrics.precision(labels = tf.round(real_scores[:,trait_num]), predictions=tf.round(pred_scores[:,trait_num]))\n",
    "              return {\"auc\"+str(trait_num): auc_value, \"accuracy\"+str(trait_num): accuracy_value, \"recall\"+str(trait_num): recall_value, \"precision\"+str(trait_num):precision_value}\n",
    "\n",
    "          labels = true_y # need to round them if true labels are not 1 or 0\n",
    "          eval_metrics_lst = [metric_fn(ystar, labels, trait_num) for trait_num in range(num_labels)]\n",
    "\n",
    "          for d in eval_metrics_lst:\n",
    "              tf.summary.scalar(list(d.keys())[0], list(d.values())[0][1])  # make available to tensorboard\n",
    "              tf.summary.scalar(list(d.keys())[1], list(d.values())[1][1])  # make available to tensorboard\n",
    "              eval_metrics.update(d)\n",
    "              \n",
    "          \n",
    "          # output from model\n",
    "          # -------------------------------------------------------------------------------------------\n",
    "\n",
    "          # training \n",
    "          if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "              return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "          # prediction\n",
    "          elif mode == tf.estimator.ModeKeys.PREDICT:\n",
    "              return tf.estimator.EstimatorSpec(mode=mode, predictions={'prediction_mean': ystar, 'prediction_var': variance})\n",
    "\n",
    "          # evaluation\n",
    "          else:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode,loss=loss, eval_metric_ops=eval_metrics)\n",
    "\n",
    "      return model_fn\n",
    "\n",
    "\n",
    "  def prepare_examples(self, df, score_column, text_col_name, supplied_context_df=None):\n",
    "      num_labels = len(score_column)\n",
    "      input_examples = create_examples(df, score_column, text_col_name)\n",
    "      input_features = convert_examples_to_features(input_examples, max_seq_length, tokenizer)\n",
    "      \n",
    "      if supplied_context_df is not None:\n",
    "        supplied_context_examples = create_examples(supplied_context_df, score_column, text_col_name)\n",
    "        supplied_context_features = convert_examples_to_features(supplied_context_examples, max_seq_length, tokenizer)\n",
    "        input_fn = input_fn_builder(\n",
    "          features=input_features, seq_length=max_seq_length, \n",
    "          num_labels = num_labels, is_training=True, drop_remainder=False,\n",
    "          supplied_context_features = supplied_context_features)\n",
    "      \n",
    "      else:\n",
    "        input_fn = input_fn_builder(\n",
    "          features=input_features, seq_length=max_seq_length, \n",
    "          num_labels = num_labels, is_training=True, drop_remainder=False)\n",
    "        \n",
    "      return input_fn\n",
    "  \n",
    "  def predict(self, \n",
    "            df, \n",
    "            score_col, \n",
    "            text_col,\n",
    "            supplied_context_df=None\n",
    "             ):\n",
    "    \n",
    "    pred_input_fn = self.prepare_examples(df, score_col, text_col, supplied_context_df)\n",
    "    preds = self.estimator.predict(input_fn=pred_input_fn)\n",
    "    \n",
    "    return preds\n",
    "  \n",
    "  def evaluate(self, \n",
    "               eval_steps,\n",
    "               df, \n",
    "               score_col, \n",
    "               text_col,\n",
    "               supplied_context_df=None):\n",
    "    \n",
    "    eval_input_fn = self.prepare_examples(df, score_col, text_col, supplied_context_df)\n",
    "    \n",
    "    result = self.estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
    "    return result\n",
    "  \n",
    "  def train(self,num_train_steps,\n",
    "            df_train, \n",
    "            score_col, \n",
    "            text_col,\n",
    "           ):\n",
    "\n",
    "    # Create an input function for training. drop_remainder = True for using TPUs.\n",
    "    train_input_fn = self.prepare_examples(df_train, score_col, text_col)\n",
    "\n",
    "    print('Beginning Training!')\n",
    "    current_time = datetime.now()\n",
    "    self.estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "    print(\"Training took time \", datetime.now() - current_time)\n",
    "    \n",
    "  \n",
    "  def train_and_evaluate(self,\n",
    "                         df_train,\n",
    "                         df_eval,\n",
    "                         score_col, \n",
    "                         text_col,\n",
    "                         num_train_steps,\n",
    "                         eval_steps,\n",
    "                         supplied_context_df=None):\n",
    "    \n",
    "    train_input_fn = self.prepare_examples(df_train, score_col, text_col)\n",
    "    eval_input_fn = self.prepare_examples(df_eval, score_col, text_col, supplied_context_df)\n",
    "    \n",
    "    train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "    eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, steps = eval_steps)\n",
    "    \n",
    "    result = tf.estimator.train_and_evaluate(self.estimator, train_spec, eval_spec)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7741,
     "status": "ok",
     "timestamp": 1559676049727,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "Z8iSEczc6NS1",
    "outputId": "5810c995-03f8-4d7e-9290-1d0b0398439d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './test_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3a24209780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:20:49.305683 139889894938496 estimator.py:201] Using config: {'_model_dir': './test_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3a24209780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tf.reset_default_graph()\n",
    "\n",
    "params = NeuralProcessParams(dim_z=600, n_hidden_units_h=[512, 256, 128], n_hidden_units_g=[512, 256, 128])\n",
    "num_train_steps = 6*(10**3)\n",
    "\n",
    "neural_process = NLP_NeuralProcess(score_col=score_column, params = params, num_draws = 20, \n",
    "                                   num_train_steps=num_train_steps,\n",
    "                                   num_classes = len(score_column),\n",
    "                                   output_dir = output_directory,\n",
    "                                  context_features = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 10266
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1911119,
     "status": "error",
     "timestamp": 1559681663767,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "-3t1yb4RrW5y",
    "outputId": "90a9604e-8a10-4b07-b19d-c033feba5985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:21:20.975353 139889894938496 estimator_training.py:185] Not using Distribute Coordinator.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:21:20.980995 139889894938496 training.py:610] Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 500 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:21:20.983616 139889894938496 training.py:698] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 500 or save_checkpoints_secs None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:21:35.024450 139889894938496 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:21:38.299519 139889894938496 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:21:38.914088 139889894938496 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"module_apply_tokens_1/bert/pooler/dense/Tanh:0\", shape=(?, 768), dtype=float32)\n",
      "Tensor(\"GatherV2_9:0\", shape=(?, 6), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-15-504275df30f7>:28: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 19:21:39.032094 139889894938496 deprecation.py:323] From <ipython-input-15-504275df30f7>:28: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat:0\", shape=(?, 768), dtype=float32)\n",
      "Tensor(\"concat_3:0\", shape=(?, 6), dtype=float32)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 19:21:39.820533 139889894938496 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 19:21:39.938756 139889894938496 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 19:21:52.445916 139889894938496 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:21:54.084609 139889894938496 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:21:54.087929 139889894938496 basic_session_run_hooks.py:527] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:21:58.896272 139889894938496 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:22:04.293217 139889894938496 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:22:04.612394 139889894938496 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:22:25.748345 139889894938496 basic_session_run_hooks.py:594] Saving checkpoints for 0 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 107.359245, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:22:48.140210 139889894938496 basic_session_run_hooks.py:249] loss = 107.359245, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.928128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:24:35.883260 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 0.928128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 59.226818, step = 100 (107.746 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:24:35.885802 139889894938496 basic_session_run_hooks.py:247] loss = 59.226818, step = 100 (107.746 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:26:02.277719 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.15748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -17.105982, step = 200 (86.396 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:26:02.282071 139889894938496 basic_session_run_hooks.py:247] loss = -17.105982, step = 200 (86.396 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:27:28.440451 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 18.520756, step = 300 (86.161 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:27:28.442601 139889894938496 basic_session_run_hooks.py:247] loss = 18.520756, step = 300 (86.161 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:28:54.587314 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 25.85622, step = 400 (86.150 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:28:54.592143 139889894938496 basic_session_run_hooks.py:247] loss = 25.85622, step = 400 (86.150 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 500 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:30:20.016486 139889894938496 basic_session_run_hooks.py:594] Saving checkpoints for 500 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:30:34.659070 139889894938496 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n",
      "****No context supplied ****\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:30:37.194020 139889894938496 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:30:48.471154 139889894938496 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-04T19:30:48Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:30:48.497553 139889894938496 evaluation.py:257] Starting evaluation at 2019-06-04T19:30:48Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:30:50.079175 139889894938496 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 19:30:50.090380 139889894938496 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./test_output/model.ckpt-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:30:50.096839 139889894938496 saver.py:1270] Restoring parameters from ./test_output/model.ckpt-500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:30:52.348905 139889894938496 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:30:52.623677 139889894938496 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [18/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:30:59.346693 139889894938496 evaluation.py:169] Evaluation [18/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [36/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:04.545999 139889894938496 evaluation.py:169] Evaluation [36/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [54/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:09.817250 139889894938496 evaluation.py:169] Evaluation [54/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [72/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:15.191000 139889894938496 evaluation.py:169] Evaluation [72/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:20.646640 139889894938496 evaluation.py:169] Evaluation [90/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [108/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:26.137515 139889894938496 evaluation.py:169] Evaluation [108/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [126/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:31.620012 139889894938496 evaluation.py:169] Evaluation [126/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [144/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:36.995284 139889894938496 evaluation.py:169] Evaluation [144/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [162/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:42.299166 139889894938496 evaluation.py:169] Evaluation [162/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [180/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:47.548905 139889894938496 evaluation.py:169] Evaluation [180/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [188/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:49.865605 139889894938496 evaluation.py:169] Evaluation [188/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-04-19:31:50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:50.368528 139889894938496 evaluation.py:277] Finished evaluation at 2019-06-04-19:31:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 500: accuracy0 = 0.94714093, accuracy1 = 0.9177194, accuracy2 = 0.9552859, accuracy3 = 0.95894283, accuracy4 = 0.9757314, accuracy5 = 0.94980055, auc0 = 0.8265211, auc1 = 0.77663845, auc2 = 0.82256985, auc3 = 0.8705586, auc4 = 0.68704534, auc5 = 0.5914797, global_step = 500, loss = -24.793327, precision0 = 0.18354431, precision1 = 0.2392638, precision2 = 0.18343195, precision3 = 0.14736842, precision4 = 0.0, precision5 = 0.0, recall0 = 0.13302752, recall1 = 0.24, recall2 = 0.19135803, recall3 = 0.24778761, recall4 = 0.0, recall5 = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:50.370552 139889894938496 estimator.py:1979] Saving dict for global step 500: accuracy0 = 0.94714093, accuracy1 = 0.9177194, accuracy2 = 0.9552859, accuracy3 = 0.95894283, accuracy4 = 0.9757314, accuracy5 = 0.94980055, auc0 = 0.8265211, auc1 = 0.77663845, auc2 = 0.82256985, auc3 = 0.8705586, auc4 = 0.68704534, auc5 = 0.5914797, global_step = 500, loss = -24.793327, precision0 = 0.18354431, precision1 = 0.2392638, precision2 = 0.18343195, precision3 = 0.14736842, precision4 = 0.0, precision5 = 0.0, recall0 = 0.13302752, recall1 = 0.24, recall2 = 0.19135803, recall3 = 0.24778761, recall4 = 0.0, recall5 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 500: ./test_output/model.ckpt-500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:52.900394 139889894938496 estimator.py:2039] Saving 'checkpoint_path' summary for global step 500: ./test_output/model.ckpt-500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.558029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:53.789319 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 0.558029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -45.72812, step = 500 (179.200 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:31:53.791681 139889894938496 basic_session_run_hooks.py:247] loss = -45.72812, step = 500 (179.200 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:33:19.898699 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 130.16965, step = 600 (86.109 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:33:19.900964 139889894938496 basic_session_run_hooks.py:247] loss = 130.16965, step = 600 (86.109 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:34:46.181379 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.15898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -37.705444, step = 700 (86.283 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:34:46.183514 139889894938496 basic_session_run_hooks.py:247] loss = -37.705444, step = 700 (86.283 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:36:12.397265 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.15988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 46.849293, step = 800 (86.218 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:36:12.401517 139889894938496 basic_session_run_hooks.py:247] loss = 46.849293, step = 800 (86.218 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.1591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:37:38.670893 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.1591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -0.481853, step = 900 (86.273 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:37:38.674862 139889894938496 basic_session_run_hooks.py:247] loss = -0.481853, step = 900 (86.273 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:39:04.090753 139889894938496 basic_session_run_hooks.py:594] Saving checkpoints for 1000 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:39:14.220579 139889894938496 training.py:525] Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.03648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:39:15.150981 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.03648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 39.10353, step = 1000 (96.483 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:39:15.157550 139889894938496 basic_session_run_hooks.py:247] loss = 39.10353, step = 1000 (96.483 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:40:41.617286 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.15652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -15.550628, step = 1100 (86.462 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:40:41.619701 139889894938496 basic_session_run_hooks.py:247] loss = -15.550628, step = 1100 (86.462 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:42:07.795472 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -42.941463, step = 1200 (86.178 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:42:07.797912 139889894938496 basic_session_run_hooks.py:247] loss = -42.941463, step = 1200 (86.178 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:43:34.242368 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.15678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -72.98556, step = 1300 (86.450 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:43:34.247525 139889894938496 basic_session_run_hooks.py:247] loss = -72.98556, step = 1300 (86.450 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:45:00.509819 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.15919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -71.59181, step = 1400 (86.268 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:45:00.515392 139889894938496 basic_session_run_hooks.py:247] loss = -71.59181, step = 1400 (86.268 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1500 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:46:25.822616 139889894938496 basic_session_run_hooks.py:594] Saving checkpoints for 1500 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:46:39.213756 139889894938496 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n",
      "****No context supplied ****\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:46:43.107285 139889894938496 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:46:53.611540 139889894938496 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-04T19:46:53Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:46:53.637343 139889894938496 evaluation.py:257] Starting evaluation at 2019-06-04T19:46:53Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:46:55.189572 139889894938496 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./test_output/model.ckpt-1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:46:55.199151 139889894938496 saver.py:1270] Restoring parameters from ./test_output/model.ckpt-1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:46:57.485363 139889894938496 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:46:57.779283 139889894938496 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [18/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:04.610999 139889894938496 evaluation.py:169] Evaluation [18/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [36/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:09.774615 139889894938496 evaluation.py:169] Evaluation [36/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [54/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:15.011963 139889894938496 evaluation.py:169] Evaluation [54/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [72/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:20.328463 139889894938496 evaluation.py:169] Evaluation [72/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:25.714370 139889894938496 evaluation.py:169] Evaluation [90/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [108/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:31.153222 139889894938496 evaluation.py:169] Evaluation [108/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [126/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:36.628984 139889894938496 evaluation.py:169] Evaluation [126/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [144/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:42.054547 139889894938496 evaluation.py:169] Evaluation [144/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [162/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:47.404889 139889894938496 evaluation.py:169] Evaluation [162/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [180/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:52.689916 139889894938496 evaluation.py:169] Evaluation [180/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [188/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:55.022649 139889894938496 evaluation.py:169] Evaluation [188/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-04-19:47:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:55.513634 139889894938496 evaluation.py:277] Finished evaluation at 2019-06-04-19:47:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1500: accuracy0 = 0.9399933, accuracy1 = 0.91389626, accuracy2 = 0.9406583, accuracy3 = 0.94232047, accuracy4 = 0.9709109, accuracy5 = 0.94980055, auc0 = 0.82356364, auc1 = 0.7880245, auc2 = 0.80898416, auc3 = 0.8640425, auc4 = 0.7364898, auc5 = 0.7537992, global_step = 1500, loss = -52.353516, precision0 = 0.2, precision1 = 0.250646, precision2 = 0.18649517, precision3 = 0.14589666, precision4 = 0.22950819, precision5 = 0.0, recall0 = 0.21363637, recall1 = 0.29846153, recall2 = 0.3580247, recall3 = 0.42105263, recall4 = 0.09859155, recall5 = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:55.515805 139889894938496 estimator.py:1979] Saving dict for global step 1500: accuracy0 = 0.9399933, accuracy1 = 0.91389626, accuracy2 = 0.9406583, accuracy3 = 0.94232047, accuracy4 = 0.9709109, accuracy5 = 0.94980055, auc0 = 0.82356364, auc1 = 0.7880245, auc2 = 0.80898416, auc3 = 0.8640425, auc4 = 0.7364898, auc5 = 0.7537992, global_step = 1500, loss = -52.353516, precision0 = 0.2, precision1 = 0.250646, precision2 = 0.18649517, precision3 = 0.14589666, precision4 = 0.22950819, precision5 = 0.0, recall0 = 0.21363637, recall1 = 0.29846153, recall2 = 0.3580247, recall3 = 0.42105263, recall4 = 0.09859155, recall5 = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1500: ./test_output/model.ckpt-1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:55.522167 139889894938496 estimator.py:2039] Saving 'checkpoint_path' summary for global step 1500: ./test_output/model.ckpt-1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.568615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:56.375821 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 0.568615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -74.704506, step = 1500 (175.864 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:47:56.379551 139889894938496 basic_session_run_hooks.py:247] loss = -74.704506, step = 1500 (175.864 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:49:22.536027 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -91.34171, step = 1600 (86.163 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:49:22.542131 139889894938496 basic_session_run_hooks.py:247] loss = -91.34171, step = 1600 (86.163 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:50:48.852035 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.15853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -146.83464, step = 1700 (86.315 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:50:48.857150 139889894938496 basic_session_run_hooks.py:247] loss = -146.83464, step = 1700 (86.315 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:52:15.013378 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -82.96082, step = 1800 (86.161 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:52:15.018506 139889894938496 basic_session_run_hooks.py:247] loss = -82.96082, step = 1800 (86.161 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:53:41.213388 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -137.29788, step = 1900 (86.201 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:53:41.219928 139889894938496 basic_session_run_hooks.py:247] loss = -137.29788, step = 1900 (86.201 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2000 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:55:06.369157 139889894938496 basic_session_run_hooks.py:594] Saving checkpoints for 2000 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:55:17.207159 139889894938496 training.py:525] Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.03183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:55:18.128196 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.03183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -124.44159, step = 2000 (96.913 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:55:18.132847 139889894938496 basic_session_run_hooks.py:247] loss = -124.44159, step = 2000 (96.913 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:56:44.691257 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.15523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -96.44942, step = 2100 (86.563 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:56:44.696115 139889894938496 basic_session_run_hooks.py:247] loss = -96.44942, step = 2100 (86.563 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:58:10.948468 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.15932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -127.955376, step = 2200 (86.258 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:58:10.954082 139889894938496 basic_session_run_hooks.py:247] loss = -127.955376, step = 2200 (86.258 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:59:37.146058 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -92.23769, step = 2300 (86.196 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 19:59:37.150250 139889894938496 basic_session_run_hooks.py:247] loss = -92.23769, step = 2300 (86.196 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:01:03.221367 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 13.642399, step = 2400 (86.076 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:01:03.225787 139889894938496 basic_session_run_hooks.py:247] loss = 13.642399, step = 2400 (86.076 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2500 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:02:28.688776 139889894938496 basic_session_run_hooks.py:594] Saving checkpoints for 2500 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0604 20:02:36.936998 139889894938496 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:02:42.129847 139889894938496 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n",
      "****No context supplied ****\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:02:45.960917 139889894938496 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:02:57.087125 139889894938496 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-04T20:02:57Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:02:57.111583 139889894938496 evaluation.py:257] Starting evaluation at 2019-06-04T20:02:57Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:02:58.668933 139889894938496 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./test_output/model.ckpt-2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:02:58.674827 139889894938496 saver.py:1270] Restoring parameters from ./test_output/model.ckpt-2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:00.912652 139889894938496 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:01.182118 139889894938496 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [18/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:07.947972 139889894938496 evaluation.py:169] Evaluation [18/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [36/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:13.140027 139889894938496 evaluation.py:169] Evaluation [36/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [54/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:18.405444 139889894938496 evaluation.py:169] Evaluation [54/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [72/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:23.742589 139889894938496 evaluation.py:169] Evaluation [72/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:29.145504 139889894938496 evaluation.py:169] Evaluation [90/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [108/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:34.627344 139889894938496 evaluation.py:169] Evaluation [108/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [126/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:40.112055 139889894938496 evaluation.py:169] Evaluation [126/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [144/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:45.563747 139889894938496 evaluation.py:169] Evaluation [144/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [162/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:50.918604 139889894938496 evaluation.py:169] Evaluation [162/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [180/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:56.206192 139889894938496 evaluation.py:169] Evaluation [180/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [188/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:58.541533 139889894938496 evaluation.py:169] Evaluation [188/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-04-20:03:59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:59.041839 139889894938496 evaluation.py:277] Finished evaluation at 2019-06-04-20:03:59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2500: accuracy0 = 0.9468085, accuracy1 = 0.92303854, accuracy2 = 0.9517952, accuracy3 = 0.93583775, accuracy4 = 0.9662567, accuracy5 = 0.9416556, auc0 = 0.75679517, auc1 = 0.7549548, auc2 = 0.7398867, auc3 = 0.8316534, auc4 = 0.719854, auc5 = 0.7485982, global_step = 2500, loss = -32.502316, precision0 = 0.20879121, precision1 = 0.24911033, precision2 = 0.18571429, precision3 = 0.12465374, precision4 = 0.21551724, precision5 = 0.26262626, recall0 = 0.17757009, recall1 = 0.2173913, recall2 = 0.24683544, recall3 = 0.39130434, recall4 = 0.18248175, recall5 = 0.08552632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:59.047585 139889894938496 estimator.py:1979] Saving dict for global step 2500: accuracy0 = 0.9468085, accuracy1 = 0.92303854, accuracy2 = 0.9517952, accuracy3 = 0.93583775, accuracy4 = 0.9662567, accuracy5 = 0.9416556, auc0 = 0.75679517, auc1 = 0.7549548, auc2 = 0.7398867, auc3 = 0.8316534, auc4 = 0.719854, auc5 = 0.7485982, global_step = 2500, loss = -32.502316, precision0 = 0.20879121, precision1 = 0.24911033, precision2 = 0.18571429, precision3 = 0.12465374, precision4 = 0.21551724, precision5 = 0.26262626, recall0 = 0.17757009, recall1 = 0.2173913, recall2 = 0.24683544, recall3 = 0.39130434, recall4 = 0.18248175, recall5 = 0.08552632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2500: ./test_output/model.ckpt-2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:59.050809 139889894938496 estimator.py:2039] Saving 'checkpoint_path' summary for global step 2500: ./test_output/model.ckpt-2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:59.899650 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 0.566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -71.851524, step = 2500 (176.677 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:03:59.902708 139889894938496 basic_session_run_hooks.py:247] loss = -71.851524, step = 2500 (176.677 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:05:25.857712 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -88.71646, step = 2600 (85.960 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:05:25.863063 139889894938496 basic_session_run_hooks.py:247] loss = -88.71646, step = 2600 (85.960 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:06:51.969422 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -89.09877, step = 2700 (86.111 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:06:51.974220 139889894938496 basic_session_run_hooks.py:247] loss = -89.09877, step = 2700 (86.111 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:08:18.289761 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.15848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -117.43649, step = 2800 (86.321 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:08:18.295144 139889894938496 basic_session_run_hooks.py:247] loss = -117.43649, step = 2800 (86.321 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:09:44.381963 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -131.53374, step = 2900 (86.089 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:09:44.384534 139889894938496 basic_session_run_hooks.py:247] loss = -131.53374, step = 2900 (86.089 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 3000 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:11:09.655610 139889894938496 basic_session_run_hooks.py:594] Saving checkpoints for 3000 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:11:19.913519 139889894938496 training.py:525] Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.03683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:11:20.829836 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.03683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -28.444672, step = 3000 (96.450 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:11:20.834090 139889894938496 basic_session_run_hooks.py:247] loss = -28.444672, step = 3000 (96.450 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:12:47.072541 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.15952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -141.42183, step = 3100 (86.244 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:12:47.078087 139889894938496 basic_session_run_hooks.py:247] loss = -141.42183, step = 3100 (86.244 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:14:13.246713 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -90.7361, step = 3200 (86.174 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:14:13.251813 139889894938496 basic_session_run_hooks.py:247] loss = -90.7361, step = 3200 (86.174 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:15:39.237654 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -123.73179, step = 3300 (85.991 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:15:39.242970 139889894938496 basic_session_run_hooks.py:247] loss = -123.73179, step = 3300 (85.991 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.1607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:17:05.392781 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.1607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -115.691635, step = 3400 (86.153 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:17:05.395834 139889894938496 basic_session_run_hooks.py:247] loss = -115.691635, step = 3400 (86.153 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 3500 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:18:30.792919 139889894938496 basic_session_run_hooks.py:594] Saving checkpoints for 3500 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:18:44.320158 139889894938496 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n",
      "****No context supplied ****\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:18:46.824793 139889894938496 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:18:58.650402 139889894938496 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-04T20:18:58Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:18:58.674842 139889894938496 evaluation.py:257] Starting evaluation at 2019-06-04T20:18:58Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:19:00.236696 139889894938496 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./test_output/model.ckpt-3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:19:00.245359 139889894938496 saver.py:1270] Restoring parameters from ./test_output/model.ckpt-3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:19:02.520678 139889894938496 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:19:02.810255 139889894938496 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [18/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:19:09.627564 139889894938496 evaluation.py:169] Evaluation [18/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [36/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:19:14.835637 139889894938496 evaluation.py:169] Evaluation [36/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [54/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:19:20.118399 139889894938496 evaluation.py:169] Evaluation [54/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [72/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:19:25.484584 139889894938496 evaluation.py:169] Evaluation [72/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:19:30.937356 139889894938496 evaluation.py:169] Evaluation [90/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [108/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:19:36.423364 139889894938496 evaluation.py:169] Evaluation [108/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [126/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:19:41.915210 139889894938496 evaluation.py:169] Evaluation [126/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [144/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:19:47.312397 139889894938496 evaluation.py:169] Evaluation [144/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [162/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:19:52.630457 139889894938496 evaluation.py:169] Evaluation [162/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [180/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:19:57.889063 139889894938496 evaluation.py:169] Evaluation [180/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [188/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:20:00.214558 139889894938496 evaluation.py:169] Evaluation [188/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-04-20:20:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:20:00.726195 139889894938496 evaluation.py:277] Finished evaluation at 2019-06-04-20:20:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 3500: accuracy0 = 0.9438165, accuracy1 = 0.9037567, accuracy2 = 0.9375, accuracy3 = 0.93168217, accuracy4 = 0.96692157, accuracy5 = 0.93450797, auc0 = 0.73169374, auc1 = 0.76373726, auc2 = 0.7652887, auc3 = 0.7953891, auc4 = 0.7063984, auc5 = 0.75008386, global_step = 3500, loss = -6.1171823, precision0 = 0.19072165, precision1 = 0.21681416, precision2 = 0.15555556, precision3 = 0.12626262, precision4 = 0.20588236, precision5 = 0.23121387, recall0 = 0.16972478, recall1 = 0.30340558, recall2 = 0.3081761, recall3 = 0.4347826, recall4 = 0.15107913, recall5 = 0.13289036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:20:00.729730 139889894938496 estimator.py:1979] Saving dict for global step 3500: accuracy0 = 0.9438165, accuracy1 = 0.9037567, accuracy2 = 0.9375, accuracy3 = 0.93168217, accuracy4 = 0.96692157, accuracy5 = 0.93450797, auc0 = 0.73169374, auc1 = 0.76373726, auc2 = 0.7652887, auc3 = 0.7953891, auc4 = 0.7063984, auc5 = 0.75008386, global_step = 3500, loss = -6.1171823, precision0 = 0.19072165, precision1 = 0.21681416, precision2 = 0.15555556, precision3 = 0.12626262, precision4 = 0.20588236, precision5 = 0.23121387, recall0 = 0.16972478, recall1 = 0.30340558, recall2 = 0.3081761, recall3 = 0.4347826, recall4 = 0.15107913, recall5 = 0.13289036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3500: ./test_output/model.ckpt-3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:20:00.732041 139889894938496 estimator.py:2039] Saving 'checkpoint_path' summary for global step 3500: ./test_output/model.ckpt-3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.567586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:20:01.577539 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 0.567586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -71.545074, step = 3500 (176.185 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:20:01.581307 139889894938496 basic_session_run_hooks.py:247] loss = -71.545074, step = 3500 (176.185 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:21:27.743329 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -99.284805, step = 3600 (86.166 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:21:27.747251 139889894938496 basic_session_run_hooks.py:247] loss = -99.284805, step = 3600 (86.166 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:22:53.900810 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -114.596, step = 3700 (86.159 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:22:53.905988 139889894938496 basic_session_run_hooks.py:247] loss = -114.596, step = 3700 (86.159 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:24:19.916440 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -124.50805, step = 3800 (86.015 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:24:19.920526 139889894938496 basic_session_run_hooks.py:247] loss = -124.50805, step = 3800 (86.015 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:25:46.053450 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -115.4265, step = 3900 (86.137 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:25:46.058008 139889894938496 basic_session_run_hooks.py:247] loss = -115.4265, step = 3900 (86.137 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4000 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:27:11.444943 139889894938496 basic_session_run_hooks.py:594] Saving checkpoints for 4000 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:27:21.988122 139889894938496 training.py:525] Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.03243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:27:22.912914 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.03243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -101.997314, step = 4000 (96.860 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:27:22.918355 139889894938496 basic_session_run_hooks.py:247] loss = -101.997314, step = 4000 (96.860 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.1568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:28:49.357802 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.1568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -127.48932, step = 4100 (86.445 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:28:49.363401 139889894938496 basic_session_run_hooks.py:247] loss = -127.48932, step = 4100 (86.445 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:30:15.626388 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.15917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -81.11632, step = 4200 (86.269 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:30:15.632074 139889894938496 basic_session_run_hooks.py:247] loss = -81.11632, step = 4200 (86.269 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.1614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:31:41.729341 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.1614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -123.79896, step = 4300 (86.100 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:31:41.731745 139889894938496 basic_session_run_hooks.py:247] loss = -123.79896, step = 4300 (86.100 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:33:07.790082 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -166.03474, step = 4400 (86.066 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:33:07.797986 139889894938496 basic_session_run_hooks.py:247] loss = -166.03474, step = 4400 (86.066 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4500 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:34:33.083384 139889894938496 basic_session_run_hooks.py:594] Saving checkpoints for 4500 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:34:46.628257 139889894938496 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n",
      "****No context supplied ****\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:34:50.538311 139889894938496 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:01.046731 139889894938496 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-04T20:35:01Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:01.075299 139889894938496 evaluation.py:257] Starting evaluation at 2019-06-04T20:35:01Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:02.657479 139889894938496 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./test_output/model.ckpt-4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:02.669821 139889894938496 saver.py:1270] Restoring parameters from ./test_output/model.ckpt-4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:04.972535 139889894938496 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:05.260256 139889894938496 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [18/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:12.060771 139889894938496 evaluation.py:169] Evaluation [18/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [36/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:17.217961 139889894938496 evaluation.py:169] Evaluation [36/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [54/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:22.474373 139889894938496 evaluation.py:169] Evaluation [54/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [72/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:27.809761 139889894938496 evaluation.py:169] Evaluation [72/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:33.212095 139889894938496 evaluation.py:169] Evaluation [90/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [108/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:38.683418 139889894938496 evaluation.py:169] Evaluation [108/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [126/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:44.174587 139889894938496 evaluation.py:169] Evaluation [126/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [144/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:49.621975 139889894938496 evaluation.py:169] Evaluation [144/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [162/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:35:54.981829 139889894938496 evaluation.py:169] Evaluation [162/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [180/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:36:00.281072 139889894938496 evaluation.py:169] Evaluation [180/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [188/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:36:02.627762 139889894938496 evaluation.py:169] Evaluation [188/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-04-20:36:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:36:03.160846 139889894938496 evaluation.py:277] Finished evaluation at 2019-06-04-20:36:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 4500: accuracy0 = 0.9481383, accuracy1 = 0.9112367, accuracy2 = 0.94763964, accuracy3 = 0.94348407, accuracy4 = 0.9679189, accuracy5 = 0.9371675, auc0 = 0.69479233, auc1 = 0.74048144, auc2 = 0.77493364, auc3 = 0.8198751, auc4 = 0.72625214, auc5 = 0.7169095, global_step = 4500, loss = 1.7332213, precision0 = 0.20625, precision1 = 0.24189526, precision2 = 0.18067227, precision3 = 0.1335505, precision4 = 0.20879121, precision5 = 0.23333333, recall0 = 0.15137614, recall1 = 0.29663607, recall2 = 0.2638037, recall3 = 0.35652173, recall4 = 0.13571429, recall5 = 0.11744966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:36:03.162950 139889894938496 estimator.py:1979] Saving dict for global step 4500: accuracy0 = 0.9481383, accuracy1 = 0.9112367, accuracy2 = 0.94763964, accuracy3 = 0.94348407, accuracy4 = 0.9679189, accuracy5 = 0.9371675, auc0 = 0.69479233, auc1 = 0.74048144, auc2 = 0.77493364, auc3 = 0.8198751, auc4 = 0.72625214, auc5 = 0.7169095, global_step = 4500, loss = 1.7332213, precision0 = 0.20625, precision1 = 0.24189526, precision2 = 0.18067227, precision3 = 0.1335505, precision4 = 0.20879121, precision5 = 0.23333333, recall0 = 0.15137614, recall1 = 0.29663607, recall2 = 0.2638037, recall3 = 0.35652173, recall4 = 0.13571429, recall5 = 0.11744966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4500: ./test_output/model.ckpt-4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:36:03.175182 139889894938496 estimator.py:2039] Saving 'checkpoint_path' summary for global step 4500: ./test_output/model.ckpt-4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.56744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:36:04.020130 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 0.56744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -122.51836, step = 4500 (176.227 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:36:04.024848 139889894938496 basic_session_run_hooks.py:247] loss = -122.51836, step = 4500 (176.227 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:37:30.072317 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -134.2246, step = 4600 (86.055 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:37:30.079783 139889894938496 basic_session_run_hooks.py:247] loss = -134.2246, step = 4600 (86.055 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.1604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:38:56.249700 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.1604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -120.637024, step = 4700 (86.174 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:38:56.254199 139889894938496 basic_session_run_hooks.py:247] loss = -120.637024, step = 4700 (86.174 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:40:22.569998 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.15848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -156.49518, step = 4800 (86.323 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:40:22.577004 139889894938496 basic_session_run_hooks.py:247] loss = -156.49518, step = 4800 (86.323 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:41:48.707811 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -84.06723, step = 4900 (86.135 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:41:48.711769 139889894938496 basic_session_run_hooks.py:247] loss = -84.06723, step = 4900 (86.135 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 5000 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:43:14.022058 139889894938496 basic_session_run_hooks.py:594] Saving checkpoints for 5000 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:43:24.481699 139889894938496 training.py:525] Skip the current checkpoint eval due to throttle secs (600 secs).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.0343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:43:25.391335 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.0343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -144.61467, step = 5000 (96.685 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:43:25.397099 139889894938496 basic_session_run_hooks.py:247] loss = -144.61467, step = 5000 (96.685 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.15839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:44:51.718019 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.15839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -165.62206, step = 5100 (86.324 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:44:51.720566 139889894938496 basic_session_run_hooks.py:247] loss = -165.62206, step = 5100 (86.324 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:46:17.777957 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -152.2628, step = 5200 (86.064 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:46:17.784752 139889894938496 basic_session_run_hooks.py:247] loss = -152.2628, step = 5200 (86.064 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:47:43.920818 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -123.01092, step = 5300 (86.140 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:47:43.925541 139889894938496 basic_session_run_hooks.py:247] loss = -123.01092, step = 5300 (86.140 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:49:09.925764 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -112.48731, step = 5400 (86.010 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:49:09.934448 139889894938496 basic_session_run_hooks.py:247] loss = -112.48731, step = 5400 (86.010 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 5500 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:50:35.228325 139889894938496 basic_session_run_hooks.py:594] Saving checkpoints for 5500 into ./test_output/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:50:48.761100 139889894938496 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n",
      "****No context supplied ****\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:50:52.723087 139889894938496 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:03.260675 139889894938496 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-06-04T20:51:03Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:03.289554 139889894938496 evaluation.py:257] Starting evaluation at 2019-06-04T20:51:03Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:04.858136 139889894938496 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./test_output/model.ckpt-5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:04.871365 139889894938496 saver.py:1270] Restoring parameters from ./test_output/model.ckpt-5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:07.138919 139889894938496 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:07.422452 139889894938496 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [18/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:14.230380 139889894938496 evaluation.py:169] Evaluation [18/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [36/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:19.411385 139889894938496 evaluation.py:169] Evaluation [36/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [54/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:24.664474 139889894938496 evaluation.py:169] Evaluation [54/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [72/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:29.986959 139889894938496 evaluation.py:169] Evaluation [72/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [90/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:35.370489 139889894938496 evaluation.py:169] Evaluation [90/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [108/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:40.789952 139889894938496 evaluation.py:169] Evaluation [108/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [126/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:46.230926 139889894938496 evaluation.py:169] Evaluation [126/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [144/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:51.609284 139889894938496 evaluation.py:169] Evaluation [144/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [162/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:51:56.932075 139889894938496 evaluation.py:169] Evaluation [162/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [180/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:52:02.214010 139889894938496 evaluation.py:169] Evaluation [180/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [188/188]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:52:04.543467 139889894938496 evaluation.py:169] Evaluation [188/188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-06-04-20:52:05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:52:05.061331 139889894938496 evaluation.py:277] Finished evaluation at 2019-06-04-20:52:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 5500: accuracy0 = 0.9517952, accuracy1 = 0.9296875, accuracy2 = 0.95578456, accuracy3 = 0.93866354, accuracy4 = 0.9690825, accuracy5 = 0.94365025, auc0 = 0.6296212, auc1 = 0.71084654, auc2 = 0.7366374, auc3 = 0.79354906, auc4 = 0.6973097, auc5 = 0.69466585, global_step = 5500, loss = 34.294395, precision0 = 0.21969697, precision1 = 0.26291078, precision2 = 0.18562874, precision3 = 0.10769231, precision4 = 0.22093023, precision5 = 0.27906978, recall0 = 0.13425925, recall1 = 0.17391305, recall2 = 0.19254659, recall3 = 0.30701753, recall4 = 0.13768116, recall5 = 0.07973422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:52:05.063560 139889894938496 estimator.py:1979] Saving dict for global step 5500: accuracy0 = 0.9517952, accuracy1 = 0.9296875, accuracy2 = 0.95578456, accuracy3 = 0.93866354, accuracy4 = 0.9690825, accuracy5 = 0.94365025, auc0 = 0.6296212, auc1 = 0.71084654, auc2 = 0.7366374, auc3 = 0.79354906, auc4 = 0.6973097, auc5 = 0.69466585, global_step = 5500, loss = 34.294395, precision0 = 0.21969697, precision1 = 0.26291078, precision2 = 0.18562874, precision3 = 0.10769231, precision4 = 0.22093023, precision5 = 0.27906978, recall0 = 0.13425925, recall1 = 0.17391305, recall2 = 0.19254659, recall3 = 0.30701753, recall4 = 0.13768116, recall5 = 0.07973422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5500: ./test_output/model.ckpt-5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:52:05.071542 139889894938496 estimator.py:2039] Saving 'checkpoint_path' summary for global step 5500: ./test_output/model.ckpt-5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.568114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:52:05.946660 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 0.568114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -130.51959, step = 5500 (176.015 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:52:05.948972 139889894938496 basic_session_run_hooks.py:247] loss = -130.51959, step = 5500 (176.015 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.16123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:53:32.062625 139889894938496 basic_session_run_hooks.py:680] global_step/sec: 1.16123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -140.75058, step = 5600 (86.120 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0604 20:53:32.069314 139889894938496 basic_session_run_hooks.py:247] loss = -140.75058, step = 5600 (86.120 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-9d1ca38c68b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                                   \u001b[0meval_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                   \u001b[0mscore_col\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mscore_column\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                   text_col=text_col_name,)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-e1332fa65833>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self, df_train, df_eval, score_col, text_col, num_train_steps, eval_steps, supplied_context_df)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0meval_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvalSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    469\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    609\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    610\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;31m# Distributed case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1157\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1405\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    674\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1172\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# df_test = test_df\n",
    "batch_size = 32\n",
    "eval_steps = int(len(df_test) / batch_size)\n",
    "\n",
    "neural_process.train_and_evaluate(df_train=df_train,\n",
    "                                  df_eval = df_test,\n",
    "                                  num_train_steps=10000,\n",
    "                                  eval_steps = eval_steps,\n",
    "                                  score_col= score_column, \n",
    "                                  text_col=text_col_name,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1559580440677,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "yKmEsQK9OziS",
    "outputId": "5c6dc762-63a2-4abe-f208-67441a6c5367"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.antagonize==1].loc[0,'antagonize'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ylFqMHdtabBy"
   },
   "outputs": [],
   "source": [
    "### Train:\n",
    "\n",
    "neural_process.train(df_train=df_train, \n",
    "                     score_col= score_column, \n",
    "                     text_col=text_col_name, \n",
    "                     num_train_steps=num_train_steps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uHP88st76N4l"
   },
   "outputs": [],
   "source": [
    "df_test = test_df.sample(220)\n",
    "\n",
    "supp_context = df_train.sample(100)\n",
    "\n",
    "batch_size = 32\n",
    "eval_steps = int(len(df_test) / batch_size)\n",
    "\n",
    "# neural_process.evaluate(eval_steps,\n",
    "#                        df_test, \n",
    "#                        score_col= score_column, \n",
    "#                        text_col=text_col_name, supplied_context_df = supp_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fu6bWjywkRly"
   },
   "outputs": [],
   "source": [
    "! cp -r \"./gdrive/My Drive/Kaggle_toxic_comments/test_output\" \"./gdrive/My Drive/Kaggle_toxic_comments/29May\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 582360,
     "status": "ok",
     "timestamp": 1559160617676,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "kYAzaj27haPc",
    "outputId": "f51a0dc8-2be4-4f5e-925e-ed67cb4a8994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: gdrive/My Drive/Kaggle_toxic_comments/test_output/ (stored 0%)\n",
      "updating: gdrive/My Drive/Kaggle_toxic_comments/test_output/graph.pbtxt (deflated 98%)\n",
      "updating: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-0_temp_0ba0533d97bf4341863fa0f748b3242c/ (stored 0%)\n",
      "updating: gdrive/My Drive/Kaggle_toxic_comments/test_output/events.out.tfevents.1559135119.c82db80b81be (deflated 96%)\n",
      "updating: gdrive/My Drive/Kaggle_toxic_comments/test_output/checkpoint (deflated 76%)\n",
      "updating: gdrive/My Drive/Kaggle_toxic_comments/test_output/eval/ (stored 0%)\n",
      "updating: gdrive/My Drive/Kaggle_toxic_comments/test_output/eval/events.out.tfevents.1559136093.c82db80b81be (deflated 96%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-8000.data-00000-of-00001 (deflated 12%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-8000.index (deflated 69%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-8000.meta (deflated 96%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-8500.data-00000-of-00001 (deflated 12%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-8500.index (deflated 69%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-8500.meta (deflated 96%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-9000.data-00000-of-00001 (deflated 12%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-9000.index (deflated 69%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-9000.meta (deflated 96%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-9500.data-00000-of-00001 (deflated 12%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-9500.index (deflated 69%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-9500.meta (deflated 96%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-10000.data-00000-of-00001 (deflated 12%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-10000.index (deflated 69%)\n",
      "  adding: gdrive/My Drive/Kaggle_toxic_comments/test_output/model.ckpt-10000.meta (deflated 96%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r \"./gdrive/My Drive/Kaggle_toxic_comments/test_output.zip\" \"./gdrive/My Drive/Kaggle_toxic_comments/test_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 124787,
     "status": "ok",
     "timestamp": 1559163267540,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "BWl2bHQAgbJP",
    "outputId": "cfaf7a67-e227-45df-a96b-210409c9fd6d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('::ffff:127.0.0.1', 47492, 0, 0)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 721, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 418, in handle\n",
      "    self.handle_one_request()\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 406, in handle_one_request\n",
      "    method()\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 639, in do_GET\n",
      "    self.copyfile(f, self.wfile)\n",
      "  File \"/usr/lib/python3.6/http/server.py\", line 800, in copyfile\n",
      "    shutil.copyfileobj(source, outputfile)\n",
      "  File \"/usr/lib/python3.6/shutil.py\", line 82, in copyfileobj\n",
      "    fdst.write(buf)\n",
      "  File \"/usr/lib/python3.6/socketserver.py\", line 800, in write\n",
      "    self._sock.sendall(b)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download(\"./gdrive/My Drive/Kaggle_toxic_comments/test_output.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FX-JHgfyWvmz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_NqA06NHYgxh"
   },
   "outputs": [],
   "source": [
    "preds = neural_process.predict(\n",
    "                       df_test[:100], \n",
    "                       score_col= score_column, \n",
    "                       text_col=text_col_name,supplied_context_df = df_test[100:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1260
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36931,
     "status": "ok",
     "timestamp": 1559082662122,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "kwZSmXI0YgvZ",
    "outputId": "08c8a265-6895-47ed-bc6f-cddc8f962493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Could not find trained model in model_dir: ./gdrive/My Drive/Kaggle_toxic_comments/test_output, running initialization to predict.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 22:30:32.055550 140330631681920 estimator.py:604] Could not find trained model in model_dir: ./gdrive/My Drive/Kaggle_toxic_comments/test_output, running initialization to predict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 22:30:32.172517 140330631681920 estimator.py:1111] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 22:30:35.487530 140330631681920 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 22:30:36.393283 140330631681920 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"module_apply_tokens_1/bert/pooler/dense/Tanh:0\", shape=(50, 768), dtype=float32)\n",
      "Tensor(\"strided_slice_3:0\", shape=(50, 6), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-9-504275df30f7>:28: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0528 22:30:36.517789 140330631681920 deprecation.py:323] From <ipython-input-9-504275df30f7>:28: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat:0\", shape=(?, 768), dtype=float32)\n",
      "Tensor(\"concat_3:0\", shape=(?, 6), dtype=float32)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0528 22:30:36.959087 140330631681920 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0528 22:30:37.083598 140330631681920 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0528 22:30:50.013116 140330631681920 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 22:30:50.772849 140330631681920 estimator.py:1113] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 22:30:52.711461 140330631681920 monitored_session.py:222] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 22:30:58.300700 140330631681920 session_manager.py:491] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0528 22:30:58.594700 140330631681920 session_manager.py:493] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction_mean': array([0.58968437, 0.50963736, 0.39044586, 0.48339668, 0.38118672,\n",
      "       0.68578017], dtype=float32), 'prediction_var': array([0.23760812, 0.33857793, 0.46133524, 0.4781304 , 0.36333713,\n",
      "       0.52541244], dtype=float32)}\n",
      "{'prediction_mean': array([0.61491287, 0.53158444, 0.40401617, 0.5010439 , 0.36084887,\n",
      "       0.6722851 ], dtype=float32), 'prediction_var': array([0.24582544, 0.34406394, 0.42419687, 0.457196  , 0.4034973 ,\n",
      "       0.5169641 ], dtype=float32)}\n",
      "{'prediction_mean': array([0.6055819 , 0.541195  , 0.39108545, 0.5093929 , 0.37909573,\n",
      "       0.6716364 ], dtype=float32), 'prediction_var': array([0.2535335 , 0.35427654, 0.43777767, 0.47225547, 0.37682575,\n",
      "       0.4316023 ], dtype=float32)}\n",
      "{'prediction_mean': array([0.6171516 , 0.5247955 , 0.4102393 , 0.5289594 , 0.38734797,\n",
      "       0.6871959 ], dtype=float32), 'prediction_var': array([0.22779545, 0.3911062 , 0.414222  , 0.46190476, 0.33947837,\n",
      "       0.44611964], dtype=float32)}\n",
      "{'prediction_mean': array([0.59801173, 0.51222736, 0.3951928 , 0.48996457, 0.3952407 ,\n",
      "       0.6781851 ], dtype=float32), 'prediction_var': array([0.24413896, 0.32128927, 0.46695882, 0.44756022, 0.3230121 ,\n",
      "       0.55537826], dtype=float32)}\n",
      "{'prediction_mean': array([0.595419  , 0.5229403 , 0.3841215 , 0.48814982, 0.38483587,\n",
      "       0.70231044], dtype=float32), 'prediction_var': array([0.24957803, 0.35753584, 0.43337855, 0.46043387, 0.33863333,\n",
      "       0.4658741 ], dtype=float32)}\n",
      "{'prediction_mean': array([0.6430291 , 0.54333544, 0.40891185, 0.47035974, 0.39581817,\n",
      "       0.6887767 ], dtype=float32), 'prediction_var': array([0.25097373, 0.3337281 , 0.3942756 , 0.41716012, 0.34921676,\n",
      "       0.47894126], dtype=float32)}\n",
      "{'prediction_mean': array([0.6085166 , 0.5322702 , 0.40275726, 0.4932809 , 0.37684804,\n",
      "       0.6730779 ], dtype=float32), 'prediction_var': array([0.24829116, 0.31815463, 0.38745126, 0.43287912, 0.3491499 ,\n",
      "       0.4796229 ], dtype=float32)}\n",
      "{'prediction_mean': array([0.60344416, 0.5469733 , 0.38801488, 0.4804294 , 0.38690695,\n",
      "       0.66494787], dtype=float32), 'prediction_var': array([0.27485383, 0.31592324, 0.4013483 , 0.45839936, 0.32867062,\n",
      "       0.44528002], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for pred in preds:\n",
    "  i += 1\n",
    "  if i<10:\n",
    "    print(pred)\n",
    "  else:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7hEFhEGHkrVy"
   },
   "outputs": [],
   "source": [
    "test_scores = df_test[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
    "       'identity_hate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fri1X4hdkrev"
   },
   "outputs": [],
   "source": [
    "uncertainty = pd.DataFrame(columns=['accuracy', 'variance'])\n",
    "pred_means = pd.DataFrame(columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
    "       'identity_hate'])\n",
    "pred_variances = pd.DataFrame(columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
    "       'identity_hate'])\n",
    "\n",
    "for i, pred in enumerate(preds):\n",
    "  if i<len(test_scores):\n",
    "    scores = np.array(test_scores.iloc[i])\n",
    "    #     print(scores)\n",
    "    mean_prediction = np.round(pred['prediction_mean'])\n",
    "    pred_means = pred_means.append({score_column[k]:pred['prediction_mean'][k] for k in range(len(score_column))}, ignore_index=True)\n",
    "    #     print(mean_prediction)\n",
    "    acc = scores==mean_prediction\n",
    "    variance = pred['prediction_var']\n",
    "    pred_variances = pred_variances.append({score_column[k]:variance[k] for k in range(len(score_column))}, ignore_index=True)\n",
    "    for j in range(len(scores)):\n",
    "      uncertainty = uncertainty.append({'accuracy': acc[j], 'variance': variance[j]}, ignore_index=True)\n",
    "  else:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1559055475792,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "gc3034n5pYtd",
    "outputId": "9da3ada9-da4d-428e-a0c8-4029957be10f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03968876489706338\n",
      "0.2590321116743508\n"
     ]
    }
   ],
   "source": [
    "print(uncertainty[uncertainty.accuracy==True]['variance'].mean())\n",
    "print(uncertainty[uncertainty.accuracy==False]['variance'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h5PsPzmyH6sA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJvlFgZ9j_r6"
   },
   "outputs": [],
   "source": [
    "def total_accuaracy(pred_means, test_scores):\n",
    "  preds = np.round(pred_means)\n",
    "  comparison = preds == test_scores\n",
    "  correct_guesses = np.reshape(comparison.values,-1)\n",
    "  return np.sum(correct_guesses) / len(correct_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPZACnkUGrr5"
   },
   "outputs": [],
   "source": [
    "def class_accuaracy(pred_means, test_scores):\n",
    "  preds = np.round(pred_means)\n",
    "  comparison = preds == test_scores\n",
    "  correct_guesses = comparison.values\n",
    "  return correct_guesses.sum(axis=0)/ len(correct_guesses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1559055480466,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "-xVcqWkdHT-s",
    "outputId": "c268f1f9-b375-4ab2-e2a8-21ddb71989e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8877807269185054\n",
      "[0.71103783 0.97731843 0.83179174 0.98662163 0.83903054 0.98088421]\n"
     ]
    }
   ],
   "source": [
    "print(total_accuaracy(pred_means, test_scores.reset_index(drop=True)))\n",
    "print(class_accuaracy(pred_means, test_scores.reset_index(drop=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 609,
     "status": "ok",
     "timestamp": 1559058584997,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "wjZUS-Ergg00",
    "outputId": "93ab92bc-8a92-4c7e-f0e8-d2df97e87ebb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on toxic comments:\n",
      "[0.22029045 0.93495602 0.42667212 0.95868276 0.46430763 0.88668439]\n",
      "proportion of toxic comments:\n",
      "0.13107590015818119\n",
      "\n",
      "accuracy on severe_toxic comments:\n",
      "[0.19650655 0.         0.09606987 0.89519651 0.18340611 0.65938865]\n",
      "proportion of severe_toxic comments:\n",
      "0.006139574787527816\n",
      "\n",
      "accuracy on obscene comments:\n",
      "[0.22695035 0.9047619  0.11043566 0.95812226 0.31273219 0.86018237]\n",
      "proportion of obscene comments:\n",
      "0.0793855063138422\n",
      "\n",
      "accuracy on threat comments:\n",
      "[0.23353293 0.83233533 0.40718563 0.01796407 0.38922156 0.79041916]\n",
      "proportion of threat comments:\n",
      "0.004477331831952599\n",
      "\n",
      "accuracy on insult comments:\n",
      "[0.23107715 0.90829694 0.27620087 0.95487627 0.10953421 0.82860262]\n",
      "proportion of insult comments:\n",
      "0.07367489745033379\n",
      "\n",
      "accuracy on identity_hate comments:\n",
      "[0.22504537 0.83666062 0.33212341 0.9292196  0.21778584 0.00181488]\n",
      "proportion of identity_hate comments:\n",
      "0.014772514008418456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def subset_accuracy(att):\n",
    "  print(\"accuracy on \"+att+ \" comments:\")\n",
    "  print(class_accuaracy(pred_means.iloc[np.where(test_scores[att] == 1)].reset_index(drop=True),\n",
    "                        test_scores.iloc[np.where(test_scores[att] == 1)].reset_index(drop=True)))\n",
    "\n",
    "  print(\"proportion of \"+att+ \" comments:\")\n",
    "  print(len(test_scores[test_scores[att] ==1])/len(test_scores))\n",
    "  print()\n",
    "\n",
    "for att in score_column:\n",
    "  subset_accuracy(att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 743,
     "status": "ok",
     "timestamp": 1559059183414,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "m2flPKNig2zn",
    "outputId": "0eb97fbe-d5d2-4676-db24-4bc7b7663b35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 137,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_scores[test_scores.severe_toxic==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NZ1zjhdxZByn"
   },
   "outputs": [],
   "source": [
    "at_least_one = (test_scores.toxic==1) | (test_scores.severe_toxic==1) | \\\n",
    "               (test_scores.obscene==1) | (test_scores.threat==1) | \\\n",
    "               (test_scores.insult==1) | (test_scores.identity_hate==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2VzhiqkLZB2h"
   },
   "outputs": [],
   "source": [
    "print(uncertainty[uncertainty.accuracy==True]['variance'].mean())\n",
    "print(uncertainty[uncertainty.accuracy==False]['variance'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1558900798557,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "75VhsEk5ZB5E",
    "outputId": "d1d7411d-4cdc-43de-c697-c41c82472cfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37299"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1558903339593,
     "user": {
      "displayName": "Ilan Price",
      "photoUrl": "",
      "userId": "14888046437571338619"
     },
     "user_tz": -60
    },
    "id": "wXgIhm8zujWn",
    "outputId": "4e9d86f8-5349-47a8-f0d2-ee399497879e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "didnt work\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "  print(\"this\")\n",
    "  True/\"this\"\n",
    "except:\n",
    "  print(\"didnt work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWn5PHX-4Tdt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Class_BERT_NeuralProcesses_notebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
