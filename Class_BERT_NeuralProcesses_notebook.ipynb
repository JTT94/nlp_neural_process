{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Class_BERT_NeuralProcesses_notebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JTT94/nlp_neural_process/blob/master/Class_BERT_NeuralProcesses_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SZKAwmizhzHo",
        "outputId": "24c592ac-6fa1-4601-b737-7b815a0c830a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import re\n",
        "\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import string\n",
        "from datetime import datetime \n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow_probability import distributions as tfd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7PWS-GcrZbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.logging.set_verbosity(tf.logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pgB8X8dti3qc",
        "outputId": "47badb57-b75e-46ba-dd8f-897d0f21cf53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "!pip install bert-tensorflow\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0706 12:24:43.776601 140042348476288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jDvh4JVNQFck",
        "outputId": "08618e8e-703d-4157-b1c9-80808fe06532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6BzlNM53sIBp",
        "colab": {}
      },
      "source": [
        "# output_directory = \"./gdrive/My Drive/Kaggle_toxic_comments/test_output\"\n",
        "# output_directory = \"./test_output\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CKlcN3PR6RL",
        "colab_type": "code",
        "outputId": "0ec4073b-c71f-41bb-e44a-b2295f14992b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "DATAFLAG = 'unhealthy'\n",
        "BUCKET = 'rail_jigsaw_modeling' #@param {type:\"string\"}\n",
        "MODEL = 'batch32_attributeOverrep' #@param {type:\"string\"}\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/{}/models/{}'.format(BUCKET, DATAFLAG, MODEL)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://rail_jigsaw_modeling/unhealthy/models/batch32_attributeOverrep *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZCJDPOgQOsqJ",
        "colab": {}
      },
      "source": [
        "# initialiase tensorboard \n",
        "# from https://stackoverflow.com/questions/47818822/can-i-use-tensorboard-with-google-colab\n",
        "\n",
        "\n",
        "# Get TensorBoard running in the background. \n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(OUTPUT_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5sZ3Bl48oaxU",
        "outputId": "917f4c42-99d7-4558-9c0c-85da5157d1fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "# # #Download and unzip ngrok. \n",
        "!test -e ngrok-stable-linux-amd64.zip || wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!test -e ngrok || unzip ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-06 12:29:54--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.4.75.11, 54.236.200.27, 35.169.95.168, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.4.75.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17556757 (17M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \rngrok-stable-linux- 100%[===================>]  16.74M   101MB/s    in 0.2s    \n",
            "\n",
            "2019-07-06 12:29:55 (101 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [17556757/17556757]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mLp9PmAzoWhE",
        "colab": {}
      },
      "source": [
        "# #Launch ngrok background process...\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eL1A1ibjOwnL",
        "outputId": "2f02f474-b6bb-4676-c90f-cf07e7068076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://ef284727.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bweIS72l5WS5",
        "outputId": "68096b13-abb5-4ea4-f5e9-cf01855d26e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import os, sys\n",
        "sys.path.append('../') # add personal code dir to path for import\n",
        "\n",
        "\n",
        "!test -d neural_process || git clone https://github.com/JTT94/nlp_neural_process.git neural_process\n",
        "sys.path.append('./neural_process/')\n",
        "\n",
        "import random\n",
        "from neural_process import split_context_target, NeuralProcessParams\n",
        "from neural_process.network import *\n",
        "from neural_process.loss import *\n",
        "from neural_process.predict import *\n",
        "from neural_process.process import *\n",
        "\n",
        "from neural_process.tf_model_builder_AUC import *\n",
        "from neural_process.bert_utils import *"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'neural_process'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/146)   \u001b[K\rremote: Counting objects:   1% (2/146)   \u001b[K\rremote: Counting objects:   2% (3/146)   \u001b[K\rremote: Counting objects:   3% (5/146)   \u001b[K\rremote: Counting objects:   4% (6/146)   \u001b[K\rremote: Counting objects:   5% (8/146)   \u001b[K\rremote: Counting objects:   6% (9/146)   \u001b[K\rremote: Counting objects:   7% (11/146)   \u001b[K\rremote: Counting objects:   8% (12/146)   \u001b[K\rremote: Counting objects:   9% (14/146)   \u001b[K\rremote: Counting objects:  10% (15/146)   \u001b[K\rremote: Counting objects:  11% (17/146)   \u001b[K\rremote: Counting objects:  12% (18/146)   \u001b[K\rremote: Counting objects:  13% (19/146)   \u001b[K\rremote: Counting objects:  14% (21/146)   \u001b[K\rremote: Counting objects:  15% (22/146)   \u001b[K\rremote: Counting objects:  16% (24/146)   \u001b[K\rremote: Counting objects:  17% (25/146)   \u001b[K\rremote: Counting objects:  18% (27/146)   \u001b[K\rremote: Counting objects:  19% (28/146)   \u001b[K\rremote: Counting objects:  20% (30/146)   \u001b[K\rremote: Counting objects:  21% (31/146)   \u001b[K\rremote: Counting objects:  22% (33/146)   \u001b[K\rremote: Counting objects:  23% (34/146)   \u001b[K\rremote: Counting objects:  24% (36/146)   \u001b[K\rremote: Counting objects:  25% (37/146)   \u001b[K\rremote: Counting objects:  26% (38/146)   \u001b[K\rremote: Counting objects:  27% (40/146)   \u001b[K\rremote: Counting objects:  28% (41/146)   \u001b[K\rremote: Counting objects:  29% (43/146)   \u001b[K\rremote: Counting objects:  30% (44/146)   \u001b[K\rremote: Counting objects:  31% (46/146)   \u001b[K\rremote: Counting objects:  32% (47/146)   \u001b[K\rremote: Counting objects:  33% (49/146)   \rremote: Counting objects:  34% (50/146)   \u001b[K\rremote: Counting objects:  35% (52/146)   \u001b[K\rremote: Counting objects:  36% (53/146)   \u001b[K\rremote: Counting objects:  37% (55/146)   \u001b[K\rremote: Counting objects:  38% (56/146)   \u001b[K\rremote: Counting objects:  39% (57/146)   \u001b[K\rremote: Counting objects:  40% (59/146)   \u001b[K\rremote: Counting objects:  41% (60/146)   \u001b[K\rremote: Counting objects:  42% (62/146)   \u001b[K\rremote: Counting objects:  43% (63/146)   \u001b[K\rremote: Counting objects:  44% (65/146)   \u001b[K\rremote: Counting objects:  45% (66/146)   \u001b[K\rremote: Counting objects:  46% (68/146)   \u001b[K\rremote: Counting objects:  47% (69/146)   \u001b[K\rremote: Counting objects:  48% (71/146)   \u001b[K\rremote: Counting objects:  49% (72/146)   \u001b[K\rremote: Counting objects:  50% (73/146)   \u001b[K\rremote: Counting objects:  51% (75/146)   \u001b[K\rremote: Counting objects:  52% (76/146)   \u001b[K\rremote: Counting objects:  53% (78/146)   \u001b[K\rremote: Counting objects:  54% (79/146)   \u001b[K\rremote: Counting objects:  55% (81/146)   \u001b[K\rremote: Counting objects:  56% (82/146)   \u001b[K\rremote: Counting objects:  57% (84/146)   \u001b[K\rremote: Counting objects:  58% (85/146)   \u001b[K\rremote: Counting objects:  59% (87/146)   \u001b[K\rremote: Counting objects:  60% (88/146)   \u001b[K\rremote: Counting objects:  61% (90/146)   \u001b[K\rremote: Counting objects:  62% (91/146)   \u001b[K\rremote: Counting objects:  63% (92/146)   \u001b[K\rremote: Counting objects:  64% (94/146)   \u001b[K\rremote: Counting objects:  65% (95/146)   \u001b[K\rremote: Counting objects:  66% (97/146)   \u001b[K\rremote: Counting objects:  67% (98/146)   \u001b[K\rremote: Counting objects:  68% (100/146)   \u001b[K\rremote: Counting objects:  69% (101/146)   \u001b[K\rremote: Counting objects:  70% (103/146)   \u001b[K\rremote: Counting objects:  71% (104/146)   \u001b[K\rremote: Counting objects:  72% (106/146)   \u001b[K\rremote: Counting objects:  73% (107/146)   \u001b[K\rremote: Counting objects:  74% (109/146)   \u001b[K\rremote: Counting objects:  75% (110/146)   \u001b[K\rremote: Counting objects:  76% (111/146)   \u001b[K\rremote: Counting objects:  77% (113/146)   \u001b[K\rremote: Counting objects:  78% (114/146)   \u001b[K\rremote: Counting objects:  79% (116/146)   \u001b[K\rremote: Counting objects:  80% (117/146)   \u001b[K\rremote: Counting objects:  81% (119/146)   \u001b[K\rremote: Counting objects:  82% (120/146)   \u001b[K\rremote: Counting objects:  83% (122/146)   \u001b[K\rremote: Counting objects:  84% (123/146)   \u001b[K\rremote: Counting objects:  85% (125/146)   \u001b[K\rremote: Counting objects:  86% (126/146)   \u001b[K\rremote: Counting objects:  87% (128/146)   \u001b[K\rremote: Counting objects:  88% (129/146)   \u001b[K\rremote: Counting objects:  89% (130/146)   \u001b[K\rremote: Counting objects:  90% (132/146)   \u001b[K\rremote: Counting objects:  91% (133/146)   \u001b[K\rremote: Counting objects:  92% (135/146)   \u001b[K\rremote: Counting objects:  93% (136/146)   \u001b[K\rremote: Counting objects:  94% (138/146)   \u001b[K\rremote: Counting objects:  95% (139/146)   \u001b[K\rremote: Counting objects:  96% (141/146)   \u001b[K\rremote: Counting objects:  97% (142/146)   \u001b[K\rremote: Counting objects:  98% (144/146)   \u001b[K\rremote: Counting objects:  99% (145/146)   \u001b[K\rremote: Counting objects: 100% (146/146)   \u001b[K\rremote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 146 (delta 89), reused 132 (delta 79), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (146/146), 786.12 KiB | 6.72 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "69MNF4fEi5Ly",
        "outputId": "ca8d9513-ee93-4c7e-a2e8-3204321a58b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "# Initialize session\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "K.tensorflow_backend._get_available_gpus()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0706 12:30:02.469578 140042348476288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0706 12:30:02.470762 140042348476288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/job:localhost/replica:0/task:0/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cc1rwgOZi9F1",
        "colab": {}
      },
      "source": [
        "# # filename = './cleaned_data.csv'\n",
        "# filename = './gdrive/My Drive/Oxford/RAIL/Jigsaw/Technical Team/toxic_comments/Data/data1.csv'\n",
        "# df = pd.read_csv(filename, index_col=0)\n",
        "# cols = ['comment','antagonize', 'condescending', 'dismissive', 'generalisation', 'hostile', 'sarcastic']\n",
        "# # cols = ['comment','cleaned_comment','antagonize', 'condescending', 'dismissive', 'generalisation', 'hostile', 'sarcastic', 'healthy']\n",
        "# df = df[cols]\n",
        "\n",
        "# score_column = ['antagonize', 'condescending', 'dismissive', 'generalisation', 'hostile', 'sarcastic']\n",
        "# # text_col_name = 'cleaned_comment'\n",
        "# text_col_name = 'comment'\n",
        "\n",
        "# df_train = df.sample(frac = 0.8)\n",
        "# df_test = df[~df.isin(df_train)].dropna()\n",
        "\n",
        "# df_train[score_column] = df_train[score_column].round()\n",
        "# df_test[score_column] = df_test[score_column].round()\n",
        "# #--------\n",
        "\n",
        "# # ### For Unhealthy dataset\n",
        "\n",
        "cols = ['comment','antagonize', 'condescending', 'dismissive', 'generalisation', 'hostile', 'sarcastic', '_trusted_judgments']\n",
        "score_column = ['antagonize', 'condescending', 'dismissive', 'generalisation', 'hostile', 'sarcastic']\n",
        "text_col_name = 'comment'\n",
        "\n",
        "## Training data\n",
        "\n",
        "train_filename = './gdrive/My Drive/unhealthy_rail/unhealthy_train.csv'\n",
        "\n",
        "df_train = pd.read_csv(train_filename)\n",
        "df_train = df_train[cols].round()\n",
        "\n",
        "#Cast to float - because scores and labels need to be concattenated in the model function, and so need to be same type\n",
        "for i in score_column:\n",
        "  df_train[i] = pd.to_numeric(df_train[i],downcast='float')\n",
        "\n",
        "  \n",
        "## Validation data\n",
        "\n",
        "val_filename = './gdrive/My Drive/unhealthy_rail/unhealthy_val.csv'\n",
        "\n",
        "df_val = pd.read_csv(val_filename)\n",
        "df_val = df_val[cols].round()\n",
        "\n",
        "#Cast to float - because scores and labels need to be concattenated in the model function, and so need to be same type\n",
        "for i in score_column:\n",
        "  df_val[i] = pd.to_numeric(df_val[i],downcast='float')\n",
        "\n",
        "## Test data\n",
        "\n",
        "test_filename = './gdrive/My Drive/unhealthy_rail/unhealthy_test.csv'\n",
        "\n",
        "df_test = pd.read_csv(test_filename)\n",
        "df_test = df_test[cols].round()\n",
        "\n",
        "#Cast to float - because scores and labels need to be concattenated in the model function, and so need to be same type\n",
        "for i in score_column:\n",
        "  df_test[i] = pd.to_numeric(df_test[i],downcast='float')\n",
        "\n",
        "\n",
        "\n",
        "# # # ### For kaggle dataset\n",
        "\n",
        "# ## Training data\n",
        "\n",
        "# # filename = './gdrive/My Drive/Data/train.csv'\n",
        "# train_filename = './gdrive/My Drive/Kaggle_toxic_comments/finalSplit/train_kaggle.csv'\n",
        "\n",
        "# df = pd.read_csv(train_filename)\n",
        "# cols = ['comment_text','toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "# df = df[cols]\n",
        "\n",
        "# score_column = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "# text_col_name = 'comment_text'\n",
        "\n",
        "# #Cast to float - because scores and labels need to be concattenated in the model function, and so need to be same type\n",
        "# for i in score_column:\n",
        "#   df[i] = pd.to_numeric(df[i],downcast='float')\n",
        "\n",
        "# df_train = df[df.comment_text.str.len() <= 250]\n",
        "\n",
        "# ## Validation data\n",
        "\n",
        "# # filename = './gdrive/My Drive/Data/train.csv'\n",
        "# val_filename = './gdrive/My Drive/Kaggle_toxic_comments/finalSplit/val_kaggle.csv'\n",
        "\n",
        "# df = pd.read_csv(val_filename)\n",
        "# cols = ['comment_text','toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "# df = df[cols]\n",
        "\n",
        "# score_column = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "# text_col_name = 'comment_text'\n",
        "\n",
        "# #Cast to float - because scores and labels need to be concattenated in the model function, and so need to be same type\n",
        "# for i in score_column:\n",
        "#   df[i] = pd.to_numeric(df[i],downcast='float')\n",
        "\n",
        "# df_val = df[df.comment_text.str.len() <= 250]\n",
        "\n",
        "# ## Test data\n",
        "\n",
        "# # filename = './gdrive/My Drive/Data/train.csv'\n",
        "# test_filename = './gdrive/My Drive/Kaggle_toxic_comments/finalSplit/test_kaggle.csv'\n",
        "\n",
        "# df = pd.read_csv(test_filename)\n",
        "# cols = ['comment_text','toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "# df = df[cols]\n",
        "\n",
        "# score_column = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "# text_col_name = 'comment_text'\n",
        "\n",
        "# #Cast to float - because scores and labels need to be concattenated in the model function, and so need to be same type\n",
        "# for i in score_column:\n",
        "#   df[i] = pd.to_numeric(df[i],downcast='float')\n",
        "\n",
        "# df_test = df[df.comment_text.str.len() <= 250]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i2roS1iGnUvH",
        "colab": {}
      },
      "source": [
        "# data = pd.concat([df_train,test_df])\n",
        "\n",
        "# data =  data.sample(frac = 1.0)\n",
        "\n",
        "# msk = np.random.rand(len(data)) < 0.8\n",
        "\n",
        "# train = data[msk]\n",
        "\n",
        "# temp = data[~msk]\n",
        "\n",
        "# msk2 = np.random.rand(len(temp)) <= 0.5\n",
        "\n",
        "# val = temp[msk2]\n",
        "\n",
        "# test = temp[~msk2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "coSxH1Vgnw_H",
        "colab": {}
      },
      "source": [
        "# train.to_csv(\"train_kaggle.csv\")\n",
        "# test.to_csv(\"test_kaggle.csv\")\n",
        "# val.to_csv(\"val_kaggle.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mUIe15uTi9Ok",
        "outputId": "0fee1c9a-4f6b-40e8-c32c-7dc65f3cbd1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_model_hub = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "tokenizer = create_tokenizer_from_hub_module(BERT_model_hub)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0706 12:37:16.423782 140042348476288 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "W0706 12:37:16.547700 140042348476288 deprecation_wrapper.py:119] From ./neural_process/neural_process/bert_utils.py:39: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0706 12:37:18.122014 140042348476288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IVESPLmgl98I",
        "colab": {}
      },
      "source": [
        "# #Pre process data for bert embedding\n",
        "max_seq_length = 128\n",
        "\n",
        "import pickle\n",
        "\n",
        "# train_input_examples = create_examples(df_train.sample(100), score_column, text_col_name)\n",
        "# # # test_input_examples = create_examples(df_test, score_column, text_col_name)\n",
        "\n",
        "# train_features = convert_examples_to_features(train_input_examples, max_seq_length, tokenizer)\n",
        "# # # test_features = convert_examples_to_features(test_input_examples, max_seq_length, tokenizer)\n",
        "\n",
        "# pickle.dump(train_features, open('./gdrive/My Drive/Kaggle_toxic_comments/train_features.p', 'wb'))\n",
        "# # pickle.dump(test_features, open('./gdrive/My Drive/Kaggle_toxic_comments/test_features.p', 'wb'))\n",
        "\n",
        "# # ## Load features previously saved\n",
        "# train_features = pickle.load(open('./gdrive/My Drive/Kaggle_toxic_comments/train_features.p', 'rb'))\n",
        "# test_features = pickle.load(open('./gdrive/My Drive/Kaggle_toxic_comments/train_features.p', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wOdj6CWiPYSX",
        "colab": {}
      },
      "source": [
        "# utility methods\n",
        "from collections import namedtuple\n",
        "NeuralProcessParams = namedtuple('NeuralProcessParams', ['dim_z', 'n_hidden_units_h', 'n_hidden_units_g'])\n",
        "GaussianParams = namedtuple('GaussianParams', ['mu', 'sigma'])\n",
        "\n",
        "\n",
        "def batch_mlp(input, inner_layer_dims, output_dim, variable_scope):\n",
        "  \"\"\"Apply MLP to the final axis of a 3D tensor (reusing already defined MLPs).\n",
        "  \n",
        "  Args:\n",
        "    input: input tensor of shape [B,n,d_in].\n",
        "    output_sizes: An iterable containing the output sizes of the MLP as defined \n",
        "        in `basic.Linear`.\n",
        "    variable_scope: String giving the name of the variable scope. If this is set\n",
        "        to be the same as a previously defined MLP, then the weights are reused.\n",
        "    \n",
        "  Returns:\n",
        "    tensor of shape [B,n,d_out] where d_out=output_sizes[-1]\n",
        "  \"\"\"\n",
        "  # Get the shapes of the input and reshape to parallelise across observations\n",
        "\n",
        "  output = input\n",
        "\n",
        "  \n",
        "  # Pass through MLP\n",
        "  with tf.variable_scope(variable_scope, reuse=tf.AUTO_REUSE):\n",
        "    for i, size in enumerate(inner_layer_dims):\n",
        "      output = tf.nn.relu(\n",
        "          tf.layers.dense(output, size, name=\"layer_{}\".format(i)))\n",
        "\n",
        "    # Last layer without a ReLu\n",
        "    output = tf.layers.dense(output, output_dim, name=\"layer_{}\".format(i + 1))\n",
        "\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g_gK0D7AhoLK",
        "colab": {}
      },
      "source": [
        "# class Embedder(object):\n",
        "  \n",
        "#   def __init__(self, BERT_model_hub = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\", trainable=True):\n",
        "#     self.BERT_model_hub = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "#     self.tokenizer = create_tokenizer_from_hub_module(BERT_model_hub)\n",
        "#     self.trainable = trainable\n",
        "    \n",
        "#   def __call__(self, input_ids, input_mask, segment_ids):\n",
        "#     embedder = hub.Module(self.BERT_model_hub,trainable=self.trainable)\n",
        "#     bert_inputs = dict(input_ids=input_ids,\n",
        "#                        input_mask=input_mask, \n",
        "#                        segment_ids=segment_ids)\n",
        "\n",
        "#     bert_outputs = embedder(inputs=bert_inputs,\n",
        "#                                signature=\"tokens\", \n",
        "#                                as_dict=True)\n",
        "    \n",
        "#   # Use \"pooled_output\" for classification tasks on an entire sentence. Use \"sequence_outputs\" for token-level output\n",
        "#     return bert_outputs[\"pooled_output\"]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2HMqLmD8PTEP",
        "colab": {}
      },
      "source": [
        "class Decoder(object):\n",
        "  \"\"\"The Decoder.\"\"\"\n",
        "\n",
        "  def __init__(self, layer_dims, num_classes):\n",
        "    self.layer_dims = layer_dims\n",
        "    self.num_classes = num_classes\n",
        "    \n",
        "  def __call__(self, input_xs_embedding, z_samples):\n",
        "  \n",
        "        # inputs dimensions\n",
        "    # z_sample has dim [n_draws, dim_z]\n",
        "    # x_star has dim [N_star, dim_x]\n",
        "    n_draws = z_samples.get_shape().as_list()[0]\n",
        "    n_xs = tf.shape(input_xs_embedding)[0]\n",
        "\n",
        "    # Repeat z samples for each x*\n",
        "    #z_samples_repeat = tf.expand_dims(z_samples, axis=1)\n",
        "\n",
        "    #z_samples_repeat = tf.expand_dims(z_samples, axis=1)\n",
        "    z_samples_repeat = tf.tile(z_samples, [1, n_xs, 1])\n",
        "\n",
        "    # Repeat x* for each z sample\n",
        "    x_star_repeat = tf.expand_dims(input_xs_embedding, axis=0)\n",
        "    x_star_repeat = tf.tile(x_star_repeat, [n_draws, 1, 1])\n",
        "\n",
        "    # Concatenate x* and z\n",
        "    inputs = tf.concat([x_star_repeat, z_samples_repeat], axis=2)\n",
        "\n",
        "    # decoder mlp\n",
        "    inner_layer_dims = self.layer_dims\n",
        "    output_dim = self.num_classes *2\n",
        "    hidden = batch_mlp(inputs, inner_layer_dims, output_dim, \"decoder\")\n",
        "\n",
        "    # Get the mean an the variance\n",
        "    mu, log_sigma = tf.split(hidden, 2, axis= -1)\n",
        "\n",
        "    # Bound the variance\n",
        "    sigma_star = 0.1 + 0.9 * tf.nn.softplus(log_sigma)\n",
        "    mu_star = tf.math.sigmoid(mu)\n",
        "\n",
        "\n",
        "    return GaussianParams(mu_star, sigma_star)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L6DmGdqzaGjS",
        "colab": {}
      },
      "source": [
        "class Encoder(object):\n",
        "\n",
        "  def __init__(self, layer_dims, latent_dim):\n",
        "    self.layer_dims = layer_dims\n",
        "    self.latent_dim = latent_dim\n",
        "    \n",
        "  def __call__(self, xs, ys):\n",
        "    print(xs)\n",
        "    print(ys)\n",
        "    xys = tf.concat([xs, ys], axis=1)\n",
        "\n",
        "\n",
        "    # encoder mlp\n",
        "    inner_layer_dims = self.layer_dims[:-1]\n",
        "    output_dim = self.layer_dims[-1]\n",
        "    rs = batch_mlp(xys, inner_layer_dims, output_dim, \"encoder\")\n",
        "    \n",
        "    # aggregate rs\n",
        "    r = self._aggregate_r(rs)\n",
        "    \n",
        "    # get mu and sigma\n",
        "    z_params = self._get_z_params(r)\n",
        "    \n",
        "    # distribution\n",
        "    dist = tfd.MultivariateNormalDiag(loc=z_params.mu,\n",
        "                                          scale_diag=z_params.sigma)\n",
        "    return dist\n",
        "    \n",
        "  def _aggregate_r(self, context_rs: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Aggregate the output of the encoder to a single representation\n",
        "\n",
        "    Creates an aggregation (mean) operator to combine the encodings of multiple context inputs\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    context_rs\n",
        "        Input encodings tensor, shape: (n_samples, dim_r)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        Output tensor of aggregation result\n",
        "    \"\"\"\n",
        "    mean = tf.reduce_mean(context_rs, axis=0)\n",
        "    r = tf.reshape(mean, [1, -1])\n",
        "    return r\n",
        "  \n",
        "  def _get_z_params(self, context_r: tf.Tensor) -> GaussianParams:\n",
        "    \"\"\"Map encoding to mean and covariance of the random variable Z\n",
        "\n",
        "    Creates a linear dense layer to map encoding to mu_z, and another linear mapping + a softplus activation for Sigma_z\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    context_r\n",
        "        Input encoding tensor, shape: (1, dim_r)\n",
        "    params\n",
        "        Neural process parameters\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        Output tensors of the mappings for mu_z and Sigma_z\n",
        "    \"\"\"\n",
        "    hidden = context_r\n",
        "    with tf.variable_scope(\"latent_encoder\", reuse=tf.AUTO_REUSE):\n",
        "      # First apply intermediate relu layer \n",
        "      hidden = tf.nn.relu(\n",
        "          tf.layers.dense(hidden, \n",
        "                          (self.layer_dims[-1] + self.latent_dim)/2, \n",
        "                          name=\"penultimate_layer\"))\n",
        "      \n",
        "      # Then apply further linear layers to output latent mu and log sigma\n",
        "      mu = tf.layers.dense(hidden, self.latent_dim, name=\"mean_layer\")\n",
        "      log_sigma = tf.layers.dense(hidden, self.latent_dim, name=\"std_layer\")\n",
        "      \n",
        "\n",
        "    # Compute sigma\n",
        "    sigma = 0.1 + 0.9 * tf.sigmoid(log_sigma)\n",
        "\n",
        "    return GaussianParams(mu, sigma)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LWZZAs1haFkc",
        "colab": {}
      },
      "source": [
        "class NLP_NeuralProcess(object):\n",
        "  \n",
        "  def __init__(self,\n",
        "                  score_col, \n",
        "                  params = NeuralProcessParams(dim_z=20, \n",
        "                                                     n_hidden_units_h=[128, 128, 128], \n",
        "                                                     n_hidden_units_g=[128, 128, 128]),\n",
        "                  num_classes = 6, \n",
        "                  num_draws = 2, \n",
        "                  lr = 2e-5,\n",
        "                  batch_size = 32, \n",
        "                  num_warmup_steps=100,\n",
        "                  num_train_steps = 10**3,\n",
        "                  save_summary_steps = 100,\n",
        "                  save_checkpoints_steps = 500,\n",
        "                  keep_checkpoint_max = None,\n",
        "                  output_dir = \"./test_output\",\n",
        "                  context_features = None\n",
        "                 ):\n",
        "    \n",
        "    self.params = params\n",
        "    self.encoder = Encoder(layer_dims = self.params.n_hidden_units_h, \n",
        "                           latent_dim=self.params.dim_z)\n",
        "    self.decoder = Decoder(layer_dims= self.params.n_hidden_units_g, \n",
        "                           num_classes=num_classes)\n",
        "    self.num_draws = num_draws\n",
        "    self.num_classes = num_classes\n",
        "#     self.estimator = None\n",
        "    #self.embedder = Embedder()\n",
        "    #####  \n",
        "    num_labels = len(score_col)\n",
        "    \n",
        "    \n",
        "    # Specify outpit directory and number of checkpoint steps to save\n",
        "    \n",
        "    run_config = tf.estimator.RunConfig(model_dir=output_dir,\n",
        "          save_summary_steps=save_summary_steps, save_checkpoints_steps=save_checkpoints_steps)\n",
        "    \n",
        "    model_fn = self.model_fn_builder(num_labels = num_labels, learning_rate=lr,\n",
        "      num_train_steps=num_train_steps, num_warmup_steps=num_warmup_steps)\n",
        "    \n",
        "    if context_features is not None:\n",
        "      estimator_params = {\"batch_size\": batch_size, \"context_features\": context_features}\n",
        "      self.estimator = tf.estimator.Estimator(model_fn=model_fn,config=run_config,\n",
        "                                              params=estimator_params)\n",
        "    \n",
        "    else: \n",
        "      self.estimator = tf.estimator.Estimator(model_fn=model_fn,config=run_config,\n",
        "            params={\"batch_size\": batch_size})\n",
        "    \n",
        "    \n",
        "  def create_model(self, \n",
        "                   target_input_ids, \n",
        "                   target_input_mask, \n",
        "                   target_segment_ids, \n",
        "                   target_scores=None,\n",
        "                   context_input_ids = None, \n",
        "                   context_input_mask = None, \n",
        "                   context_segment_ids= None, \n",
        "                   context_scores = None\n",
        "                   ):\n",
        "    \n",
        "    # apply embedder\n",
        "    embedder = hub.Module(BERT_model_hub,trainable=True)\n",
        "    \n",
        "    valid_context = (context_input_ids is not None) & (context_input_mask is not None) & (context_segment_ids is not None) & (context_scores is not None)\n",
        "    \n",
        "    # target processing - all scenarios\n",
        "    target_inputs = dict(input_ids=target_input_ids,\n",
        "                     input_mask=target_input_mask, \n",
        "                     segment_ids=target_segment_ids)\n",
        "    target_embeddings = embedder(inputs=target_inputs,\n",
        "                               signature=\"tokens\", \n",
        "                               as_dict=True)\n",
        "    target_xs = target_embeddings[\"pooled_output\"]\n",
        "    \n",
        "    \n",
        "    if valid_context:\n",
        "      \n",
        "      # context processing - training\n",
        "      context_inputs = dict(input_ids=context_input_ids,\n",
        "                         input_mask=context_input_mask, \n",
        "                         segment_ids=context_segment_ids)\n",
        "      context_embeddings = embedder(inputs=context_inputs,\n",
        "                                 signature=\"tokens\", \n",
        "                                 as_dict=True)\n",
        "      context_xs = context_embeddings[\"pooled_output\"]\n",
        "      context_ys = context_scores\n",
        "      # total x,y \n",
        "      x_all = tf.concat([context_xs, target_xs], axis=0)\n",
        "      \n",
        "      # get encoding params with context\n",
        "      context_z_dist = self.encoder(context_xs, context_ys)\n",
        "      # predictions with context\n",
        "      posterior_pred = self.decoder(target_xs, context_z_dist.sample(self.num_draws))\n",
        "        \n",
        "       # target scores - context training / evaluation\n",
        "      if target_scores is not None:\n",
        "        target_ys = target_scores\n",
        "        y_all = tf.concat([context_ys, target_ys], axis=0)\n",
        "        all_z_dist = self.encoder(x_all, y_all)\n",
        "        \n",
        "        # loss\n",
        "        loglike = self.loglikelihood(target_ys, posterior_pred)\n",
        "        KL_loss = self.KLqp_gaussian(all_z_dist.parameters['loc'], \n",
        "                                     all_z_dist.parameters['scale_diag'], \n",
        "                                     context_z_dist.parameters['loc'], \n",
        "                                     context_z_dist.parameters['scale_diag'])\n",
        "        loss = tf.negative(loglike) + KL_loss\n",
        "        # context and training / evaluation\n",
        "        return (loss, posterior_pred, target_ys)\n",
        "      \n",
        "      # context prediction\n",
        "      return  (None, posterior_pred, None)\n",
        "    \n",
        "    # no context\n",
        "    else:\n",
        "      x_all = target_xs \n",
        "      # get internal representation\n",
        "      mean_zero = tf.constant(np.repeat(0., params.dim_z))\n",
        "      epsilon_dist = tfd.MultivariateNormalDiag(loc= mean_zero)                            \n",
        "      epsilon = tf.expand_dims(epsilon_dist.sample(self.num_draws), axis=1)\n",
        "      epsilon = tf.cast(epsilon, tf.float32)\n",
        "      prior_predict = self.decoder(x_all, epsilon)\n",
        "      \n",
        "      # target scores - no context training / evaluation\n",
        "      if target_scores is not None:\n",
        "        target_ys = target_scores\n",
        "        loglike = self.loglikelihood(target_ys, prior_predict)\n",
        "        loss = tf.negative(loglike)\n",
        "        # no context/ training / evaluation\n",
        "        return  (loss, prior_predict, target_ys)\n",
        "   \n",
        "    \n",
        "      # no context prediction\n",
        "      return  (None, prior_predict, None)\n",
        "\n",
        "  \n",
        "  def loglikelihood(self, y_star: tf.Tensor, dist):\n",
        "    \"\"\"Log-likelihood of an output given a predicted \"\"\"\n",
        "    p_normal = tfd.MultivariateNormalDiag(loc = dist.mu, scale_diag=dist.sigma)\n",
        "    loglike = p_normal.log_prob(y_star)\n",
        "    loglike = tf.reduce_sum(loglike, axis=0)\n",
        "    loglike = tf.reduce_mean(loglike)\n",
        "    return loglike\n",
        "  \n",
        "  def KLqp_gaussian(self, mu_q: tf.Tensor, sigma_q: tf.Tensor, mu_p: tf.Tensor, sigma_p: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Kullback-Leibler divergence between two Gaussian distributions\n",
        "\n",
        "    Determines KL(q || p) = < log( q / p ) >_q\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mu_q\n",
        "        Mean tensor of distribution q, shape: (1, dim)\n",
        "    sigma_q\n",
        "        Variance tensor of distribution q, shape: (1, dim)\n",
        "    mu_p\n",
        "        Mean tensor of distribution p, shape: (1, dim)\n",
        "    sigma_p\n",
        "        Variance tensor of distribution p, shape: (1, dim)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        KL tensor, shape: (1)\n",
        "    \"\"\"\n",
        "    sigma2_q = tf.square(sigma_q) + 1e-16\n",
        "    sigma2_p = tf.square(sigma_p) + 1e-16\n",
        "    temp = sigma2_q / sigma2_p + tf.square(mu_q - mu_p) / sigma2_p - 1.0 + tf.log(sigma2_p / sigma2_q + 1e-16)\n",
        "    return 0.5 * tf.reduce_sum(temp)\n",
        "  \n",
        "  def context_target_split(self, batch_size =32):\n",
        "    btch_sz = batch_size\n",
        "    n_context = tf.random_shuffle(tf.range(1,btch_sz))[0]\n",
        "    \n",
        "    indices = tf.range(0, btch_sz)\n",
        "    context_set_indices = tf.gather(tf.random_shuffle(indices),tf.range(n_context))\n",
        "    target_set_indices = tf.gather(tf.random_shuffle(indices),tf.range(n_context, btch_sz))\n",
        "    \n",
        "    return context_set_indices, target_set_indices\n",
        "    \n",
        "  def model_fn_builder(self, num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
        "      \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "      \n",
        "      \n",
        "      def model_fn(features, mode, params):  # pylint: disable=unused-argument\n",
        "          \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "          \n",
        "          # run model\n",
        "          # -------------------------------------------------------------------------------------------\n",
        "          target_input_ids = None\n",
        "          target_input_mask = None\n",
        "          target_segment_ids = None \n",
        "          target_scores = None\n",
        "          \n",
        "          context_input_ids = None \n",
        "          context_input_mask = None \n",
        "          context_segment_ids = None\n",
        "          context_scores = None\n",
        "          \n",
        "          # training \n",
        "          if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            input_ids = features[\"input_ids\"]\n",
        "            input_mask = features[\"input_mask\"]\n",
        "            segment_ids = features[\"segment_ids\"]    \n",
        "            scores = features[\"scores\"]\n",
        "            \n",
        "            # context split\n",
        "            context_set_indices, target_set_indices= self.context_target_split(batch_size =32)\n",
        "            \n",
        "            target_input_ids = tf.gather(input_ids,target_set_indices)\n",
        "            target_input_mask = tf.gather(input_mask,target_set_indices)\n",
        "            target_segment_ids = tf.gather(segment_ids,target_set_indices) \n",
        "            target_scores = tf.gather(scores,target_set_indices)\n",
        "\n",
        "            context_input_ids = tf.gather(input_ids,context_set_indices) \n",
        "            context_input_mask = tf.gather(input_mask,context_set_indices) \n",
        "            context_segment_ids = tf.gather(segment_ids,context_set_indices)\n",
        "            context_scores = tf.gather(scores,context_set_indices)\n",
        "            \n",
        "            \n",
        "          elif mode == tf.estimator.ModeKeys.PREDICT:\n",
        "            print('Prediction')\n",
        "            target_input_ids = features[\"input_ids\"]\n",
        "            target_input_mask = features[\"input_mask\"]\n",
        "            target_segment_ids = features[\"segment_ids\"]    \n",
        "            target_scores = features[\"scores\"]\n",
        "            \n",
        "            try:\n",
        "              context_input_ids = features[\"supplied_context_input_ids\"][0]\n",
        "              context_input_mask = features[\"supplied_context_input_mask\"][0]\n",
        "              context_segment_ids = features[\"supplied_context_segment_ids\"][0] \n",
        "              context_scores = features[\"supplied_context_scores\"][0]\n",
        "               \n",
        "            except:\n",
        "              print(\"****No context supplied ****\")\n",
        "              context_input_ids = None\n",
        "              context_input_mask = None\n",
        "              context_segment_ids = None\n",
        "              context_scores = None\n",
        "            \n",
        "          else:\n",
        "            print('Evaluation')\n",
        "            target_input_ids = features[\"input_ids\"]\n",
        "            target_input_mask = features[\"input_mask\"]\n",
        "            target_segment_ids = features[\"segment_ids\"]    \n",
        "            target_scores = features[\"scores\"]\n",
        "\n",
        "            try:\n",
        "              context_input_ids = features[\"supplied_context_input_ids\"][0]\n",
        "              context_input_mask = features[\"supplied_context_input_mask\"][0]\n",
        "              context_segment_ids = features[\"supplied_context_segment_ids\"][0] \n",
        "              context_scores = features[\"supplied_context_scores\"][0]\n",
        "               \n",
        "            except:\n",
        "              print(\"****No context supplied ****\")\n",
        "              context_input_ids = None\n",
        "              context_input_mask = None\n",
        "              context_segment_ids = None\n",
        "              context_scores = None\n",
        "\n",
        "\n",
        "          (loss, prediction, true_y) = self.create_model(target_input_ids, \n",
        "                                                         target_input_mask, \n",
        "                                                         target_segment_ids, \n",
        "                                                         target_scores,\n",
        "                                                         context_input_ids, \n",
        "                                                         context_input_mask, \n",
        "                                                         context_segment_ids, \n",
        "                                                         context_scores)\n",
        "\n",
        "          train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "          ystar, _ = tf.nn.moments(prediction.mu,[0])\n",
        "          variance, _ = tf.nn.moments(tf.math.square(prediction.sigma),[0])\n",
        "          \n",
        "          # Calculate evaluation metrics\n",
        "          eval_metrics = {}\n",
        "          # AUC\n",
        "          def metric_fn(pred_scores, real_scores, trait_num):\n",
        "              auc_value = tf.metrics.auc(real_scores[:,trait_num], pred_scores[:,trait_num])\n",
        "              accuracy_value = tf.metrics.accuracy(labels = tf.round(real_scores[:,trait_num]), predictions=tf.round(pred_scores[:,trait_num]))\n",
        "              recall_value = tf.metrics.recall(labels = tf.round(real_scores[:,trait_num]), predictions=tf.round(pred_scores[:,trait_num]))\n",
        "              precision_value = tf.metrics.precision(labels = tf.round(real_scores[:,trait_num]), predictions=tf.round(pred_scores[:,trait_num]))\n",
        "              return {\"auc\"+str(trait_num): auc_value, \"accuracy\"+str(trait_num): accuracy_value, \"recall\"+str(trait_num): recall_value, \"precision\"+str(trait_num):precision_value}\n",
        "\n",
        "          labels = true_y # need to round them if true labels are not 1 or 0\n",
        "          eval_metrics_lst = [metric_fn(ystar, labels, trait_num) for trait_num in range(num_labels)]\n",
        "\n",
        "          for d in eval_metrics_lst:\n",
        "              tf.summary.scalar(list(d.keys())[0], list(d.values())[0][1])  # make available to tensorboard\n",
        "              tf.summary.scalar(list(d.keys())[1], list(d.values())[1][1])  # make available to tensorboard\n",
        "              eval_metrics.update(d)\n",
        "              \n",
        "          \n",
        "          # output from model\n",
        "          # -------------------------------------------------------------------------------------------\n",
        "\n",
        "          # training \n",
        "          if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "              return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "\n",
        "          # prediction\n",
        "          elif mode == tf.estimator.ModeKeys.PREDICT:\n",
        "              return tf.estimator.EstimatorSpec(mode=mode, predictions={'prediction_mean': ystar, 'prediction_var': variance})\n",
        "\n",
        "          # evaluation\n",
        "          else:\n",
        "            return tf.estimator.EstimatorSpec(mode=mode,loss=loss, eval_metric_ops=eval_metrics)\n",
        "\n",
        "      return model_fn\n",
        "\n",
        "\n",
        "  def prepare_examples(self, df, score_column, text_col_name, supplied_context_df=None):\n",
        "      num_labels = len(score_column)\n",
        "      input_examples = create_examples(df, score_column, text_col_name)\n",
        "      input_features = convert_examples_to_features(input_examples, max_seq_length, tokenizer)\n",
        "      \n",
        "      if supplied_context_df is not None:\n",
        "        supplied_context_examples = create_examples(supplied_context_df, score_column, text_col_name)\n",
        "        supplied_context_features = convert_examples_to_features(supplied_context_examples, max_seq_length, tokenizer)\n",
        "        input_fn = input_fn_builder(\n",
        "          features=input_features, seq_length=max_seq_length, \n",
        "          num_labels = num_labels, is_training=True, drop_remainder=False,\n",
        "          supplied_context_features = supplied_context_features)\n",
        "      \n",
        "      else:\n",
        "        input_fn = input_fn_builder(\n",
        "          features=input_features, seq_length=max_seq_length, \n",
        "          num_labels = num_labels, is_training=True, drop_remainder=False)\n",
        "        \n",
        "      return input_fn\n",
        "  \n",
        "  def predict(self, \n",
        "            df, \n",
        "            score_col, \n",
        "            text_col,\n",
        "            supplied_context_df=None\n",
        "             ):\n",
        "    \n",
        "    pred_input_fn = self.prepare_examples(df, score_col, text_col, supplied_context_df)\n",
        "    preds = self.estimator.predict(input_fn=pred_input_fn)\n",
        "    \n",
        "    return preds\n",
        "  \n",
        "  def evaluate(self, \n",
        "               eval_steps,\n",
        "               df, \n",
        "               score_col, \n",
        "               text_col,\n",
        "               supplied_context_df=None):\n",
        "    \n",
        "    eval_input_fn = self.prepare_examples(df, score_col, text_col, supplied_context_df)\n",
        "    \n",
        "    result = self.estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "    return result\n",
        "  \n",
        "  def train(self,num_train_steps,\n",
        "            df_train, \n",
        "            score_col, \n",
        "            text_col,\n",
        "           ):\n",
        "\n",
        "    # Create an input function for training. drop_remainder = True for using TPUs.\n",
        "    train_input_fn = self.prepare_examples(df_train, score_col, text_col)\n",
        "\n",
        "    print('Beginning Training!')\n",
        "    current_time = datetime.now()\n",
        "    self.estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "    print(\"Training took time \", datetime.now() - current_time)\n",
        "    \n",
        "  \n",
        "  def train_and_evaluate(self,\n",
        "                         df_train,\n",
        "                         df_eval,\n",
        "                         score_col, \n",
        "                         text_col,\n",
        "                         num_train_steps,\n",
        "                         eval_steps,\n",
        "                         supplied_context_df=None):\n",
        "    \n",
        "    train_input_fn = self.prepare_examples(df_train, score_col, text_col)\n",
        "    eval_input_fn = self.prepare_examples(df_eval, score_col, text_col, supplied_context_df)\n",
        "    \n",
        "    train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "    eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn, steps = eval_steps)\n",
        "    \n",
        "    result = tf.estimator.train_and_evaluate(self.estimator, train_spec, eval_spec)\n",
        "    return result\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z8iSEczc6NS1",
        "outputId": "71be3c30-b32b-4ad9-e442-72bd345eef7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "\n",
        "# tf.reset_default_graph()\n",
        "\n",
        "params = NeuralProcessParams(dim_z=1000, n_hidden_units_h=[512, 256, 128], n_hidden_units_g=[512, 256, 128])\n",
        "num_train_steps = 10*(10**3)\n",
        "\n",
        "neural_process = NLP_NeuralProcess(score_col=score_column, params = params, num_draws = 25, \n",
        "                                   num_train_steps=num_train_steps,\n",
        "                                   num_classes = len(score_column),\n",
        "                                   output_dir = OUTPUT_DIR,\n",
        "                                  context_features = None)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0706 12:37:36.271553 140042348476288 estimator.py:209] Using config: {'_model_dir': 'gs://rail_jigsaw_modeling/unhealthy/models/batch32_attributeOverrep', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5d8204ea20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFg8H0rdqjc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-3t1yb4RrW5y",
        "outputId": "ff0b4fc2-ec8d-4f0b-ae41-3f5159c39a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# df_test = test_df\n",
        "batch_size = 32\n",
        "eval_steps = int(len(df_val) / batch_size)\n",
        "\n",
        "neural_process.train_and_evaluate(df_train=df_train,\n",
        "                                  df_eval = df_val,\n",
        "                                  num_train_steps=num_train_steps,\n",
        "                                  eval_steps = eval_steps,\n",
        "                                  score_col= score_column, \n",
        "                                  text_col=text_col_name,)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0630 12:17:29.022473 139930856781696 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "I0630 12:17:29.024063 139930856781696 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "I0630 12:17:29.028314 139930856781696 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 500 or save_checkpoints_secs None.\n",
            "W0630 12:17:29.442076 139930856781696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "I0630 12:18:23.633392 139930856781696 estimator.py:1145] Calling model_fn.\n",
            "I0630 12:18:26.547310 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "I0630 12:18:27.947446 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "W0630 12:18:28.087571 139930856781696 deprecation.py:323] From <ipython-input-18-504275df30f7>:28: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0630 12:18:28.097326 139930856781696 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"module_apply_tokens_1/bert/pooler/dense/Tanh:0\", shape=(?, 768), dtype=float32)\n",
            "Tensor(\"GatherV2_9:0\", shape=(?, 6), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0630 12:18:28.797109 139930856781696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0630 12:18:28.799007 139930856781696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0630 12:18:28.809202 139930856781696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0630 12:18:28.824592 139930856781696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"concat:0\", shape=(?, 768), dtype=float32)\n",
            "Tensor(\"concat_3:0\", shape=(?, 6), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0630 12:18:29.437728 139930856781696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0630 12:18:36.755431 139930856781696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:117: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 12:18:43.145132 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 12:18:43.148022 139930856781696 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "I0630 12:18:53.322780 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 12:18:59.748972 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 12:19:00.095987 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 12:19:55.682920 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 0 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 12:20:57.487246 139930856781696 basic_session_run_hooks.py:262] loss = 127.098755, step = 0\n",
            "I0630 12:23:04.054623 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.790088\n",
            "I0630 12:23:10.697586 139930856781696 basic_session_run_hooks.py:260] loss = -99.323555, step = 100 (133.210 sec)\n",
            "I0630 12:24:38.234116 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.0618\n",
            "I0630 12:24:38.235441 139930856781696 basic_session_run_hooks.py:260] loss = -185.84921, step = 200 (87.538 sec)\n",
            "I0630 12:26:11.939660 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.06717\n",
            "I0630 12:26:11.941083 139930856781696 basic_session_run_hooks.py:260] loss = -185.7201, step = 300 (93.706 sec)\n",
            "I0630 12:27:39.564982 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14122\n",
            "I0630 12:27:39.567105 139930856781696 basic_session_run_hooks.py:260] loss = -189.52917, step = 400 (87.626 sec)\n",
            "I0630 12:29:11.498656 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 500 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 12:29:59.288016 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 12:30:02.645590 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 12:30:13.410769 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 12:30:13.434401 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T12:30:13Z\n",
            "I0630 12:30:14.859549 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "W0630 12:30:14.868614 139930856781696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0630 12:30:15.064345 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-500\n",
            "I0630 12:32:39.623459 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 12:32:39.990456 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 12:32:53.776784 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 12:33:05.410713 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 12:33:17.215165 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 12:33:29.215169 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 12:33:41.415235 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 12:33:53.634558 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 12:34:05.851562 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 12:34:18.041480 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 12:34:30.231650 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 12:34:42.428906 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 12:34:42.972239 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-12:34:42\n",
            "I0630 12:34:42.973526 139930856781696 estimator.py:2039] Saving dict for global step 500: accuracy0 = 0.94484377, accuracy1 = 0.933125, accuracy2 = 0.9467969, accuracy3 = 0.99625, accuracy4 = 0.9472656, accuracy5 = 0.96484375, auc0 = 0.9173848, auc1 = 0.96705395, auc2 = 0.96149516, auc3 = 0.93385106, auc4 = 0.9511059, auc5 = 0.8617424, global_step = 500, loss = -115.599915, precision0 = 0.8122363, precision1 = 0.12654321, precision2 = 0.5915493, precision3 = 0.0, precision4 = 0.58444816, precision5 = 0.155, recall0 = 0.7245922, recall1 = 0.9461538, recall2 = 0.89266735, recall3 = 0.0, recall4 = 0.79703534, recall5 = 0.35632184\n",
            "I0630 12:34:51.838884 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 500: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-500\n",
            "I0630 12:34:54.683645 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.229822\n",
            "I0630 12:35:00.337498 139930856781696 basic_session_run_hooks.py:260] loss = -47.725185, step = 500 (440.770 sec)\n",
            "I0630 12:36:28.480456 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.06613\n",
            "I0630 12:36:28.481921 139930856781696 basic_session_run_hooks.py:260] loss = -190.00237, step = 600 (88.144 sec)\n",
            "I0630 12:38:01.817176 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.07139\n",
            "I0630 12:38:01.818772 139930856781696 basic_session_run_hooks.py:260] loss = -11.479952, step = 700 (93.337 sec)\n",
            "I0630 12:39:29.452539 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14109\n",
            "I0630 12:39:29.453903 139930856781696 basic_session_run_hooks.py:260] loss = -90.522934, step = 800 (87.635 sec)\n",
            "I0630 12:41:02.023653 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.08025\n",
            "I0630 12:41:02.025155 139930856781696 basic_session_run_hooks.py:260] loss = -180.72342, step = 900 (92.571 sec)\n",
            "I0630 12:42:28.688961 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 1000 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 12:43:26.139230 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 12:43:30.122241 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 12:43:40.871770 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 12:43:40.894231 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T12:43:40Z\n",
            "I0630 12:43:42.323871 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 12:43:42.533148 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-1000\n",
            "I0630 12:45:40.751950 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 12:45:41.152460 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 12:45:54.976834 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 12:46:06.646727 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 12:46:18.547751 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 12:46:30.827840 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 12:46:43.316891 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 12:46:55.701706 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 12:47:07.912388 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 12:47:20.094521 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 12:47:32.220152 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 12:47:44.404087 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 12:47:44.947424 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-12:47:44\n",
            "I0630 12:47:44.948734 139930856781696 estimator.py:2039] Saving dict for global step 1000: accuracy0 = 0.9388281, accuracy1 = 0.96421874, accuracy2 = 0.96828127, accuracy3 = 0.99625, accuracy4 = 0.95515627, accuracy5 = 0.9610937, auc0 = 0.89060813, auc1 = 0.97444695, auc2 = 0.95669997, auc3 = 0.888631, auc4 = 0.94312334, auc5 = 0.90054405, global_step = 1000, loss = -113.59689, precision0 = 0.9272152, precision1 = 0.20430107, precision2 = 0.85019714, precision3 = 0.0, precision4 = 0.7165468, precision5 = 0.17206478, recall0 = 0.5517891, recall1 = 0.890625, recall2 = 0.6890309, recall3 = 0.0, recall4 = 0.5691429, recall5 = 0.48850575\n",
            "I0630 12:47:46.966558 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1000: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-1000\n",
            "I0630 12:47:49.781467 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.245244\n",
            "I0630 12:47:56.197816 139930856781696 basic_session_run_hooks.py:260] loss = -101.53324, step = 1000 (414.173 sec)\n",
            "I0630 12:49:24.209808 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.059\n",
            "I0630 12:49:24.211426 139930856781696 basic_session_run_hooks.py:260] loss = -185.90773, step = 1100 (88.014 sec)\n",
            "I0630 12:50:57.343646 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.07372\n",
            "I0630 12:50:57.345297 139930856781696 basic_session_run_hooks.py:260] loss = -76.130516, step = 1200 (93.134 sec)\n",
            "I0630 12:52:25.013304 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14065\n",
            "I0630 12:52:25.014775 139930856781696 basic_session_run_hooks.py:260] loss = -196.66037, step = 1300 (87.669 sec)\n",
            "I0630 12:53:58.662321 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.06782\n",
            "I0630 12:53:58.663933 139930856781696 basic_session_run_hooks.py:260] loss = -181.63681, step = 1400 (93.649 sec)\n",
            "I0630 12:55:25.520720 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 1500 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 12:56:19.185831 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 12:56:23.196036 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 12:56:34.188732 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 12:56:34.214434 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T12:56:34Z\n",
            "I0630 12:56:35.684769 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 12:56:35.914680 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-1500\n",
            "I0630 12:58:51.141942 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 12:58:51.542577 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 12:59:05.500768 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 12:59:17.185294 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 12:59:29.033351 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 12:59:41.196535 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 12:59:53.425696 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 13:00:05.817965 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 13:00:18.153236 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 13:00:30.344346 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 13:00:42.539479 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 13:00:54.736646 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 13:00:55.293681 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-13:00:55\n",
            "I0630 13:00:55.294855 139930856781696 estimator.py:2039] Saving dict for global step 1500: accuracy0 = 0.9447656, accuracy1 = 0.9725781, accuracy2 = 0.9690625, accuracy3 = 0.99625, accuracy4 = 0.9567969, accuracy5 = 0.97976565, auc0 = 0.96785635, auc1 = 0.98524374, auc2 = 0.98212284, auc3 = 0.9392056, auc4 = 0.974657, auc5 = 0.945935, global_step = 1500, loss = -143.63872, precision0 = 0.8927305, precision1 = 0.24423963, precision2 = 0.8317073, precision3 = 0.0, precision4 = 0.7511664, precision5 = 0.2746114, recall0 = 0.63214064, recall1 = 0.8217054, recall2 = 0.72553194, recall3 = 0.0, recall4 = 0.55136985, recall5 = 0.30813953\n",
            "I0630 13:00:56.750009 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1500: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-1500\n",
            "I0630 13:00:59.587941 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.237572\n",
            "I0630 13:01:06.206128 139930856781696 basic_session_run_hooks.py:260] loss = -42.38348, step = 1500 (427.542 sec)\n",
            "I0630 13:02:34.259843 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.05628\n",
            "I0630 13:02:34.265829 139930856781696 basic_session_run_hooks.py:260] loss = 63.632313, step = 1600 (88.060 sec)\n",
            "I0630 13:04:10.026634 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.0442\n",
            "I0630 13:04:10.028107 139930856781696 basic_session_run_hooks.py:260] loss = -207.54591, step = 1700 (95.762 sec)\n",
            "I0630 13:05:37.923849 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.13769\n",
            "I0630 13:05:37.925703 139930856781696 basic_session_run_hooks.py:260] loss = -198.20169, step = 1800 (87.898 sec)\n",
            "I0630 13:07:14.771947 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.03254\n",
            "I0630 13:07:14.773897 139930856781696 basic_session_run_hooks.py:260] loss = -147.12552, step = 1900 (96.848 sec)\n",
            "I0630 13:08:41.837614 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 2000 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 13:09:38.063406 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 13:09:40.435351 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 13:09:51.166447 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 13:09:51.189424 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T13:09:51Z\n",
            "I0630 13:09:53.848002 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 13:09:54.060300 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-2000\n",
            "I0630 13:12:01.973761 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 13:12:02.282515 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 13:12:16.036235 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 13:12:28.208979 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 13:12:40.859935 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 13:12:53.644406 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 13:13:06.065397 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 13:13:18.278913 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 13:13:30.376253 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 13:13:42.474024 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 13:13:54.645963 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 13:14:06.839271 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 13:14:07.352098 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-13:14:07\n",
            "I0630 13:14:07.353347 139930856781696 estimator.py:2039] Saving dict for global step 2000: accuracy0 = 0.9515625, accuracy1 = 0.9717969, accuracy2 = 0.9585937, accuracy3 = 0.99625, accuracy4 = 0.958125, accuracy5 = 0.96921873, auc0 = 0.9476724, auc1 = 0.98437107, auc2 = 0.97853774, auc3 = 0.9368448, auc4 = 0.96661156, auc5 = 0.9326799, global_step = 2000, loss = -139.52708, precision0 = 0.8435952, precision1 = 0.23755656, precision2 = 0.6683087, precision3 = 0.0, precision4 = 0.67823344, precision5 = 0.1904762, recall0 = 0.74921435, recall1 = 0.81395346, recall2 = 0.86595744, recall3 = 0.0, recall4 = 0.73714286, recall5 = 0.39306358\n",
            "I0630 13:14:10.380240 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 2000: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-2000\n",
            "I0630 13:14:13.249814 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.238961\n",
            "I0630 13:14:23.200550 139930856781696 basic_session_run_hooks.py:260] loss = -198.84549, step = 2000 (428.427 sec)\n",
            "I0630 13:15:51.382227 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.01903\n",
            "I0630 13:15:51.383589 139930856781696 basic_session_run_hooks.py:260] loss = -207.5443, step = 2100 (88.183 sec)\n",
            "I0630 13:17:25.378700 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.06387\n",
            "I0630 13:17:25.380130 139930856781696 basic_session_run_hooks.py:260] loss = -172.82962, step = 2200 (93.997 sec)\n",
            "I0630 13:18:53.143664 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.13941\n",
            "I0630 13:18:53.145226 139930856781696 basic_session_run_hooks.py:260] loss = -204.52928, step = 2300 (87.765 sec)\n",
            "I0630 13:20:26.855060 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.06711\n",
            "I0630 13:20:26.856537 139930856781696 basic_session_run_hooks.py:260] loss = -188.02907, step = 2400 (93.711 sec)\n",
            "I0630 13:21:53.583503 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 2500 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "W0630 13:22:27.050174 139930856781696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "I0630 13:22:48.296004 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 13:22:50.678394 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 13:23:02.041162 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 13:23:02.065765 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T13:23:02Z\n",
            "I0630 13:23:03.500823 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 13:23:03.724622 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-2500\n",
            "I0630 13:25:18.153517 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 13:25:18.498854 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 13:25:32.281924 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 13:25:44.296864 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 13:25:56.681140 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 13:26:09.377498 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 13:26:21.780694 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 13:26:33.966416 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 13:26:45.974211 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 13:26:57.950095 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 13:27:09.946522 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 13:27:22.050849 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 13:27:22.628782 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-13:27:22\n",
            "I0630 13:27:22.629962 139930856781696 estimator.py:2039] Saving dict for global step 2500: accuracy0 = 0.9478125, accuracy1 = 0.9585937, accuracy2 = 0.96546876, accuracy3 = 0.99625, accuracy4 = 0.9603906, accuracy5 = 0.9599219, auc0 = 0.93671405, auc1 = 0.98360693, auc2 = 0.97122484, auc3 = 0.906049, auc4 = 0.9698035, auc5 = 0.9361186, global_step = 2500, loss = -134.57233, precision0 = 0.91119003, precision1 = 0.18524332, precision2 = 0.7517659, precision3 = 0.0, precision4 = 0.7113402, precision5 = 0.18435754, recall0 = 0.64366376, recall1 = 0.9147287, recall2 = 0.791711, recall3 = 0.0, recall4 = 0.7089041, recall5 = 0.5689655\n",
            "I0630 13:27:24.565857 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 2500: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-2500\n",
            "I0630 13:27:27.426238 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.237772\n",
            "I0630 13:27:35.356599 139930856781696 basic_session_run_hooks.py:260] loss = -196.84615, step = 2500 (428.500 sec)\n",
            "I0630 13:29:03.530928 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.04053\n",
            "I0630 13:29:03.532478 139930856781696 basic_session_run_hooks.py:260] loss = -170.93617, step = 2600 (88.176 sec)\n",
            "I0630 13:30:36.672072 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.07364\n",
            "I0630 13:30:36.673527 139930856781696 basic_session_run_hooks.py:260] loss = -49.006725, step = 2700 (93.141 sec)\n",
            "I0630 13:32:04.193269 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14258\n",
            "I0630 13:32:04.194572 139930856781696 basic_session_run_hooks.py:260] loss = -37.31442, step = 2800 (87.521 sec)\n",
            "I0630 13:33:38.518625 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.06016\n",
            "I0630 13:33:38.520482 139930856781696 basic_session_run_hooks.py:260] loss = -207.54553, step = 2900 (94.326 sec)\n",
            "I0630 13:35:05.189974 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 3000 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 13:36:01.334971 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 13:36:05.449781 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 13:36:16.174699 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 13:36:16.199861 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T13:36:16Z\n",
            "I0630 13:36:17.621978 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 13:36:17.827485 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-3000\n",
            "I0630 13:38:32.938745 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 13:38:33.380973 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 13:38:46.990318 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 13:38:58.650464 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 13:39:10.444082 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 13:39:22.501302 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 13:39:34.716029 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 13:39:46.956250 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 13:39:59.170853 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 13:40:11.377863 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 13:40:23.588388 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 13:40:35.796574 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 13:40:36.340818 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-13:40:36\n",
            "I0630 13:40:36.342032 139930856781696 estimator.py:2039] Saving dict for global step 3000: accuracy0 = 0.95304686, accuracy1 = 0.9803906, accuracy2 = 0.96671873, accuracy3 = 0.99625, accuracy4 = 0.9567969, accuracy5 = 0.97945315, auc0 = 0.97216755, auc1 = 0.9867519, auc2 = 0.98224044, auc3 = 0.9315867, auc4 = 0.97801465, auc5 = 0.96345586, global_step = 3000, loss = -148.60611, precision0 = 0.89125293, precision1 = 0.30914825, precision2 = 0.7721519, precision3 = 0.0, precision4 = 0.7575277, precision5 = 0.2857143, recall0 = 0.7095358, recall1 = 0.75384617, recall2 = 0.77707005, recall3 = 0.0, recall4 = 0.5444191, recall5 = 0.3468208\n",
            "I0630 13:40:38.378165 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 3000: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-3000\n",
            "I0630 13:40:41.252040 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.236556\n",
            "I0630 13:40:48.101046 139930856781696 basic_session_run_hooks.py:260] loss = 1418.971, step = 3000 (429.581 sec)\n",
            "I0630 13:42:16.099141 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.05433\n",
            "I0630 13:42:16.100989 139930856781696 basic_session_run_hooks.py:260] loss = -202.47093, step = 3100 (88.000 sec)\n",
            "I0630 13:43:49.893627 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.06616\n",
            "I0630 13:43:49.895220 139930856781696 basic_session_run_hooks.py:260] loss = -21.118132, step = 3200 (93.794 sec)\n",
            "I0630 13:45:17.316330 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14387\n",
            "I0630 13:45:24.004229 139930856781696 basic_session_run_hooks.py:260] loss = -202.82283, step = 3300 (94.109 sec)\n",
            "I0630 13:46:51.781676 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.05859\n",
            "I0630 13:46:51.783148 139930856781696 basic_session_run_hooks.py:260] loss = -193.37299, step = 3400 (87.779 sec)\n",
            "I0630 13:48:26.039698 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 3500 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 13:49:17.389240 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 13:49:21.404393 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 13:49:32.168141 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 13:49:32.191591 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T13:49:32Z\n",
            "I0630 13:49:34.836625 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 13:49:35.049833 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-3500\n",
            "I0630 13:51:46.650627 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 13:51:46.997096 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 13:52:00.648974 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 13:52:12.297093 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 13:52:24.016271 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 13:52:35.915874 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 13:52:48.120218 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 13:53:00.447009 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 13:53:12.644603 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 13:53:24.838762 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 13:53:36.992691 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 13:53:49.099439 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 13:53:49.657717 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-13:53:49\n",
            "I0630 13:53:49.658989 139930856781696 estimator.py:2039] Saving dict for global step 3500: accuracy0 = 0.9501563, accuracy1 = 0.9853906, accuracy2 = 0.96898437, accuracy3 = 0.99625, accuracy4 = 0.9600781, accuracy5 = 0.9821875, auc0 = 0.9559914, auc1 = 0.9869875, auc2 = 0.97791, auc3 = 0.9209299, auc4 = 0.97239035, auc5 = 0.94237286, global_step = 3500, loss = -142.3102, precision0 = 0.9147826, precision1 = 0.36651585, precision2 = 0.77451974, precision3 = 0.0, precision4 = 0.73445594, precision5 = 0.33125, recall0 = 0.66080403, recall1 = 0.6328125, recall2 = 0.8148936, recall3 = 0.0, recall4 = 0.6494845, recall5 = 0.3045977\n",
            "I0630 13:53:51.613577 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 3500: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-3500\n",
            "I0630 13:53:54.429758 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.236604\n",
            "I0630 13:54:01.046442 139930856781696 basic_session_run_hooks.py:260] loss = -193.35703, step = 3500 (429.263 sec)\n",
            "I0630 13:55:28.827211 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.05935\n",
            "I0630 13:55:28.828525 139930856781696 basic_session_run_hooks.py:260] loss = -113.95857, step = 3600 (87.782 sec)\n",
            "I0630 13:57:02.133767 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.07174\n",
            "I0630 13:57:02.135260 139930856781696 basic_session_run_hooks.py:260] loss = -146.46481, step = 3700 (93.307 sec)\n",
            "I0630 13:58:29.642882 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14274\n",
            "I0630 13:58:36.336951 139930856781696 basic_session_run_hooks.py:260] loss = -207.54657, step = 3800 (94.202 sec)\n",
            "I0630 14:00:04.085202 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.05885\n",
            "I0630 14:00:04.086633 139930856781696 basic_session_run_hooks.py:260] loss = -115.78955, step = 3900 (87.750 sec)\n",
            "I0630 14:01:36.187499 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 4000 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 14:02:26.210456 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 14:02:28.595721 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 14:02:39.942305 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 14:02:39.967237 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T14:02:39Z\n",
            "I0630 14:02:41.393887 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 14:02:41.598360 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-4000\n",
            "I0630 14:04:55.244374 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 14:04:55.633234 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 14:05:09.468139 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 14:05:21.155070 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 14:05:33.090701 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 14:05:45.308546 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 14:05:57.613447 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 14:06:09.907487 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 14:06:22.121345 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 14:06:34.331318 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 14:06:46.517686 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 14:06:58.717522 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 14:06:59.295545 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-14:06:59\n",
            "I0630 14:06:59.296746 139930856781696 estimator.py:2039] Saving dict for global step 4000: accuracy0 = 0.9541406, accuracy1 = 0.96546876, accuracy2 = 0.96203125, accuracy3 = 0.99625, accuracy4 = 0.95632815, accuracy5 = 0.9664062, auc0 = 0.96047825, auc1 = 0.9855982, auc2 = 0.98484653, auc3 = 0.92218053, auc4 = 0.97479635, auc5 = 0.9490051, global_step = 4000, loss = -147.09041, precision0 = 0.8649238, precision1 = 0.21389396, precision2 = 0.6836983, precision3 = 0.0, precision4 = 0.6456984, precision5 = 0.2072893, recall0 = 0.7481156, recall1 = 0.90697676, recall2 = 0.89776355, recall3 = 0.0, recall4 = 0.798627, recall5 = 0.5260116\n",
            "I0630 14:07:00.895824 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 4000: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-4000\n",
            "I0630 14:07:03.754005 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.238283\n",
            "I0630 14:07:09.522767 139930856781696 basic_session_run_hooks.py:260] loss = -207.35385, step = 4000 (425.436 sec)\n",
            "I0630 14:08:37.298839 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.06901\n",
            "I0630 14:08:37.300271 139930856781696 basic_session_run_hooks.py:260] loss = -166.96547, step = 4100 (87.778 sec)\n",
            "I0630 14:10:12.166554 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.0541\n",
            "I0630 14:10:12.168146 139930856781696 basic_session_run_hooks.py:260] loss = -123.62465, step = 4200 (94.868 sec)\n",
            "I0630 14:11:39.704332 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14236\n",
            "I0630 14:11:45.418885 139930856781696 basic_session_run_hooks.py:260] loss = 275.06387, step = 4300 (93.251 sec)\n",
            "I0630 14:13:13.025742 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.07157\n",
            "I0630 14:13:13.027350 139930856781696 basic_session_run_hooks.py:260] loss = -36.856796, step = 4400 (87.608 sec)\n",
            "I0630 14:14:46.725654 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 4500 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 14:15:35.615378 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 14:15:39.667065 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 14:15:50.554215 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 14:15:50.580609 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T14:15:50Z\n",
            "I0630 14:15:52.024901 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 14:15:52.236159 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-4500\n",
            "I0630 14:17:46.171339 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 14:17:46.598816 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 14:18:00.283322 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 14:18:12.000016 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 14:18:23.902122 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 14:18:36.194870 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 14:18:48.682887 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 14:19:01.119397 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 14:19:13.377197 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 14:19:25.571701 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 14:19:37.712708 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 14:19:49.891763 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 14:19:50.443175 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-14:19:50\n",
            "I0630 14:19:50.444329 139930856781696 estimator.py:2039] Saving dict for global step 4500: accuracy0 = 0.9534375, accuracy1 = 0.985, accuracy2 = 0.9675, accuracy3 = 0.99625, accuracy4 = 0.95984375, accuracy5 = 0.9840625, auc0 = 0.95596457, auc1 = 0.98752534, auc2 = 0.98127806, auc3 = 0.9298549, auc4 = 0.97270006, auc5 = 0.9500996, global_step = 4500, loss = -147.83426, precision0 = 0.89784515, precision1 = 0.36734694, precision2 = 0.80536133, precision3 = 0.0, precision4 = 0.7862839, precision5 = 0.36363637, recall0 = 0.70621467, recall1 = 0.70866144, recall2 = 0.7351064, recall3 = 0.0, recall4 = 0.5647194, recall5 = 0.25730994\n",
            "I0630 14:19:52.378992 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 4500: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-4500\n",
            "I0630 14:19:55.287532 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.248594\n",
            "I0630 14:20:01.099244 139930856781696 basic_session_run_hooks.py:260] loss = -138.42824, step = 4500 (408.072 sec)\n",
            "I0630 14:21:28.720810 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.07028\n",
            "I0630 14:21:28.722676 139930856781696 basic_session_run_hooks.py:260] loss = -173.06781, step = 4600 (87.623 sec)\n",
            "I0630 14:23:01.902080 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.07318\n",
            "I0630 14:23:01.903606 139930856781696 basic_session_run_hooks.py:260] loss = -207.54605, step = 4700 (93.181 sec)\n",
            "I0630 14:24:29.448801 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14225\n",
            "I0630 14:24:36.140255 139930856781696 basic_session_run_hooks.py:260] loss = -124.62334, step = 4800 (94.237 sec)\n",
            "I0630 14:26:03.611260 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.06199\n",
            "I0630 14:26:03.615372 139930856781696 basic_session_run_hooks.py:260] loss = -187.36475, step = 4900 (87.475 sec)\n",
            "I0630 14:27:35.901385 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 5000 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 14:28:28.763564 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 14:28:32.832288 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 14:28:43.575652 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 14:28:43.601342 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T14:28:43Z\n",
            "I0630 14:28:45.054584 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 14:28:45.266505 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-5000\n",
            "I0630 14:30:43.866250 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 14:30:44.289596 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 14:30:58.076630 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 14:31:09.797448 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 14:31:21.618719 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 14:31:33.718692 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 14:31:46.004252 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 14:31:58.383573 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 14:32:10.619271 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 14:32:22.824553 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 14:32:35.022129 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 14:32:47.226310 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 14:32:47.798508 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-14:32:47\n",
            "I0630 14:32:47.799659 139930856781696 estimator.py:2039] Saving dict for global step 5000: accuracy0 = 0.9557812, accuracy1 = 0.97085935, accuracy2 = 0.96375, accuracy3 = 0.99625, accuracy4 = 0.96117187, accuracy5 = 0.9753906, auc0 = 0.96493256, auc1 = 0.98657197, auc2 = 0.98595846, auc3 = 0.9318808, auc4 = 0.97816676, auc5 = 0.9503106, global_step = 5000, loss = -149.80096, precision0 = 0.8696904, precision1 = 0.24042553, precision2 = 0.70472103, precision3 = 0.0, precision4 = 0.70486486, precision5 = 0.23595506, recall0 = 0.75831765, recall1 = 0.875969, recall2 = 0.8724761, recall3 = 0.0, recall4 = 0.74429226, recall5 = 0.36206895\n",
            "I0630 14:32:49.761467 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 5000: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-5000\n",
            "I0630 14:32:52.665954 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.244466\n",
            "I0630 14:32:58.291056 139930856781696 basic_session_run_hooks.py:260] loss = -196.37592, step = 5000 (414.676 sec)\n",
            "I0630 14:34:26.012211 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.07128\n",
            "I0630 14:34:26.013538 139930856781696 basic_session_run_hooks.py:260] loss = -186.56831, step = 5100 (87.723 sec)\n",
            "I0630 14:35:59.395327 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.07086\n",
            "I0630 14:35:59.396918 139930856781696 basic_session_run_hooks.py:260] loss = -207.5461, step = 5200 (93.383 sec)\n",
            "I0630 14:37:26.789317 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14424\n",
            "I0630 14:37:34.283060 139930856781696 basic_session_run_hooks.py:260] loss = -120.08839, step = 5300 (94.886 sec)\n",
            "I0630 14:39:01.931179 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.05106\n",
            "I0630 14:39:01.932768 139930856781696 basic_session_run_hooks.py:260] loss = -116.73102, step = 5400 (87.650 sec)\n",
            "I0630 14:40:36.840532 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 5500 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 14:41:27.658283 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 14:41:31.786429 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 14:41:42.526662 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 14:41:42.551582 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T14:41:42Z\n",
            "I0630 14:41:43.976554 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 14:41:44.192919 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-5500\n",
            "I0630 14:43:49.459115 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 14:43:49.883020 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 14:44:03.730150 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 14:44:15.445661 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 14:44:27.260377 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 14:44:39.426695 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 14:44:51.805253 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 14:45:04.285272 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 14:45:16.560866 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 14:45:28.755869 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 14:45:40.942966 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 14:45:53.159645 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 14:45:53.735823 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-14:45:53\n",
            "I0630 14:45:53.737031 139930856781696 estimator.py:2039] Saving dict for global step 5500: accuracy0 = 0.9565625, accuracy1 = 0.97765625, accuracy2 = 0.9700781, accuracy3 = 0.99625, accuracy4 = 0.9591406, accuracy5 = 0.9775781, auc0 = 0.9635521, auc1 = 0.98745733, auc2 = 0.98302495, auc3 = 0.9349432, auc4 = 0.97707576, auc5 = 0.9558884, global_step = 5500, loss = -150.4642, precision0 = 0.8865672, precision1 = 0.2857143, precision2 = 0.82880753, precision3 = 0.0, precision4 = 0.7619048, precision5 = 0.2584746, recall0 = 0.74623114, recall1 = 0.8, recall2 = 0.7468085, recall3 = 0.0, recall4 = 0.58514285, recall5 = 0.35260117\n",
            "I0630 14:45:55.656985 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 5500: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-5500\n",
            "I0630 14:45:58.613197 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.239991\n",
            "I0630 14:46:06.421493 139930856781696 basic_session_run_hooks.py:260] loss = -181.50185, step = 5500 (424.489 sec)\n",
            "I0630 14:47:34.384821 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.04415\n",
            "I0630 14:47:34.386373 139930856781696 basic_session_run_hooks.py:260] loss = -125.58034, step = 5600 (87.965 sec)\n",
            "I0630 14:49:08.812077 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.05902\n",
            "I0630 14:49:08.813703 139930856781696 basic_session_run_hooks.py:260] loss = 69.01187, step = 5700 (94.427 sec)\n",
            "I0630 14:50:36.170568 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14471\n",
            "I0630 14:50:42.255059 139930856781696 basic_session_run_hooks.py:260] loss = -121.5587, step = 5800 (93.441 sec)\n",
            "I0630 14:52:09.906564 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.06683\n",
            "I0630 14:52:09.907984 139930856781696 basic_session_run_hooks.py:260] loss = -174.30287, step = 5900 (87.653 sec)\n",
            "I0630 14:53:42.845436 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 6000 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 14:54:33.407534 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 14:54:37.482890 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 14:54:48.218333 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 14:54:48.242729 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T14:54:48Z\n",
            "I0630 14:54:49.662866 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 14:54:49.882631 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-6000\n",
            "I0630 14:56:51.316385 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 14:56:51.728659 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 14:57:05.452711 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 14:57:17.140561 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 14:57:29.047162 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 14:57:41.228959 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 14:57:53.560623 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 14:58:05.892450 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 14:58:18.134728 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 14:58:30.321910 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 14:58:42.509137 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 14:58:54.710718 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 14:58:55.268380 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-14:58:55\n",
            "I0630 14:58:55.269591 139930856781696 estimator.py:2039] Saving dict for global step 6000: accuracy0 = 0.95632815, accuracy1 = 0.97734374, accuracy2 = 0.9615625, accuracy3 = 0.99625, accuracy4 = 0.9600781, accuracy5 = 0.98226565, auc0 = 0.97566366, auc1 = 0.98726696, auc2 = 0.9852722, auc3 = 0.9295747, auc4 = 0.9804657, auc5 = 0.962362, global_step = 6000, loss = -152.0671, precision0 = 0.8525815, precision1 = 0.27823693, precision2 = 0.6814516, precision3 = 0.0, precision4 = 0.68304914, precision5 = 0.33734939, recall0 = 0.78584844, recall1 = 0.78294575, recall2 = 0.8970276, recall3 = 0.0, recall4 = 0.7773973, recall5 = 0.3236994\n",
            "I0630 14:58:58.062248 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 6000: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-6000\n",
            "I0630 14:59:00.859630 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.243337\n",
            "I0630 14:59:07.337517 139930856781696 basic_session_run_hooks.py:260] loss = -114.290596, step = 6000 (417.430 sec)\n",
            "I0630 15:00:35.282939 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.05906\n",
            "I0630 15:00:35.284328 139930856781696 basic_session_run_hooks.py:260] loss = -119.09042, step = 6100 (87.947 sec)\n",
            "I0630 15:02:09.304387 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.06359\n",
            "I0630 15:02:09.306396 139930856781696 basic_session_run_hooks.py:260] loss = -207.5466, step = 6200 (94.022 sec)\n",
            "I0630 15:03:36.717600 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14399\n",
            "I0630 15:03:42.910370 139930856781696 basic_session_run_hooks.py:260] loss = -207.54622, step = 6300 (93.604 sec)\n",
            "I0630 15:05:10.518862 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.06608\n",
            "I0630 15:05:10.520474 139930856781696 basic_session_run_hooks.py:260] loss = -201.7718, step = 6400 (87.610 sec)\n",
            "I0630 15:06:43.894304 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 6500 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 15:07:35.427397 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 15:07:39.424902 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 15:07:50.162212 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 15:07:50.187381 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T15:07:50Z\n",
            "I0630 15:07:52.865472 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 15:07:53.091992 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-6500\n",
            "I0630 15:09:46.911894 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 15:09:47.249371 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 15:10:00.967935 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 15:10:12.717966 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 15:10:24.617859 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 15:10:36.804900 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 15:10:49.345173 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 15:11:01.749197 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 15:11:13.971969 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 15:11:26.171637 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 15:11:38.353653 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 15:11:50.580426 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 15:11:51.131342 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-15:11:51\n",
            "I0630 15:11:51.132615 139930856781696 estimator.py:2039] Saving dict for global step 6500: accuracy0 = 0.95390624, accuracy1 = 0.9780469, accuracy2 = 0.9665625, accuracy3 = 0.99625, accuracy4 = 0.96101564, accuracy5 = 0.97898436, auc0 = 0.9672937, auc1 = 0.98742956, auc2 = 0.9848023, auc3 = 0.924293, auc4 = 0.97809947, auc5 = 0.9570905, global_step = 6500, loss = -147.68375, precision0 = 0.90136325, precision1 = 0.2892562, precision2 = 0.73990613, precision3 = 0.0, precision4 = 0.7403599, precision5 = 0.29237288, recall0 = 0.7064739, recall1 = 0.8203125, recall2 = 0.8391906, recall3 = 0.0, recall4 = 0.6597938, recall5 = 0.40350878\n",
            "I0630 15:11:52.370259 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 6500: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-6500\n",
            "I0630 15:11:54.549192 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.247506\n",
            "I0630 15:12:01.413781 139930856781696 basic_session_run_hooks.py:260] loss = -192.8234, step = 6500 (410.893 sec)\n",
            "I0630 15:13:29.191476 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.05661\n",
            "I0630 15:13:29.193482 139930856781696 basic_session_run_hooks.py:260] loss = -207.5458, step = 6600 (87.780 sec)\n",
            "I0630 15:15:04.625671 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.04784\n",
            "I0630 15:15:04.627054 139930856781696 basic_session_run_hooks.py:260] loss = -200.08028, step = 6700 (95.434 sec)\n",
            "I0630 15:16:32.027859 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14414\n",
            "I0630 15:16:39.064872 139930856781696 basic_session_run_hooks.py:260] loss = -167.11034, step = 6800 (94.438 sec)\n",
            "I0630 15:18:06.822536 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.05491\n",
            "I0630 15:18:06.823877 139930856781696 basic_session_run_hooks.py:260] loss = -174.54004, step = 6900 (87.759 sec)\n",
            "I0630 15:19:42.212921 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 7000 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 15:20:37.726362 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 15:20:40.054743 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 15:20:51.242218 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 15:20:51.267059 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T15:20:51Z\n",
            "I0630 15:20:52.695839 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 15:20:52.910275 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-7000\n",
            "I0630 15:22:45.164565 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 15:22:45.600884 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 15:22:59.430938 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 15:23:11.494904 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 15:23:23.984548 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 15:23:36.690087 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 15:23:49.059215 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 15:24:01.222254 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 15:24:13.222095 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 15:24:25.166499 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 15:24:37.192864 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 15:24:49.334145 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 15:24:49.861469 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-15:24:49\n",
            "I0630 15:24:49.862802 139930856781696 estimator.py:2039] Saving dict for global step 7000: accuracy0 = 0.9564844, accuracy1 = 0.97679687, accuracy2 = 0.96648437, accuracy3 = 0.99625, accuracy4 = 0.961875, accuracy5 = 0.9750781, auc0 = 0.96989614, auc1 = 0.9874226, auc2 = 0.9857497, auc3 = 0.9386885, auc4 = 0.9774367, auc5 = 0.9528146, global_step = 7000, loss = -149.14963, precision0 = 0.8959449, precision1 = 0.28350514, precision2 = 0.7410208, precision3 = 0.0, precision4 = 0.72921616, precision5 = 0.24652778, recall0 = 0.7355528, recall1 = 0.85271317, recall2 = 0.8349308, recall3 = 0.0, recall4 = 0.70251715, recall5 = 0.41040462\n",
            "I0630 15:24:51.287584 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 7000: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-7000\n",
            "I0630 15:24:53.481634 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.245906\n",
            "I0630 15:25:00.611055 139930856781696 basic_session_run_hooks.py:260] loss = -198.43321, step = 7000 (413.787 sec)\n",
            "I0630 15:26:28.319650 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.05443\n",
            "I0630 15:26:28.320995 139930856781696 basic_session_run_hooks.py:260] loss = -207.5465, step = 7100 (87.710 sec)\n",
            "I0630 15:27:55.902450 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14178\n",
            "I0630 15:28:03.020616 139930856781696 basic_session_run_hooks.py:260] loss = -190.22781, step = 7200 (94.700 sec)\n",
            "I0630 15:29:30.707226 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.0548\n",
            "I0630 15:29:30.708551 139930856781696 basic_session_run_hooks.py:260] loss = -207.5463, step = 7300 (87.688 sec)\n",
            "I0630 15:30:58.125585 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14392\n",
            "I0630 15:31:04.376586 139930856781696 basic_session_run_hooks.py:260] loss = -171.3007, step = 7400 (93.668 sec)\n",
            "I0630 15:32:31.205698 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 7500 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 15:33:29.463840 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 15:33:33.414291 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 15:33:44.196580 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 15:33:44.221727 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T15:33:44Z\n",
            "I0630 15:33:45.674169 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 15:33:45.897137 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-7500\n",
            "I0630 15:35:57.518511 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 15:35:57.840859 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 15:36:11.712403 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 15:36:23.745871 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 15:36:36.188472 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 15:36:48.898759 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 15:37:01.292767 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 15:37:13.452028 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 15:37:25.439950 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 15:37:37.397254 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 15:37:49.445425 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 15:38:01.628506 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 15:38:02.165689 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-15:38:02\n",
            "I0630 15:38:02.166810 139930856781696 estimator.py:2039] Saving dict for global step 7500: accuracy0 = 0.9578906, accuracy1 = 0.9810156, accuracy2 = 0.96601564, accuracy3 = 0.99625, accuracy4 = 0.9578125, accuracy5 = 0.97914064, auc0 = 0.97397375, auc1 = 0.9873572, auc2 = 0.98657733, auc3 = 0.9324436, auc4 = 0.98034555, auc5 = 0.9638628, global_step = 7500, loss = -153.04675, precision0 = 0.8622344, precision1 = 0.31847134, precision2 = 0.7330275, precision3 = 0.0, precision4 = 0.72207445, precision5 = 0.27906978, recall0 = 0.7882205, recall1 = 0.7751938, recall2 = 0.8472959, recall3 = 0.0, recall4 = 0.62128145, recall5 = 0.3488372\n",
            "I0630 15:38:04.153293 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 7500: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-7500\n",
            "I0630 15:38:07.160434 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.233081\n",
            "I0630 15:38:13.782206 139930856781696 basic_session_run_hooks.py:260] loss = -123.546394, step = 7500 (429.406 sec)\n",
            "I0630 15:39:41.673303 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.05806\n",
            "I0630 15:39:41.674829 139930856781696 basic_session_run_hooks.py:260] loss = -13.145276, step = 7600 (87.893 sec)\n",
            "I0630 15:41:09.217288 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14228\n",
            "I0630 15:41:18.213897 139930856781696 basic_session_run_hooks.py:260] loss = -155.63737, step = 7700 (96.539 sec)\n",
            "I0630 15:42:45.883696 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.03449\n",
            "I0630 15:42:45.885503 139930856781696 basic_session_run_hooks.py:260] loss = -186.23683, step = 7800 (87.672 sec)\n",
            "I0630 15:44:13.483145 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14156\n",
            "I0630 15:44:20.088122 139930856781696 basic_session_run_hooks.py:260] loss = -179.07437, step = 7900 (94.203 sec)\n",
            "I0630 15:45:46.953297 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 8000 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 15:46:43.174305 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 15:46:47.233469 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 15:46:58.105701 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 15:46:58.131065 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T15:46:58Z\n",
            "I0630 15:46:59.578572 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 15:46:59.806087 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-8000\n",
            "I0630 15:49:08.191591 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 15:49:08.629340 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 15:49:22.638674 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 15:49:34.763732 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 15:49:47.341586 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 15:50:00.152971 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 15:50:12.571098 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 15:50:24.778413 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 15:50:36.900954 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 15:50:48.969821 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 15:51:01.076269 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 15:51:13.277625 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 15:51:13.811933 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-15:51:13\n",
            "I0630 15:51:13.813019 139930856781696 estimator.py:2039] Saving dict for global step 8000: accuracy0 = 0.9549219, accuracy1 = 0.9832031, accuracy2 = 0.96914065, accuracy3 = 0.99625, accuracy4 = 0.95875, accuracy5 = 0.9817188, auc0 = 0.9721181, auc1 = 0.9879674, auc2 = 0.9849251, auc3 = 0.93201315, auc4 = 0.9789636, auc5 = 0.9568114, global_step = 8000, loss = -149.93004, precision0 = 0.9074819, precision1 = 0.34065935, precision2 = 0.7758621, precision3 = 0.0, precision4 = 0.7246753, precision5 = 0.33695653, recall0 = 0.709434, recall1 = 0.7265625, recall2 = 0.8146965, recall3 = 0.0, recall4 = 0.63844395, recall5 = 0.35632184\n",
            "I0630 15:51:15.745034 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 8000: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-8000\n",
            "I0630 15:51:18.573098 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.235244\n",
            "I0630 15:51:27.457981 139930856781696 basic_session_run_hooks.py:260] loss = -195.49002, step = 8000 (427.370 sec)\n",
            "I0630 15:52:55.458235 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.03215\n",
            "I0630 15:52:55.459746 139930856781696 basic_session_run_hooks.py:260] loss = -172.21071, step = 8100 (88.002 sec)\n",
            "I0630 15:54:22.979917 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14257\n",
            "I0630 15:54:30.363839 139930856781696 basic_session_run_hooks.py:260] loss = -160.43538, step = 8200 (94.904 sec)\n",
            "I0630 15:55:57.937464 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.0531\n",
            "I0630 15:55:57.939026 139930856781696 basic_session_run_hooks.py:260] loss = -207.5456, step = 8300 (87.575 sec)\n",
            "I0630 15:57:25.432521 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14292\n",
            "I0630 15:57:33.098068 139930856781696 basic_session_run_hooks.py:260] loss = -189.65245, step = 8400 (95.159 sec)\n",
            "I0630 15:59:00.048964 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 8500 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 15:59:58.531675 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 16:00:02.487974 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 16:00:13.295852 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 16:00:13.321850 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T16:00:13Z\n",
            "I0630 16:00:14.756154 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 16:00:14.971172 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-8500\n",
            "I0630 16:02:30.351923 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 16:02:30.665082 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 16:02:44.428115 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 16:02:56.570744 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 16:03:09.151386 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 16:03:21.990851 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 16:03:34.445657 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 16:03:46.665538 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 16:03:58.787622 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 16:04:10.864650 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 16:04:22.986481 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 16:04:35.202777 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 16:04:35.719459 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-16:04:35\n",
            "I0630 16:04:35.720717 139930856781696 estimator.py:2039] Saving dict for global step 8500: accuracy0 = 0.9553125, accuracy1 = 0.97796875, accuracy2 = 0.9678906, accuracy3 = 0.99625, accuracy4 = 0.95953125, accuracy5 = 0.9778906, auc0 = 0.9642955, auc1 = 0.9878942, auc2 = 0.98424405, auc3 = 0.9366513, auc4 = 0.97806597, auc5 = 0.95468307, global_step = 8500, loss = -147.73224, precision0 = 0.9093098, precision1 = 0.2912088, precision2 = 0.7637089, precision3 = 0.0, precision4 = 0.7303226, precision5 = 0.28, recall0 = 0.7116834, recall1 = 0.8153846, recall2 = 0.8148936, recall3 = 0.0, recall4 = 0.64685714, recall5 = 0.40462428\n",
            "I0630 16:04:37.649734 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 8500: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-8500\n",
            "I0630 16:04:40.518268 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.22984\n",
            "I0630 16:04:47.712622 139930856781696 basic_session_run_hooks.py:260] loss = -120.23009, step = 8500 (434.615 sec)\n",
            "I0630 16:06:15.828541 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.0492\n",
            "I0630 16:06:15.829989 139930856781696 basic_session_run_hooks.py:260] loss = -163.04858, step = 8600 (88.117 sec)\n",
            "I0630 16:07:43.455972 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.1412\n",
            "I0630 16:07:49.809418 139930856781696 basic_session_run_hooks.py:260] loss = -141.94847, step = 8700 (93.979 sec)\n",
            "I0630 16:09:17.485608 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.06349\n",
            "I0630 16:09:17.487084 139930856781696 basic_session_run_hooks.py:260] loss = -144.09398, step = 8800 (87.678 sec)\n",
            "I0630 16:10:44.790512 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14541\n",
            "I0630 16:10:51.254152 139930856781696 basic_session_run_hooks.py:260] loss = -165.93959, step = 8900 (93.767 sec)\n",
            "I0630 16:12:18.114745 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 9000 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 16:13:25.669628 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 16:13:27.992287 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 16:13:38.859887 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 16:13:38.884746 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T16:13:38Z\n",
            "I0630 16:13:41.525004 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 16:13:41.728521 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-9000\n",
            "I0630 16:15:57.207706 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 16:15:57.605643 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 16:16:11.463559 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 16:16:23.592447 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 16:16:36.143228 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 16:16:48.938685 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 16:17:01.369393 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 16:17:13.576052 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 16:17:25.665043 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 16:17:37.709519 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 16:17:49.825736 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 16:18:02.027642 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 16:18:02.561695 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-16:18:02\n",
            "I0630 16:18:02.562816 139930856781696 estimator.py:2039] Saving dict for global step 9000: accuracy0 = 0.954375, accuracy1 = 0.97976565, accuracy2 = 0.9682031, accuracy3 = 0.99625, accuracy4 = 0.95921874, accuracy5 = 0.978125, auc0 = 0.9642256, auc1 = 0.9876291, auc2 = 0.98378354, auc3 = 0.9320768, auc4 = 0.97888345, auc5 = 0.95782906, global_step = 9000, loss = -148.21016, precision0 = 0.9152961, precision1 = 0.3027523, precision2 = 0.787944, precision3 = 0.0, precision4 = 0.75836974, precision5 = 0.28968254, recall0 = 0.69824344, recall1 = 0.76153845, recall2 = 0.77707005, recall3 = 0.0, recall4 = 0.5940707, recall5 = 0.41954023\n",
            "I0630 16:18:05.097093 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 9000: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-9000\n",
            "I0630 16:18:07.949355 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.225653\n",
            "I0630 16:18:15.922299 139930856781696 basic_session_run_hooks.py:260] loss = 0.68623126, step = 9000 (444.668 sec)\n",
            "I0630 16:19:43.823115 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.04304\n",
            "I0630 16:19:43.824850 139930856781696 basic_session_run_hooks.py:260] loss = -207.54604, step = 9100 (87.903 sec)\n",
            "I0630 16:21:11.239184 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14395\n",
            "I0630 16:21:17.366693 139930856781696 basic_session_run_hooks.py:260] loss = -126.97516, step = 9200 (93.542 sec)\n",
            "I0630 16:22:45.020849 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.06631\n",
            "I0630 16:22:45.022613 139930856781696 basic_session_run_hooks.py:260] loss = -207.54599, step = 9300 (87.656 sec)\n",
            "I0630 16:24:12.720469 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14026\n",
            "I0630 16:24:18.817352 139930856781696 basic_session_run_hooks.py:260] loss = -26.407652, step = 9400 (93.795 sec)\n",
            "I0630 16:25:45.613277 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 9500 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 16:26:41.841550 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 16:26:44.168303 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 16:26:55.662176 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 16:26:55.686022 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T16:26:55Z\n",
            "I0630 16:26:57.123426 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 16:26:57.360218 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-9500\n",
            "I0630 16:28:57.633809 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 16:28:57.971866 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 16:29:12.059732 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 16:29:24.215577 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 16:29:36.796978 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 16:29:49.606067 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 16:30:02.037119 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 16:30:14.233745 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 16:30:26.334615 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 16:30:38.392504 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 16:30:50.523222 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 16:31:02.716977 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 16:31:03.259240 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-16:31:03\n",
            "I0630 16:31:03.260569 139930856781696 estimator.py:2039] Saving dict for global step 9500: accuracy0 = 0.9564844, accuracy1 = 0.97382814, accuracy2 = 0.9657813, accuracy3 = 0.99625, accuracy4 = 0.96070313, accuracy5 = 0.973125, auc0 = 0.9737912, auc1 = 0.98734367, auc2 = 0.9855496, auc3 = 0.93571186, auc4 = 0.9813451, auc5 = 0.96207595, global_step = 9500, loss = -151.31613, precision0 = 0.8831361, precision1 = 0.25700936, precision2 = 0.7348273, precision3 = 0.0, precision4 = 0.72760737, precision5 = 0.2521739, recall0 = 0.7495292, recall1 = 0.86614174, recall2 = 0.8363443, recall3 = 0.0, recall4 = 0.6784897, recall5 = 0.50289017\n",
            "I0630 16:31:05.207009 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 9500: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-9500\n",
            "I0630 16:31:07.674355 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 0.240991\n",
            "I0630 16:31:14.398573 139930856781696 basic_session_run_hooks.py:260] loss = -69.49249, step = 9500 (415.581 sec)\n",
            "I0630 16:32:42.117501 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.05884\n",
            "I0630 16:32:42.119094 139930856781696 basic_session_run_hooks.py:260] loss = -163.85019, step = 9600 (87.721 sec)\n",
            "I0630 16:34:09.754943 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14106\n",
            "I0630 16:34:17.047217 139930856781696 basic_session_run_hooks.py:260] loss = -189.11328, step = 9700 (94.928 sec)\n",
            "I0630 16:35:44.642552 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.05388\n",
            "I0630 16:35:44.644081 139930856781696 basic_session_run_hooks.py:260] loss = 254.13054, step = 9800 (87.597 sec)\n",
            "I0630 16:37:12.157758 139930856781696 basic_session_run_hooks.py:692] global_step/sec: 1.14266\n",
            "I0630 16:37:20.217186 139930856781696 basic_session_run_hooks.py:260] loss = -184.42317, step = 9900 (95.573 sec)\n",
            "I0630 16:38:47.249250 139930856781696 basic_session_run_hooks.py:606] Saving checkpoints for 10000 into gs://rail_jigsaw_modeling/kaggle/models/model.ckpt.\n",
            "I0630 16:39:43.808368 139930856781696 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0630 16:39:47.855548 139930856781696 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0630 16:39:58.806387 139930856781696 estimator.py:1147] Done calling model_fn.\n",
            "I0630 16:39:58.832227 139930856781696 evaluation.py:255] Starting evaluation at 2019-06-30T16:39:58Z\n",
            "I0630 16:40:00.319108 139930856781696 monitored_session.py:240] Graph was finalized.\n",
            "I0630 16:40:00.533541 139930856781696 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-10000\n",
            "I0630 16:42:05.722029 139930856781696 session_manager.py:500] Running local_init_op.\n",
            "I0630 16:42:06.130187 139930856781696 session_manager.py:502] Done running local_init_op.\n",
            "I0630 16:42:20.025755 139930856781696 evaluation.py:167] Evaluation [40/400]\n",
            "I0630 16:42:32.162861 139930856781696 evaluation.py:167] Evaluation [80/400]\n",
            "I0630 16:42:44.705931 139930856781696 evaluation.py:167] Evaluation [120/400]\n",
            "I0630 16:42:57.495491 139930856781696 evaluation.py:167] Evaluation [160/400]\n",
            "I0630 16:43:09.903321 139930856781696 evaluation.py:167] Evaluation [200/400]\n",
            "I0630 16:43:22.083752 139930856781696 evaluation.py:167] Evaluation [240/400]\n",
            "I0630 16:43:34.141643 139930856781696 evaluation.py:167] Evaluation [280/400]\n",
            "I0630 16:43:46.162483 139930856781696 evaluation.py:167] Evaluation [320/400]\n",
            "I0630 16:43:58.252594 139930856781696 evaluation.py:167] Evaluation [360/400]\n",
            "I0630 16:44:10.456467 139930856781696 evaluation.py:167] Evaluation [400/400]\n",
            "I0630 16:44:10.993526 139930856781696 evaluation.py:275] Finished evaluation at 2019-06-30-16:44:10\n",
            "I0630 16:44:10.994729 139930856781696 estimator.py:2039] Saving dict for global step 10000: accuracy0 = 0.9565625, accuracy1 = 0.9753906, accuracy2 = 0.96617186, accuracy3 = 0.99625, accuracy4 = 0.96015626, accuracy5 = 0.9753125, auc0 = 0.97294134, auc1 = 0.9880686, auc2 = 0.9846966, auc3 = 0.9297774, auc4 = 0.9804501, auc5 = 0.9589283, global_step = 10000, loss = -151.29643, precision0 = 0.8888054, precision1 = 0.2691358, precision2 = 0.7428023, precision3 = 0.0, precision4 = 0.7234568, precision5 = 0.26245847, recall0 = 0.7435575, recall1 = 0.8515625, recall2 = 0.82428116, recall3 = 0.0, recall4 = 0.67201835, recall5 = 0.4566474\n",
            "I0630 16:44:12.933728 139930856781696 estimator.py:2099] Saving 'checkpoint_path' summary for global step 10000: gs://rail_jigsaw_modeling/kaggle/models/model.ckpt-10000\n",
            "I0630 16:44:21.854191 139930856781696 estimator.py:368] Loss for final step: -157.25359.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'accuracy0': 0.9565625,\n",
              "  'accuracy1': 0.9753906,\n",
              "  'accuracy2': 0.96617186,\n",
              "  'accuracy3': 0.99625,\n",
              "  'accuracy4': 0.96015626,\n",
              "  'accuracy5': 0.9753125,\n",
              "  'auc0': 0.97294134,\n",
              "  'auc1': 0.9880686,\n",
              "  'auc2': 0.9846966,\n",
              "  'auc3': 0.9297774,\n",
              "  'auc4': 0.9804501,\n",
              "  'auc5': 0.9589283,\n",
              "  'global_step': 10000,\n",
              "  'loss': -151.29643,\n",
              "  'precision0': 0.8888054,\n",
              "  'precision1': 0.2691358,\n",
              "  'precision2': 0.7428023,\n",
              "  'precision3': 0.0,\n",
              "  'precision4': 0.7234568,\n",
              "  'precision5': 0.26245847,\n",
              "  'recall0': 0.7435575,\n",
              "  'recall1': 0.8515625,\n",
              "  'recall2': 0.82428116,\n",
              "  'recall3': 0.0,\n",
              "  'recall4': 0.67201835,\n",
              "  'recall5': 0.4566474},\n",
              " [])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uHP88st76N4l",
        "outputId": "3237fd82-c434-41e3-f0b8-8c85008dda74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size = 32\n",
        "eval_steps = int(len(df_test) / batch_size)\n",
        "\n",
        "neural_process.evaluate(eval_steps,\n",
        "                       df_test, \n",
        "                       score_col= score_column, \n",
        "                       text_col=text_col_name, supplied_context_df = None)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0706 12:37:51.596399 140042348476288 estimator.py:1145] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation\n",
            "****No context supplied ****\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0706 12:37:54.216485 140042348476288 saver.py:1499] Saver not created because there are no variables in the graph to restore\n",
            "W0706 12:37:54.402668 140042348476288 deprecation.py:323] From <ipython-input-19-504275df30f7>:28: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0706 12:37:54.413048 140042348476288 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0706 12:37:54.837756 140042348476288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0706 12:37:54.839547 140042348476288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0706 12:37:54.845036 140042348476288 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0706 12:37:54.860515 140042348476288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0706 12:37:55.221364 140042348476288 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0706 12:37:58.717274 140042348476288 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:117: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "I0706 12:38:04.042946 140042348476288 estimator.py:1147] Done calling model_fn.\n",
            "I0706 12:38:04.065395 140042348476288 evaluation.py:255] Starting evaluation at 2019-07-06T12:38:04Z\n",
            "I0706 12:38:05.663043 140042348476288 monitored_session.py:240] Graph was finalized.\n",
            "W0706 12:38:05.671857 140042348476288 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "I0706 12:38:05.864228 140042348476288 saver.py:1280] Restoring parameters from gs://rail_jigsaw_modeling/unhealthy/models/batch32_attributeOverrep/model.ckpt-5500\n",
            "I0706 12:39:22.621763 140042348476288 session_manager.py:500] Running local_init_op.\n",
            "I0706 12:39:22.978640 140042348476288 session_manager.py:502] Done running local_init_op.\n",
            "I0706 12:39:29.920014 140042348476288 evaluation.py:167] Evaluation [14/140]\n",
            "I0706 12:39:34.329604 140042348476288 evaluation.py:167] Evaluation [28/140]\n",
            "I0706 12:39:38.844515 140042348476288 evaluation.py:167] Evaluation [42/140]\n",
            "I0706 12:39:43.423939 140042348476288 evaluation.py:167] Evaluation [56/140]\n",
            "I0706 12:39:48.053324 140042348476288 evaluation.py:167] Evaluation [70/140]\n",
            "I0706 12:39:52.665134 140042348476288 evaluation.py:167] Evaluation [84/140]\n",
            "I0706 12:39:57.231184 140042348476288 evaluation.py:167] Evaluation [98/140]\n",
            "I0706 12:40:01.707237 140042348476288 evaluation.py:167] Evaluation [112/140]\n",
            "I0706 12:40:06.114189 140042348476288 evaluation.py:167] Evaluation [126/140]\n",
            "I0706 12:40:10.466370 140042348476288 evaluation.py:167] Evaluation [140/140]\n",
            "I0706 12:40:10.907343 140042348476288 evaluation.py:275] Finished evaluation at 2019-07-06-12:40:10\n",
            "I0706 12:40:10.908632 140042348476288 estimator.py:2039] Saving dict for global step 5500: accuracy0 = 0.9345982, accuracy1 = 0.92745537, accuracy2 = 0.95625, accuracy3 = 0.96049106, accuracy4 = 0.9660714, accuracy5 = 0.94910717, auc0 = 0.71659636, auc1 = 0.73817134, auc2 = 0.7584312, auc3 = 0.7839753, auc4 = 0.79039407, auc5 = 0.6684058, global_step = 5500, loss = 11.920478, precision0 = 0.325, precision1 = 0.3181818, precision2 = 0.225, precision3 = 0.2173913, precision4 = 0.37254903, precision5 = 0.0, recall0 = 0.15537849, recall1 = 0.15162455, recall2 = 0.05172414, recall3 = 0.3030303, recall4 = 0.13669065, recall5 = 0.0\n",
            "I0706 12:40:16.931709 140042348476288 estimator.py:2099] Saving 'checkpoint_path' summary for global step 5500: gs://rail_jigsaw_modeling/unhealthy/models/batch32_attributeOverrep/model.ckpt-5500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy0': 0.9345982,\n",
              " 'accuracy1': 0.92745537,\n",
              " 'accuracy2': 0.95625,\n",
              " 'accuracy3': 0.96049106,\n",
              " 'accuracy4': 0.9660714,\n",
              " 'accuracy5': 0.94910717,\n",
              " 'auc0': 0.71659636,\n",
              " 'auc1': 0.73817134,\n",
              " 'auc2': 0.7584312,\n",
              " 'auc3': 0.7839753,\n",
              " 'auc4': 0.79039407,\n",
              " 'auc5': 0.6684058,\n",
              " 'global_step': 5500,\n",
              " 'loss': 11.920478,\n",
              " 'precision0': 0.325,\n",
              " 'precision1': 0.3181818,\n",
              " 'precision2': 0.225,\n",
              " 'precision3': 0.2173913,\n",
              " 'precision4': 0.37254903,\n",
              " 'precision5': 0.0,\n",
              " 'recall0': 0.15537849,\n",
              " 'recall1': 0.15162455,\n",
              " 'recall2': 0.05172414,\n",
              " 'recall3': 0.3030303,\n",
              " 'recall4': 0.13669065,\n",
              " 'recall5': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_NqA06NHYgxh",
        "colab": {}
      },
      "source": [
        "preds = neural_process.predict(\n",
        "                       df_test, \n",
        "                       score_col= score_column, \n",
        "                       text_col=text_col_name,supplied_context_df = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7hEFhEGHkrVy",
        "colab": {}
      },
      "source": [
        "test_scores = df_test[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
        "       'identity_hate']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fri1X4hdkrev",
        "colab": {}
      },
      "source": [
        "uncertainty = pd.DataFrame(columns=['presence','accuracy', 'variance'])\n",
        "pred_means = pd.DataFrame(columns = score_column)\n",
        "pred_variances = pd.DataFrame(columns = score_column)\n",
        "\n",
        "for i, pred in enumerate(preds):\n",
        "  if i<len(test_scores):\n",
        "    scores = np.array(test_scores.iloc[i])\n",
        "    #     print(scores)\n",
        "    pred_means = pred_means.append({score_column[k]:pred['prediction_mean'][k] for k in range(len(score_column))}, ignore_index=True)\n",
        "    #     print(mean_prediction)\n",
        "    variance = pred['prediction_var']\n",
        "    pred_variances = pred_variances.append({score_column[k]:variance[k] for k in range(len(score_column))}, ignore_index=True)  \n",
        "    mean_prediction = np.round(pred['prediction_mean'])\n",
        "    acc = scores==mean_prediction\n",
        "    for j in range(len(scores)):\n",
        "      uncertainty = uncertainty.append({'presence':scores[j], 'accuracy': acc[j], 'variance': variance[j]}, ignore_index=True)\n",
        "  else:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gc3034n5pYtd",
        "outputId": "a69323e2-0669-4dc3-c60f-a3eb29f96a44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "print(\"Average variance for accurate/correct predictions:\")\n",
        "print(uncertainty[uncertainty.accuracy==True]['variance'].mean())\n",
        "print(\"Average variance for inaccurate/false predictions:\")\n",
        "print(uncertainty[uncertainty.accuracy==False]['variance'].mean())\n",
        "print(\"Ratio of average variance incorrect::correct\")\n",
        "print(uncertainty[uncertainty.accuracy==False]['variance'].mean()/uncertainty[uncertainty.accuracy==True]['variance'].mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average variance for accurate/correct predictions:\n",
            "0.028313040560416065\n",
            "Average variance for inaccurate/false predictions:\n",
            "0.17314979795674157\n",
            "Ratio of average variance incorrect::correct\n",
            "6.1155493910046195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h5PsPzmyH6sA"
      },
      "source": [
        "Check for correlation with presence/absence of attribtue with variance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOcNVys4-Nl-",
        "colab_type": "code",
        "outputId": "2005b4a9-b59a-4246-9cc5-98a9bebdb45b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "print(\"Average variance for predictions when attribute is present:\")\n",
        "print(uncertainty[uncertainty.presence==1]['variance'].mean())\n",
        "print(\"Average variance for predictions when attribute is absent:\")\n",
        "print(uncertainty[uncertainty.presence==0]['variance'].mean())\n",
        "print(\"Ratio of average variance present::absent\")\n",
        "print(uncertainty[uncertainty.presence==1]['variance'].mean()/uncertainty[uncertainty.presence==0]['variance'].mean())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average variance for predictions when attribute is present:\n",
            "0.06275598715517035\n",
            "Average variance for predictions when attribute is absent:\n",
            "0.04078093643102508\n",
            "Ratio of average variance present::absent\n",
            "1.538855961812275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL1LWvFh-NpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uncertainty = pd.DataFrame(columns=['presence','accuracy', 'variance', 'num_judgments'])\n",
        "pred_means = pd.DataFrame(columns = score_column)\n",
        "pred_variances = pd.DataFrame(columns = score_column)\n",
        "\n",
        "for i, pred in enumerate(preds):\n",
        "  if i<len(test_scores):\n",
        "    scores = np.array(test_scores.iloc[i])\n",
        "    #     print(scores)\n",
        "    pred_means = pred_means.append({score_column[k]:pred['prediction_mean'][k] for k in range(len(score_column))}, ignore_index=True)\n",
        "    #     print(mean_prediction)\n",
        "    variance = pred['prediction_var']\n",
        "    pred_variances = pred_variances.append({score_column[k]:variance[k] for k in range(len(score_column))}, ignore_index=True)  \n",
        "    mean_prediction = np.round(pred['prediction_mean'])\n",
        "    acc = scores==mean_prediction\n",
        "    for j in range(len(scores)):\n",
        "      uncertainty = uncertainty.append({'presence':scores[j], 'accuracy': acc[j], 'variance': variance[j]}, ignore_index=True)\n",
        "  else:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65kV2A4--Nr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RJvlFgZ9j_r6",
        "colab": {}
      },
      "source": [
        "def total_accuaracy(pred_means, test_scores):\n",
        "  preds = np.round(pred_means)\n",
        "  comparison = preds == test_scores\n",
        "  correct_guesses = np.reshape(comparison.values,-1)\n",
        "  return np.sum(correct_guesses) / len(correct_guesses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cPZACnkUGrr5",
        "colab": {}
      },
      "source": [
        "def class_accuaracy(pred_means, test_scores):\n",
        "  preds = np.round(pred_means)\n",
        "  comparison = preds == test_scores\n",
        "  correct_guesses = comparison.values\n",
        "  return correct_guesses.sum(axis=0)/ len(correct_guesses)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-xVcqWkdHT-s",
        "outputId": "083c9935-5fca-4925-8b62-8da2c822253d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "print(total_accuaracy(pred_means, test_scores.reset_index(drop=True)))\n",
        "print(class_accuaracy(pred_means, test_scores.reset_index(drop=True)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9060351812645391\n",
            "[0.79283306 0.95742178 0.8519564  0.99568729 0.87359837 0.96471418]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wjZUS-Ergg00",
        "outputId": "f6bcda19-d41a-4d7e-c161-f81329af473b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "source": [
        "def subset_accuracy(att, att_num):\n",
        "  print(\"accuracy on \"+att+ \" comments:\")\n",
        "  print(class_accuaracy(pred_means.iloc[np.where(test_scores[att] == 1)].reset_index(drop=True),\n",
        "                        test_scores.iloc[np.where(test_scores[att] == 1)].reset_index(drop=True))[att_num])\n",
        "\n",
        "  print(\"proportion of \"+att+ \" comments:\")\n",
        "  print(len(test_scores.iloc[np.where(test_scores[att] == 1)].reset_index(drop=True))/len(test_scores))\n",
        "  print()\n",
        "\n",
        "for i, att in enumerate(score_column):\n",
        "  subset_accuracy(att, i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy on toxic comments:\n",
            "0.11676646706586827\n",
            "proportion of toxic comments:\n",
            "0.1309495804908649\n",
            "\n",
            "accuracy on severe_toxic comments:\n",
            "0.030864197530864196\n",
            "proportion of severe_toxic comments:\n",
            "0.012702893436838392\n",
            "\n",
            "accuracy on obscene comments:\n",
            "0.09008097165991903\n",
            "proportion of obscene comments:\n",
            "0.07747196738022426\n",
            "\n",
            "accuracy on threat comments:\n",
            "0.0\n",
            "proportion of threat comments:\n",
            "0.004312710734729083\n",
            "\n",
            "accuracy on insult comments:\n",
            "0.06285072951739619\n",
            "proportion of insult comments:\n",
            "0.06986591390261115\n",
            "\n",
            "accuracy on identity_hate comments:\n",
            "0.013333333333333334\n",
            "proportion of identity_hate comments:\n",
            "0.011761938367442954\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m2flPKNig2zn",
        "outputId": "0eb97fbe-d5d2-4676-db24-4bc7b7663b35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "len(test_scores[test_scores.severe_toxic==1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "229"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NZ1zjhdxZByn",
        "colab": {}
      },
      "source": [
        "at_least_one = (test_scores.toxic==1) | (test_scores.severe_toxic==1) | \\\n",
        "               (test_scores.obscene==1) | (test_scores.threat==1) | \\\n",
        "               (test_scores.insult==1) | (test_scores.identity_hate==1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2VzhiqkLZB2h",
        "colab": {}
      },
      "source": [
        "print(uncertainty[uncertainty.accuracy==True]['variance'].mean())\n",
        "print(uncertainty[uncertainty.accuracy==False]['variance'].mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "75VhsEk5ZB5E",
        "outputId": "d1d7411d-4cdc-43de-c697-c41c82472cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37299"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wXgIhm8zujWn",
        "outputId": "4e9d86f8-5349-47a8-f0d2-ee399497879e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "try: \n",
        "  print(\"this\")\n",
        "  True/\"this\"\n",
        "except:\n",
        "  print(\"didnt work\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this\n",
            "didnt work\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iWn5PHX-4Tdt",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}